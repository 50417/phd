# An initial attempt to build a CLgen Java model.
# File: //deeplearning/clgen/proto/clgen.proto
# Proto: clgen.Instance
working_dir: "/var/phd/clgen/java"
model {
  corpus {
    local_directory: "/var/phd/datasets/github/corpuses/java/"
    # The set of Java keywords.
    greedy_multichar_atomizer {
        tokens: "abstract"
        tokens: "assert"
        tokens: "boolean"
        tokens: "break"
        tokens: "byte"
        tokens: "case"
        tokens: "catch"
        tokens: "char"
        tokens: "class"
        tokens: "continue"
        tokens: "default"
        tokens: "do"
        tokens: "double"
        tokens: "else"
        tokens: "enum"
        tokens: "extends"
        tokens: "final"
        tokens: "finally"
        tokens: "float"
        tokens: "for"
        tokens: "if"
        tokens: "implements"
        tokens: "import"
        tokens: "instanceof"
        tokens: "int"
        tokens: "interface"
        tokens: "long"
        tokens: "native"
        tokens: "new"
        tokens: "package"
        tokens: "private"
        tokens: "protected"
        tokens: "public"
        tokens: "return"
        tokens: "short"
        tokens: "static"
        tokens: "strictfp"
        tokens: "super"
        tokens: "switch"
        tokens: "synchronized"
        tokens: "this"
        tokens: "throw"
        tokens: "throws"
        tokens: "transient"
        tokens: "try"
        tokens: "void"
        tokens: "volatile"
        tokens: "while"
    }
    contentfile_separator: "\n\n"
    # For now we've not going to worry about even testing to see if the Java
    # files are statically compilable, since I don't want to exclude files with
    # user package imports.
    # preprocessor: "deeplearning.clgen.preprocessors.java:Compile"
    preprocessor: "deeplearning.clgen.preprocessors.cxx:StripComments"
    preprocessor: "deeplearning.clgen.preprocessors.java:ClangFormat"
    preprocessor: "deeplearning.clgen.preprocessors.common:StripDuplicateEmptyLines"
    preprocessor: "deeplearning.clgen.preprocessors.common:StripTrailingWhitespace"
  }
  architecture {
    embedding_size: 64
    neuron_type: LSTM
    neurons_per_layer: 1024
    num_layers: 2
    post_layer_dropout_micros: 0  # = 0.0 real value
  }
  training {
    num_epochs: 50
    sequence_length: 50
    batch_size: 64
    shuffle_corpus_contentfiles_between_epochs: true
    adam_optimizer {
      initial_learning_rate_micros: 2000  # 0.02
      learning_rate_decay_per_epoch_micros: 5000  # 0.05
      beta_1_micros: 900000 # 0.9
      beta_2_micros: 999000 # 0.999
      normalized_gradient_clip_micros: 5000000 # 5.0
    }
  }
}
sampler {
  start_text: "public class "
  batch_size: 64
  temperature_micros: 1000000
  termination_criteria {
    symtok {
      depth_increase_token: "{"
      depth_decrease_token: "}"
    }
  }
  termination_criteria {
    maxlen {
      maximum_tokens_in_sample: 5000
    }
  }
}
