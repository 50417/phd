{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pathlib\n",
    "import typing\n",
    "import collections\n",
    "\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "import humanize\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from deeplearning.clgen import clgen\n",
    "from deeplearning.clgen import errors\n",
    "from deeplearning.clgen.corpuses import corpuses\n",
    "from deeplearning.clgen.proto import corpus_pb2\n",
    "from deeplearning.clgen.proto import clgen_pb2\n",
    "from deeplearning.clgen.proto import model_pb2\n",
    "from deeplearning.clgen.proto import sampler_pb2\n",
    "from lib.labm8 import bazelutil\n",
    "from lib.labm8 import pbutil\n",
    "from lib.labm8 import viz\n",
    "\n",
    "FLAGS = flags.FLAGS(['argv[0]', '--logtostderr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 instances\n"
     ]
    }
   ],
   "source": [
    "working_dir = '/mnt/cc/data/experimental/polyglot/baselines'\n",
    "\n",
    "def InstanceConfigs(language: str, model: str, temperature: str) -> typing.Dict[str, str]:\n",
    "    return {\n",
    "        'corpus': bazelutil.DataPath(f'phd/experimental/polyglot/baselines/corpuses/{language}-char.pbtxt'),\n",
    "        'model': bazelutil.DataPath(f'phd/experimental/polyglot/baselines/models/{model}.pbtxt'),\n",
    "        'sampler': bazelutil.DataPath(f'phd/experimental/polyglot/baselines/samplers/{language}-{temperature}.pbtxt'),\n",
    "    }\n",
    "\n",
    "def InstanceFromConfigs(config_paths):\n",
    "    corpus_config = pbutil.FromFile(config_paths['corpus'], corpus_pb2.Corpus())\n",
    "    model_config = pbutil.FromFile(config_paths['model'], model_pb2.Model())\n",
    "    sampler_config = pbutil.FromFile(config_paths['sampler'], sampler_pb2.Sampler())\n",
    "    model_config.corpus.CopyFrom(corpus_config)\n",
    "    return clgen.Instance(\n",
    "        clgen_pb2.Instance(working_dir=working_dir, model=model_config, sampler=sampler_config))\n",
    "\n",
    "instances = [\n",
    "    InstanceFromConfigs(InstanceConfigs('opencl', '32-512x2-adam', '1.0')),\n",
    "    InstanceFromConfigs(InstanceConfigs('opencl', '32-1024x2-adam', '1.0')),\n",
    "    InstanceFromConfigs(InstanceConfigs('opencl', '64-512x2-adam', '1.0')),\n",
    "    InstanceFromConfigs(InstanceConfigs('opencl', '64-1024x2-adam', '1.0')),\n",
    "    InstanceFromConfigs(InstanceConfigs('opencl', '128-512x2-adam', '1.0')),\n",
    "    InstanceFromConfigs(InstanceConfigs('opencl', '128-1024x2-adam', '1.0')),\n",
    "    InstanceFromConfigs(InstanceConfigs('opencl', '512-1024x2-adam', '1.0')),\n",
    "    InstanceFromConfigs(InstanceConfigs('opencl', '1024-1024x2-adam', '1.0')),\n",
    "    # InstanceFromConfigs(InstanceConfigs('java', '128-1024x2-adam', '1.0')),\n",
    "]\n",
    "print(\"Loaded {} instances\".format(len(instances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2 output corpuses\n"
     ]
    }
   ],
   "source": [
    "def GetOutputCorpus(instance: clgen.Instance) -> corpuses.Corpus:\n",
    "    with instance.Session():\n",
    "        out_dir = instance.model.SamplerCache(instance.sampler)\n",
    "        if not out_dir.is_dir():\n",
    "            return None\n",
    "        output_corpus_config = corpus_pb2.Corpus()\n",
    "        output_corpus_config.CopyFrom(instance.model.corpus.config)\n",
    "        output_corpus_config.local_directory = str(out_dir)\n",
    "        return corpuses.Corpus(output_corpus_config)\n",
    "\n",
    "output_corpuses = [GetOutputCorpus(i) for i in instances]\n",
    "print(\"Loaded {} output corpuses\".format(len([x for x in output_corpuses if x])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linuxbrew/.linuxbrew/opt/python/lib/python3.6/site-packages/ipykernel_launcher.py:45: RuntimeWarning: Mean of empty slice.\n",
      "/home/linuxbrew/.linuxbrew/opt/python/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f6f86926aa2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInstanceStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_corpuses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f6f86926aa2d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mInstanceStats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_corpuses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-f6f86926aa2d>\u001b[0m in \u001b[0;36mInstanceStats\u001b[0;34m(instance, output_corpus)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# Sample times is in milliseconds, and we want time per thousand, so they cancel out.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         stats['Time / 1k samples'] = humanize.naturaldelta(\n\u001b[0;32m---> 45\u001b[0;31m             datetime.timedelta(seconds=sample_times.mean()))\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Output samples'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhumanize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintcomma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_corpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "def InstanceStats(instance: clgen.Instance, output_corpus: corpuses.Corpus) -> typing.Dict[str, typing.Any]:\n",
    "    stats = collections.OrderedDict()\n",
    "    stats['Language'] = {\n",
    "        'opencl': 'OpenCL',\n",
    "        'java': 'Java',\n",
    "    }[pathlib.Path(instance.model.corpus.config.local_directory).stem]\n",
    "    with instance.Session():\n",
    "        instance.model.corpus.Create()\n",
    "    stats['Encoding'] = 'Character' if 'Ascii' in str(instance.model.corpus.atomizer) else 'Token'\n",
    "    stats['Vocab size'] = instance.model.corpus.atomizer.vocab_size\n",
    "    stats['Corpus size'] = '{:.1f}M'.format(instance.model.corpus.encoded.token_count / 1e6)\n",
    "    stats['Embedding'] = instance.model.config.architecture.embedding_size\n",
    "    stats['Model size'] = f'{instance.model.config.architecture.neurons_per_layer}x{instance.model.config.architecture.num_layers}'\n",
    "    stats['Dropout'] = instance.model.config.architecture.post_layer_dropout_micros / 1e6\n",
    "    if instance.model.config.training.HasField('adam_optimizer'):\n",
    "        stats['Optimizer'] = 'Adam'\n",
    "        stats['Learning rate'] = instance.model.config.training.adam_optimizer.initial_learning_rate_micros / 1e6\n",
    "        stats['Decay'] = instance.model.config.training.adam_optimizer.learning_rate_decay_per_epoch_micros / 1e6\n",
    "    else:\n",
    "        stats['Optimizer'] = 'RMSProp'\n",
    "        stats['Learning rate'] = instance.model.config.training.rmsprop_optimizer.initial_learning_rate_micros / 1e6\n",
    "        stats['Decay'] = instance.model.config.training.rmsprop_optimizer.learning_rate_decay_per_epoch_micros / 1e6\n",
    "    telemetry = instance.model.TrainingTelemetry()\n",
    "    if telemetry:\n",
    "        stats['Epochs'] = len(telemetry)\n",
    "        stats['Final Loss'] = '{:.3f}'.format(telemetry[-1].loss)\n",
    "        stats['Training time'] = humanize.naturaldelta(\n",
    "            datetime.timedelta(seconds=sum(t.epoch_wall_time_ms for t in telemetry) / 1e3))\n",
    "        stats['Time / epoch'] = humanize.naturaldelta(\n",
    "            datetime.timedelta(seconds=np.array([t.epoch_wall_time_ms for t in telemetry]).mean() / 1e3))\n",
    "\n",
    "    if output_corpus:\n",
    "        with instance.Session():\n",
    "            try:\n",
    "                output_corpus.Create()\n",
    "            except errors.EmptyCorpusException:\n",
    "                pass\n",
    "        samples_dir = instance.model.SamplerCache(instance.sampler)\n",
    "        sample_times = np.array([\n",
    "            pbutil.FromFile(samples_dir / f, model_pb2.Sample, uninitialized_okay=True).wall_time_ms for f in samples_dir.iterdir()\n",
    "        ], dtype=np.int32)\n",
    "        # TODO(cec): Use the number of extracted kernels, not the number of samples themselves.\n",
    "        # Sample times is in milliseconds, and we want time per thousand, so they cancel out.\n",
    "        stats['Time / 1k samples'] = humanize.naturaldelta(\n",
    "            datetime.timedelta(seconds=sample_times.mean()))\n",
    "        stats['Output samples'] = humanize.intcomma(output_corpus.preprocessed.input_size)\n",
    "        if output_corpus.preprocessed.size:\n",
    "            stats['Output vocab size'] = humanize.intcomma(output_corpus.vocab_size)\n",
    "        stats['Num good'] = humanize.intcomma(output_corpus.preprocessed.size)\n",
    "        stats['Efficiency'] = '{:.2%}'.format(\n",
    "            output_corpus.preprocessed.size / (output_corpus.preprocessed.input_size or 1))\n",
    "    # TODO(cec):\n",
    "    # * Post process discard ratio.\n",
    "    # * Time / 1k good samples.\n",
    "    return stats\n",
    "\n",
    "stats = pd.DataFrame([InstanceStats(i, o) for i, o in zip(instances, output_corpuses)]).fillna('-')\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (_, row), instance in zip(stats.iterrows(), instances):\n",
    "    plt.plot([t.epoch_num for t in instance.model.TrainingTelemetry()], \n",
    "             [t.loss for t in instance.model.TrainingTelemetry()], \n",
    "             label=f\"{row['Language']}-{row['Embedding']}-{row['Model size']}\")\n",
    "\n",
    "ax = plt.gca()\n",
    "plt.title('Training Losses')\n",
    "\n",
    "# X axis.\n",
    "# plt.xlim((0, 50 - 1))\n",
    "# ax.set_xticklabels([i + 1 for i in ax.get_xticks()])\n",
    "plt.xlabel('Epochs')\n",
    "\n",
    "# Y axis.\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.legend()\n",
    "viz.finalise(size=(10, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
