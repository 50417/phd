{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from deeplearning.clgen import clgen\n",
    "from deeplearning.clgen.corpuses import corpuses\n",
    "from deeplearning.clgen.proto import corpus_pb2\n",
    "from deeplearning.clgen.proto import clgen_pb2\n",
    "from deeplearning.clgen.proto import model_pb2\n",
    "from deeplearning.clgen.proto import sampler_pb2\n",
    "from deeplearning.clgen import clgen\n",
    "from lib.labm8 import bazelutil\n",
    "from lib.labm8 import pbutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "clone_lists_dir = bazelutil.DataPath('phd/experimental/polyglot/baselines/corpuses')\n",
    "corpuses_dir = bazelutil.DataPath('phd/experimental/polyglot/baselines/corpuses')\n",
    "models_dir = bazelutil.DataPath('phd/experimental/polyglot/baselines/models')\n",
    "samplers_dir = bazelutil.DataPath('phd/experimental/polyglot/baselines/samplers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadProtos(directory, proto_class):\n",
    "    return {\n",
    "        name.stem: corpuses.Corpus(pbutil.FromFile(directory / name, proto_class()))\n",
    "        for name in directory.iterdir()\n",
    "    }\n",
    "\n",
    "corpuses = LoadProtos(corpuses_dir, corpus_pb2.Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 instances\n"
     ]
    }
   ],
   "source": [
    "working_dir = '/var/phd/clgen/baseline'\n",
    "instance_configs = [\n",
    "    {\n",
    "        'corpus': bazelutil.DataPath('phd/experimental/polyglot/baselines/corpuses/opencl-char.pbtxt'),\n",
    "        'model': bazelutil.DataPath('phd/experimental/polyglot/baselines/models/1024x2x50-adam.pbtxt'),\n",
    "        'sampler': bazelutil.DataPath('phd/experimental/polyglot/baselines/samplers/opencl-1.0.pbtxt'),\n",
    "    },\n",
    "    {\n",
    "        'corpus': bazelutil.DataPath('phd/experimental/polyglot/baselines/corpuses/opencl-char.pbtxt'),\n",
    "        'model': bazelutil.DataPath('phd/experimental/polyglot/baselines/models/512x2x50-adam.pbtxt'),\n",
    "        'sampler': bazelutil.DataPath('phd/experimental/polyglot/baselines/samplers/opencl-1.0.pbtxt'),\n",
    "    },\n",
    "    {\n",
    "        'corpus': bazelutil.DataPath('phd/experimental/polyglot/baselines/corpuses/opencl-tok.pbtxt'),\n",
    "        'model': bazelutil.DataPath('phd/experimental/polyglot/baselines/models/1024x2x50-adam.pbtxt'),\n",
    "        'sampler': bazelutil.DataPath('phd/experimental/polyglot/baselines/samplers/opencl-1.0.pbtxt'),\n",
    "    },\n",
    "    {\n",
    "        'corpus': bazelutil.DataPath('phd/experimental/polyglot/baselines/corpuses/opencl-tok.pbtxt'),\n",
    "        'model': bazelutil.DataPath('phd/experimental/polyglot/baselines/models/1024x2x50-adam.pbtxt'),\n",
    "        'sampler': bazelutil.DataPath('phd/experimental/polyglot/baselines/samplers/opencl-1.0.pbtxt'),\n",
    "    },\n",
    "    {\n",
    "        'corpus': bazelutil.DataPath('phd/experimental/polyglot/baselines/corpuses/java-char.pbtxt'),\n",
    "        'model': bazelutil.DataPath('phd/experimental/polyglot/baselines/models/1024x2x50-adam.pbtxt'),\n",
    "        'sampler': bazelutil.DataPath('phd/experimental/polyglot/baselines/samplers/java-1.0.pbtxt'),\n",
    "    },\n",
    "    {\n",
    "        'corpus': bazelutil.DataPath('phd/experimental/polyglot/baselines/corpuses/java-char.pbtxt'),\n",
    "        'model': bazelutil.DataPath('phd/experimental/polyglot/baselines/models/512x2x50-adam.pbtxt'),\n",
    "        'sampler': bazelutil.DataPath('phd/experimental/polyglot/baselines/samplers/java-1.0.pbtxt'),\n",
    "    },\n",
    "    {\n",
    "        'corpus': bazelutil.DataPath('phd/experimental/polyglot/baselines/corpuses/java-tok.pbtxt'),\n",
    "        'model': bazelutil.DataPath('phd/experimental/polyglot/baselines/models/1024x2x50-adam.pbtxt'),\n",
    "        'sampler': bazelutil.DataPath('phd/experimental/polyglot/baselines/samplers/java-1.0.pbtxt'),\n",
    "    },\n",
    "    {\n",
    "        'corpus': bazelutil.DataPath('phd/experimental/polyglot/baselines/corpuses/java-tok.pbtxt'),\n",
    "        'model': bazelutil.DataPath('phd/experimental/polyglot/baselines/models/1024x2x50-adam.pbtxt'),\n",
    "        'sampler': bazelutil.DataPath('phd/experimental/polyglot/baselines/samplers/java-1.0.pbtxt'),\n",
    "    },\n",
    "]\n",
    "\n",
    "def InstanceFromConfigs(config_paths):\n",
    "    corpus_config = pbutil.FromFile(config_paths['corpus'], corpus_pb2.Corpus())\n",
    "    model_config = pbutil.FromFile(config_paths['model'], model_pb2.Model())\n",
    "    sampler_config = pbutil.FromFile(config_paths['sampler'], sampler_pb2.Sampler())\n",
    "    model_config.corpus.CopyFrom(corpus_config)\n",
    "    return clgen.Instance(\n",
    "        clgen_pb2.Instance(working_dir=working_dir, model=model_config, sampler=sampler_config))\n",
    "\n",
    "\n",
    "instances = [InstanceFromConfigs(config_paths) for config_paths in instance_configs]\n",
    "print(\"Loaded {} instances\".format(len(instances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Encoding</th>\n",
       "      <th>Vocab size</th>\n",
       "      <th>Corpus size</th>\n",
       "      <th>Model size</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Learning rate</th>\n",
       "      <th>Decay</th>\n",
       "      <th>Trained?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OpenCL</td>\n",
       "      <td>Character</td>\n",
       "      <td>95</td>\n",
       "      <td>21.8M</td>\n",
       "      <td>1024x2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OpenCL</td>\n",
       "      <td>Character</td>\n",
       "      <td>95</td>\n",
       "      <td>21.8M</td>\n",
       "      <td>512x2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OpenCL</td>\n",
       "      <td>Token</td>\n",
       "      <td>181</td>\n",
       "      <td>18.9M</td>\n",
       "      <td>1024x2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OpenCL</td>\n",
       "      <td>Token</td>\n",
       "      <td>181</td>\n",
       "      <td>18.9M</td>\n",
       "      <td>1024x2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java</td>\n",
       "      <td>Character</td>\n",
       "      <td>3085</td>\n",
       "      <td>286.9M</td>\n",
       "      <td>1024x2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Java</td>\n",
       "      <td>Character</td>\n",
       "      <td>3085</td>\n",
       "      <td>286.9M</td>\n",
       "      <td>512x2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Java</td>\n",
       "      <td>Token</td>\n",
       "      <td>3133</td>\n",
       "      <td>262.2M</td>\n",
       "      <td>1024x2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Java</td>\n",
       "      <td>Token</td>\n",
       "      <td>3133</td>\n",
       "      <td>262.2M</td>\n",
       "      <td>1024x2</td>\n",
       "      <td>0.002</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language   Encoding  Vocab size Corpus size Model size  Dropout Optimizer  \\\n",
       "0   OpenCL  Character          95       21.8M     1024x2    0.002      Adam   \n",
       "1   OpenCL  Character          95       21.8M      512x2    0.002      Adam   \n",
       "2   OpenCL      Token         181       18.9M     1024x2    0.002      Adam   \n",
       "3   OpenCL      Token         181       18.9M     1024x2    0.002      Adam   \n",
       "4     Java  Character        3085      286.9M     1024x2    0.002      Adam   \n",
       "5     Java  Character        3085      286.9M      512x2    0.002      Adam   \n",
       "6     Java      Token        3133      262.2M     1024x2    0.002      Adam   \n",
       "7     Java      Token        3133      262.2M     1024x2    0.002      Adam   \n",
       "\n",
       "   Learning rate  Decay  Trained?  \n",
       "0          0.002    0.0      True  \n",
       "1          0.002    0.0      True  \n",
       "2          0.002    0.0      True  \n",
       "3          0.002    0.0      True  \n",
       "4          0.002    0.0     False  \n",
       "5          0.002    0.0     False  \n",
       "6          0.002    0.0     False  \n",
       "7          0.002    0.0     False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def InstanceStats(instance):\n",
    "    stats = {}\n",
    "    stats['Language'] = {\n",
    "        'opencl': 'OpenCL',\n",
    "        'java': 'Java',\n",
    "    }[pathlib.Path(instance.model.corpus.config.local_directory).stem]\n",
    "    instance.model.corpus.Create()\n",
    "    stats['Encoding'] = 'Character' if 'Ascii' in str(instance.model.corpus.atomizer) else 'Token'\n",
    "    stats['Vocab size'] = instance.model.corpus.atomizer.vocab_size\n",
    "    stats['Corpus size'] = '{:.1f}M'.format(instance.model.corpus.encoded.token_count / 1e6)\n",
    "    stats['Model size'] = f'{instance.model.config.architecture.neurons_per_layer}x{instance.model.config.architecture.num_layers}'\n",
    "    stats['Dropout'] = instance.model.config.architecture.post_layer_dropout_micros / 1e6\n",
    "    if instance.model.config.training.HasField('adam_optimizer'):\n",
    "        stats['Optimizer'] = 'Adam'\n",
    "        stats['Learning rate'] = instance.model.config.training.adam_optimizer.initial_learning_rate_micros / 1e6\n",
    "        stats['Decay'] = instance.model.config.training.adam_optimizer.learning_rate_decay_per_epoch_micros / 1e6\n",
    "    else:\n",
    "        stats['Optimizer'] = 'RMSProp'\n",
    "        stats['Learning rate'] = instance.model.config.training.rmsprop_optimizer.initial_learning_rate_micros / 1e6\n",
    "        stats['Decay'] = instance.model.config.training.rmsprop_optimizer.learning_rate_decay_per_epoch_micros / 1e6\n",
    "    stats['Trained?'] = instance.model.is_trained\n",
    "    # TODO: \n",
    "    # * Time / epoch\n",
    "    # * Min loss\n",
    "    # * Time / 1k samples\n",
    "    # * Post process discard ratio\n",
    "    # * Time / 1k good samples\n",
    "    return stats\n",
    "\n",
    "df = pd.DataFrame([InstanceStats(i) for i in instances],\n",
    "                  columns=['Language', 'Encoding', 'Vocab size', 'Corpus size', 'Model size', 'Dropout',\n",
    "                           'Optimizer', 'Learning rate', 'Decay', 'Trained?'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
