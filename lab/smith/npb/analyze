#!/usr/bin/env python3
from argparse import ArgumentParser

import csv
import matplotlib.pyplot as plt
import numpy as np
import os
import shutil
import sqlite3
import sys

import labm8
from labm8 import math as labmath


def create_db(db_path):
    if os.path.exists(db_path):
        os.remove(db_path)

    db = sqlite3.connect(db_path)
    c = db.cursor()
    c.executescript("""
    CREATE TABLE Runtimes(
       benchmark TEXT NOT NULL, -- benchmark ID
       dataset TEXT NOT NULL, -- dataset ID
       device TEXT NOT NULL, -- <cpu|gpu>
       run INT NOT NULL, -- run id
       runtime REAL NOT NULL -- (kernel complete - kernel submit) in ms
    );

    CREATE TABLE RuntimeStats(
       benchmark TEXT NOT NULL, -- Runtimes.benchmark
       dataset TEXT NOT NULL, -- Runtimes.dataset
       device TEXT NOT NULL, -- Runtimes.device
       runtime REAL NOT NULL, -- mean runtime
       ci REAL NOT NULL, -- 95% CI
       n INT NOT NULL -- number results
    );

    CREATE TABLE Wgsizes(
       benchmark TEXT NOT NULL, -- benchmark ID
       dataset TEXT NOT NULL, -- dataset ID
       wgsize INT NOT NULL -- scalar wgsize
    );

    CREATE TABLE WgsizeStats(
       benchmark TEXT NOT NULL, -- benchmark ID
       dataset TEXT NOT NULL, -- dataset ID
       wgsize INT NOT NULL -- scalar wgsize
    );

    CREATE TABLE Transfers(
       benchmark TEXT NOT NULL, -- benchmark ID
       dataset TEXT NOT NULL, -- dataset ID
       transfer INT NOT NULL -- transfer size (in bytes)
    );

    CREATE TABLE TransferStats(
       benchmark TEXT NOT NULL, -- benchmark ID
       dataset TEXT NOT NULL, -- dataset ID
       transfer INT NOT NULL -- transfer size (in bytes)
    );
    """)
    c.close()
    db.commit()
    return db


def csv2db(runtimes_csv_path, wgsizes_csv_path, transfers_csv_path, db_path):
    print("converting CSV data to SQLite ...")
    if not os.path.exists(runtimes_csv_path):
        raise Exception("file '{}' not found!".format(runtimes_csv_path))
    if not os.path.exists(wgsizes_csv_path):
        raise Exception("file '{}' not found!".format(wgsizes_csv_path))
    if not os.path.exists(transfers_csv_path):
        raise Exception("file '{}' not found!".format(transfers_csv_path))

    db = create_db(db_path)
    c = db.cursor()
    with open(runtimes_csv_path) as infile:
        reader = csv.DictReader(infile)
        to_db = [(i['benchmark'], i['dataset'], i['device'],
                  i['run'], i['runtime']) for i in reader]
    c.executemany("INSERT INTO Runtimes VALUES (?,?,?,?,?)", to_db)

    with open(wgsizes_csv_path) as infile:
        reader = csv.DictReader(infile)
        to_db = [(i['benchmark'], i['dataset'], i['wgsize']) for i in reader]
    c.executemany("INSERT INTO Wgsizes VALUES (?,?,?)", to_db)

    with open(transfers_csv_path) as infile:
        reader = csv.DictReader(infile)
        to_db = [(i['benchmark'], i['dataset'], i['size']) for i in reader]
    c.executemany("INSERT INTO Transfers VALUES (?,?,?)", to_db)

    db.commit()
    c.close()
    return db


def get_wgsize(db_c, benchmark, dataset):
    db_c.execute('SELECT wgsize FROM WgsizeStats WHERE benchmark=? '
                 'AND dataset=?', (benchmark, dataset))
    val = db_c.fetchone()
    return int(val[0]) if val else 0


def get_runs(db_c, benchmark, dataset, device):
    db_c.execute('SELECT DISTINCT run FROM Runtimes WHERE benchmark=? AND '
                 'dataset=? AND device=?', (benchmark, dataset, device))
    return [row[0] for row in db_c.fetchall()]


def get_transfer(db_c, benchmark, dataset):
    db_c.execute('SELECT transfer FROM TransferStats WHERE benchmark=? '
                 'AND dataset=?', (benchmark, dataset))
    val = db_c.fetchone()
    return int(val[0]) if val else 0


def runtime_stats_scenario(db_c, benchmark, dataset, device):
    runtimes = []
    runs = get_runs(db_c, benchmark, dataset, device)
    for run in runs:
        db_c.execute("SELECT SUM(runtime) FROM Runtimes WHERE benchmark=? AND "
                     "dataset=? AND device=? AND run=?",
                     (benchmark, dataset, device, run))
        runtimes.append(db_c.fetchone()[0])
    n = len(runs)
    mean = labmath.mean(runtimes)
    ci = labmath.confinterval(runtimes, array_mean=mean)[1] - mean
    return (benchmark, dataset, device, mean, ci, n)


def wgsize_stats_scenario(db_c, benchmark, dataset):
    db_c.execute('SELECT AVG(wgsize) FROM Wgsizes WHERE benchmark=? '
                 'AND dataset=?', (benchmark, dataset))
    return (benchmark, dataset, round(db_c.fetchone()[0]))


def transfer_stats_scenario(db_c, benchmark, dataset):
    db_c.execute('SELECT AVG(transfer) FROM Transfers WHERE benchmark=? '
                 'AND dataset=?', (benchmark, dataset))
    return (benchmark, dataset, round(db_c.fetchone()[0]))


def stats(db):
    print("reducing raw data to statistics ...")
    c = db.cursor()
    c.execute('SELECT DISTINCT benchmark,dataset,device FROM Runtimes')
    to_db = [runtime_stats_scenario(c, *row) for row in c.fetchall()]
    c.executemany("INSERT INTO RuntimeStats VALUES (?,?,?,?,?,?)", to_db)

    c.execute('SELECT DISTINCT benchmark,dataset FROM Wgsizes')
    to_db = [wgsize_stats_scenario(c, *row) for row in c.fetchall()]
    c.executemany("INSERT INTO WgsizeStats VALUES (?,?,?)", to_db)

    c.execute('SELECT DISTINCT benchmark,dataset FROM Transfers')
    to_db = [transfer_stats_scenario(c, *row) for row in c.fetchall()]
    c.executemany("INSERT INTO TransferStats VALUES (?,?,?)", to_db)

    db.commit()
    c.execute('SELECT Count(*) FROM Runtimes')
    print('  num runtimes', c.fetchone()[0])
    c.execute('SELECT Count(*) FROM Wgsizes')
    print('  num wgsizes', c.fetchone()[0])
    c.execute('SELECT Count(*) FROM Transfers')
    print('  num transfers', c.fetchone()[0])
    c.close()


def get_benchmarks(db):
    c = db.cursor()
    c.execute('SELECT DISTINCT benchmark FROM RuntimeStats')
    benchmarks = [row[0] for row in c.fetchall()]
    c.close()
    return benchmarks


def get_ordered_datasets(db, benchmark):
    c = db.cursor()
    c.execute("SELECT DISTINCT dataset FROM RuntimeStats WHERE benchmark=?",
              (benchmark,))
    datasets = [row[0] for row in c.fetchall()]
    ordered = []

    for label in ['S', 'W', 'A', 'B', 'C', 'D', 'E']:
        if label in datasets:
            ordered.append(label)
    if len(ordered) != len(datasets):
        raise Exception("unrecognized dataset!")
    return ordered


def get_runtime_stats(db, benchmark, dataset, device):
    c = db.cursor()
    c.execute('SELECT AVG(runtime),AVG(ci) FROM RuntimeStats WHERE '
              'benchmark=? AND dataset=? AND device=?',
              (benchmark, dataset, device))
    val = c.fetchone()
    return (0, 0) if all(v is None for v in val) else val


def has_data(db_c, benchmark, dataset):
    db_c.execute('SELECT runtime FROM RuntimeStats WHERE '
                 'benchmark=? AND dataset=?', (benchmark, dataset))
    times = [row[0] for row in db_c.fetchall()]
    return len(times) == 2


def get_oracle_stats(db, benchmark, dataset):
    cpu = get_runtime_stats(db, benchmark, dataset, 'CPU')[0]
    gpu = get_runtime_stats(db, benchmark, dataset, 'GPU')[0]
    if cpu <= gpu:
        oracle = 'CPU'
        fast = cpu
        slow = gpu
    else:
        oracle = 'GPU'
        fast = gpu
        slow = cpu
    speedup = slow / fast
    penalty = fast / slow
    return (oracle, speedup, penalty)



def features(db, out_path):
    print("extracting features ...")
    c = db.cursor()
    with open(out_path, 'w') as outfile:
        print('benchmark', 'dataset', 'transfer', 'work-items',
              'oracle', 'speedup', 'penalty',
              sep=',', file=outfile)
        for benchmark in get_benchmarks(db):
            for dataset in get_ordered_datasets(db, benchmark):
                if has_data(c, benchmark, dataset):
                    wgsize = get_wgsize(c, benchmark, dataset)
                    transfer = get_transfer(c, benchmark, dataset)
                    oracle, speedup, penalty = get_oracle_stats(
                        db, benchmark, dataset)
                    print(benchmark, dataset, transfer, wgsize,
                          oracle, speedup, penalty,
                          sep=',', file=outfile)
                else:
                    print("warning: no data for workload:", benchmark, dataset,
                          file=sys.stderr)


def plot_benchmark(db, benchmark, plot_path):
    print("plot {}".format(plot_path))
    c = db.cursor()
    datasets = get_ordered_datasets(db, benchmark)

    labels, cpu, cpu_err, gpu, gpu_err = [], [], [], [], []
    for dataset in get_ordered_datasets(db, benchmark):
        label = dataset
        ctime, cerr = get_runtime_stats(
            db, benchmark, dataset, 'CPU')
        gtime, gerr = get_runtime_stats(
            db, benchmark, dataset, 'GPU')

        labels.append(label)
        cpu.append(ctime / 1000.0)  # convert ms t s
        cpu_err.append(cerr / 1000.0)  # convert ms t s
        gpu.append(gtime / 1000.0)  # convert ms t s
        gpu_err.append(gerr / 1000.0)  # convert ms t s

    N = len(labels)
    ind = np.arange(N)
    width = 0.35       # the width of the bars

    fig, ax = plt.subplots()
    rects1 = ax.bar(ind, cpu, width, color='r', yerr=cpu_err)
    rects2 = ax.bar(ind + width, gpu, width, color='y', yerr=gpu_err)

    # add some text for labels, title and axes ticks
    ax.set_ylabel('OpenCL Runtime (s)')
    ax.set_title('npb-3.3 benchmark {}'.format(benchmark))
    ax.set_xticks(ind + width)
    ax.set_xticklabels(labels)

    # No negative runtimes!
    ax.set_ylim(bottom=0)

    ax.legend((rects1[0], rects2[0]), ('CPU', 'GPU'))

    def autolabel(rects, speedups):
        # attach some text labels
        for rect, speedup in zip(rects, speedups):
            ax.text(rect.get_x() + rect.get_width() / 2.,
                    1.07 * rect.get_height(),
                    speedup, ha='center', va='bottom')

    speedups = []
    for c,g in zip(cpu,gpu):
        if c and g:
            speedups.append('{:.2f}'.format(c / g))
        else:
            speedups.append('n/a')
    autolabel(rects2, speedups)

    plt.savefig(plot_path)


def plots(db, img_path):
    if os.path.exists(img_path):
        shutil.rmtree(img_path)
    os.makedirs(img_path)

    for benchmark in get_benchmarks(db):
        plot_path = os.path.join(img_path, benchmark + '.png')
        plot_benchmark(db, benchmark, plot_path)


def main():
    parser = ArgumentParser()
    parser.add_argument('input', help='path to dataset')
    args = parser.parse_args()

    data_root = os.path.expanduser(args.input)

    runtimes_csv_path = os.path.join(data_root, 'runtimes.csv')
    wgsizes_csv_path = os.path.join(data_root, 'wgsizes.csv')
    transfers_csv_path = os.path.join(data_root, 'transfers.csv')
    features_csv_path = os.path.join(data_root, 'features.csv')
    db_path = os.path.join(data_root, 'data.db')
    img_path = os.path.join(data_root, 'img')

    # db = sqlite3.connect(db_path)
    db = csv2db(runtimes_csv_path, wgsizes_csv_path, transfers_csv_path, db_path)
    stats(db)
    features(db, features_csv_path)
    plots(db, img_path)


if __name__ == "__main__":
    main()
