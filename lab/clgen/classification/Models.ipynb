{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# preamble\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%run lib/preamble.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def zero_r():\n",
    "    def train_fn(model, train, *args, **kwargs):\n",
    "        \"\"\" train a model \"\"\"\n",
    "        model[\"zero_r\"] = Counter(train[\"y\"][:,0]).most_common(1)[0][0]\n",
    "\n",
    "    def test_fn(model, test, seed, *args, **kwargs):\n",
    "        \"\"\" make predictions for test data \"\"\"\n",
    "        return [model[\"zero_r\"]] * len(test[\"y\"])\n",
    "\n",
    "    def save_fn(outpath, model):\n",
    "        \"\"\" save a trained model \"\"\"\n",
    "        with open(outpath, \"wb\") as outfile:\n",
    "            pickle.dump(model, outfile)\n",
    "    \n",
    "    def load_fn(inpath):\n",
    "        \"\"\" load a trained model \"\"\"\n",
    "        with open(inpath, \"rb\") as infile:\n",
    "            model = pickle.load(infile)\n",
    "        return model\n",
    "        \n",
    "    return {\n",
    "        \"name\": \"zero_r\",\n",
    "        \"train_fn\": train_fn,\n",
    "        \"test_fn\": test_fn,\n",
    "        \"save_fn\": save_fn,\n",
    "        \"load_fn\": load_fn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cgo13():\n",
    "    def create_model(seed=seed, **kwargs):\n",
    "        \"\"\" instantiate a model \"\"\" \n",
    "        return DecisionTreeClassifier(random_state=seed, splitter=\"best\", criterion=\"entropy\")\n",
    "\n",
    "    def train_fn(model, train, validation, *args, **kwargs):\n",
    "        \"\"\" train a model \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        model.fit(train[\"x_4\"], train[\"y\"])\n",
    "        return {}\n",
    "\n",
    "    def test_fn(model, test, seed, *args, **kwargs):\n",
    "        \"\"\" make predictions for test data \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        return model.predict(test[\"x_4\"])\n",
    "    \n",
    "    def save_fn(outpath, model):\n",
    "        \"\"\" save a trained model \"\"\"\n",
    "        with open(outpath, \"wb\") as outfile:\n",
    "            pickle.dump(model, outfile)\n",
    "    \n",
    "    def load_fn(inpath):\n",
    "        \"\"\" load a trained model \"\"\"\n",
    "        with open(inpath, \"rb\") as infile:\n",
    "            model = pickle.load(infile)\n",
    "        return model\n",
    "        \n",
    "    return {\n",
    "        \"name\": \"cgo13\",\n",
    "        \"create_model\": create_model,\n",
    "        \"train_fn\": train_fn,\n",
    "        \"test_fn\": test_fn,\n",
    "        \"save_fn\": save_fn,\n",
    "        \"load_fn\": load_fn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def harry():\n",
    "    BATCH_SIZE = 64\n",
    "    EMBEDDING_VECTOR_LEN = 64\n",
    "    \n",
    "    def create_model(*args, data_desc=None, **kwargs):\n",
    "        \"\"\" instantiate a model \"\"\" \n",
    "        atomizer = data_desc[\"atomizer\"]\n",
    "        seq_length = data_desc[\"seq_length\"]\n",
    "        vocab_size = atomizer.vocab_size + 1\n",
    "\n",
    "        dyn_inputs = Input(shape=(2,), name=\"data_in\")\n",
    "        left = BatchNormalization(name=\"dynprop_norm\")(dyn_inputs)\n",
    "\n",
    "        seq_inputs = Input(shape=(seq_length,), dtype=\"int32\", name=\"code_in\")\n",
    "        right = Embedding(output_dim=EMBEDDING_VECTOR_LEN, input_dim=vocab_size, input_length=seq_length)(seq_inputs)\n",
    "        right = LSTM(16, consume_less=\"mem\")(right)\n",
    "        right = BatchNormalization(input_shape=(32,), name=\"lstm_norm\")(right)\n",
    "\n",
    "        aux_out = Dense(2, activation=\"sigmoid\", name=\"aux_out\")(right)\n",
    "\n",
    "        x = merge([left, right], mode=\"concat\")\n",
    "        x = Dense(18, activation=\"relu\")(x)\n",
    "        out = Dense(2, activation=\"sigmoid\", name=\"out\")(x)\n",
    "\n",
    "        model = Model(input=[dyn_inputs, seq_inputs], output=[out, aux_out])\n",
    "        model.compile(optimizer=\"adam\",\n",
    "                      loss={\"out\": \"categorical_crossentropy\", \"aux_out\": \"categorical_crossentropy\"},\n",
    "                      loss_weights={\"out\": 1., \"aux_out\": .2},\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def train_fn(model, train, *args, validation=None, **kwargs):\n",
    "        \"\"\" train a model \"\"\"\n",
    "        model.fit({\"data_in\": train[\"x_2\"], \"code_in\": train[\"x_seq\"]},\n",
    "                  {\"out\": train[\"y_2\"], \"aux_out\": train[\"y_2\"]},\n",
    "                  nb_epoch=1,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  validation_data=({\"data_in\": validation[\"x_2\"], \"code_in\": validation[\"x_seq\"]},\n",
    "                                   {\"out\": validation[\"y_2\"], \"aux_out\": validation[\"y_2\"]}),\n",
    "                  verbose=1,\n",
    "                  shuffle=True)\n",
    "\n",
    "    def test_fn(model, test, seed, *args, **kwargs):\n",
    "        \"\"\" make predictions for test data \"\"\"\n",
    "        predictions = np.array(model.predict({\"data_in\": test[\"x_2\"], \"code_in\": test[\"x_seq\"]},\n",
    "                                             batch_size=BATCH_SIZE, verbose=0))\n",
    "        clipped = [np.argmax(x) for x in predictions[0]]\n",
    "        return clipped\n",
    "\n",
    "    def save_fn(outpath, model):\n",
    "        \"\"\" save a trained model \"\"\"\n",
    "        model.save(outpath)\n",
    "    \n",
    "    def load_fn(inpath):\n",
    "        \"\"\" load a trained model \"\"\"\n",
    "        return load_model(inpath)\n",
    "\n",
    "    return {\n",
    "        \"name\": \"harry\",\n",
    "        \"create_model\": create_model,\n",
    "        \"train_fn\": train_fn,\n",
    "        \"test_fn\": test_fn,\n",
    "        \"save_fn\": save_fn,\n",
    "        \"load_fn\": load_fn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sally():\n",
    "    BATCH_SIZE = 64\n",
    "    EMBEDDING_VECTOR_LEN = 64\n",
    "    \n",
    "    def create_model(*args, data_desc=None, **kwargs):\n",
    "        \"\"\" instantiate a model \"\"\" \n",
    "        atomizer = data_desc[\"atomizer\"]\n",
    "        seq_length = data_desc[\"seq_length\"]\n",
    "        vocab_size = atomizer.vocab_size + 1\n",
    "\n",
    "        dyn_inputs = Input(shape=(2,), name=\"data_in\")\n",
    "        left = BatchNormalization(name=\"dynprop_norm\")(dyn_inputs)\n",
    "\n",
    "        seq_inputs = Input(shape=(seq_length,), dtype=\"int32\", name=\"code_in\")\n",
    "        right = Embedding(output_dim=EMBEDDING_VECTOR_LEN, input_dim=vocab_size, input_length=seq_length)(seq_inputs)\n",
    "        right = LSTM(32, consume_less=\"mem\", return_sequences=True)(right)\n",
    "        right = LSTM(32, consume_less=\"mem\")(right)\n",
    "        right = BatchNormalization(input_shape=(32,), name=\"lstm_norm\")(right)\n",
    "\n",
    "        aux_out = Dense(2, activation=\"sigmoid\", name=\"aux_out\")(right)\n",
    "\n",
    "        x = merge([left, right], mode=\"concat\")\n",
    "        x = Dense(34, activation=\"relu\")(x)\n",
    "        x = Dense(34, activation=\"relu\")(x)\n",
    "        out = Dense(2, activation=\"sigmoid\", name=\"out\")(x)\n",
    "\n",
    "        model = Model(input=[dyn_inputs, seq_inputs], output=[out, aux_out])\n",
    "        model.compile(optimizer=\"adam\",\n",
    "                      loss={\"out\": \"categorical_crossentropy\", \"aux_out\": \"categorical_crossentropy\"},\n",
    "                      loss_weights={\"out\": 1., \"aux_out\": .2},\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    def train_fn(model, train, *args, validation=None, **kwargs):\n",
    "        \"\"\" train a model \"\"\"\n",
    "        model.fit({\"data_in\": train[\"x_2\"], \"code_in\": train[\"x_seq\"]},\n",
    "                  {\"out\": train[\"y_2\"], \"aux_out\": train[\"y_2\"]},\n",
    "                  nb_epoch=1,\n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  validation_data=({\"data_in\": validation[\"x_2\"], \"code_in\": validation[\"x_seq\"]},\n",
    "                                   {\"out\": validation[\"y_2\"], \"aux_out\": validation[\"y_2\"]}),\n",
    "                  verbose=1,\n",
    "                  shuffle=True)\n",
    "\n",
    "    def test_fn(model, test, seed, *args, **kwargs):\n",
    "        \"\"\" make predictions for test data \"\"\"\n",
    "        predictions = np.array(model.predict({\"data_in\": test[\"x_2\"], \"code_in\": test[\"x_seq\"]},\n",
    "                                             batch_size=BATCH_SIZE, verbose=0))\n",
    "        clipped = [np.argmax(x) for x in predictions[0]]\n",
    "        return clipped\n",
    "\n",
    "    def save_fn(outpath, model):\n",
    "        \"\"\" save a trained model \"\"\"\n",
    "        model.save(outpath)\n",
    "    \n",
    "    def load_fn(inpath):\n",
    "        \"\"\" load a trained model \"\"\"\n",
    "        return load_model(inpath)\n",
    "\n",
    "    return {\n",
    "        \"name\": \"sally\",\n",
    "        \"create_model\": create_model,\n",
    "        \"train_fn\": train_fn,\n",
    "        \"test_fn\": test_fn,\n",
    "        \"save_fn\": save_fn,\n",
    "        \"load_fn\": load_fn\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded from models/harry/amd-B-60:20:20-CharacterAtomizer:1024-204.model\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[1,0] = 84 is not in [0, 84)\n\t [[Node: Gather_1 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_2_W_1/read, _recv_code_in_1_0)]]\n\nCaused by op 'Gather_1', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/cec/clgen/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-43-e6da83219998>\", line 1, in <module>\n    load_and_test(harry(), \"amd\", \"B\", split=(.6,.2,.2), seed=204)\n  File \"/home/cec/phd/lab/clgen/classification/lib/preamble.py\", line 473, in load_and_test\n    model = load_fn(inpath)\n  File \"<ipython-input-4-618d0ef7efac>\", line 56, in load_fn\n    return load_model(inpath)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/models.py\", line 142, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/models.py\", line 193, in model_from_config\n    return layer_from_config(config, custom_objects=custom_objects)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/utils/layer_utils.py\", line 40, in layer_from_config\n    custom_objects=custom_objects)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 2582, in from_config\n    process_layer(layer_data)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 2577, in process_layer\n    layer(input_tensors[0])\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 128, in call\n    out = K.gather(W, x)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 960, in gather\n    return tf.gather(reference, indices)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1293, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[1,0] = 84 is not in [0, 84)\n\t [[Node: Gather_1 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_2_W_1/read, _recv_code_in_1_0)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[1,0] = 84 is not in [0, 84)\n\t [[Node: Gather_1 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_2_W_1/read, _recv_code_in_1_0)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-e6da83219998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mload_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mharry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"amd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m204\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/cec/phd/lab/clgen/classification/lib/preamble.py\u001b[0m in \u001b[0;36mload_and_test\u001b[0;34m(model_desc, platform, source, split, atomizer, maxlen, seed)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;31m# test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m     \u001b[0mtest_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-618d0ef7efac>\u001b[0m in \u001b[0;36mtest_fn\u001b[0;34m(model, test, seed, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;34m\"\"\" make predictions for test data \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         predictions = np.array(model.predict({\"data_in\": test[\"x_2\"], \"code_in\": test[\"x_seq\"]},\n\u001b[0;32m---> 46\u001b[0;31m                                              batch_size=BATCH_SIZE, verbose=0))\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mclipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclipped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1272\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[1,0] = 84 is not in [0, 84)\n\t [[Node: Gather_1 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_2_W_1/read, _recv_code_in_1_0)]]\n\nCaused by op 'Gather_1', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2827, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/cec/clgen/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-43-e6da83219998>\", line 1, in <module>\n    load_and_test(harry(), \"amd\", \"B\", split=(.6,.2,.2), seed=204)\n  File \"/home/cec/phd/lab/clgen/classification/lib/preamble.py\", line 473, in load_and_test\n    model = load_fn(inpath)\n  File \"<ipython-input-4-618d0ef7efac>\", line 56, in load_fn\n    return load_model(inpath)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/models.py\", line 142, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/models.py\", line 193, in model_from_config\n    return layer_from_config(config, custom_objects=custom_objects)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/utils/layer_utils.py\", line 40, in layer_from_config\n    custom_objects=custom_objects)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 2582, in from_config\n    process_layer(layer_data)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 2577, in process_layer\n    layer(input_tensors[0])\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 128, in call\n    out = K.gather(W, x)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 960, in gather\n    return tf.gather(reference, indices)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1293, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[1,0] = 84 is not in [0, 84)\n\t [[Node: Gather_1 = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_2_W_1/read, _recv_code_in_1_0)]]\n"
     ]
    }
   ],
   "source": [
    "load_and_test(harry(), \"amd\", \"B\", split=(.6,.2,.2), seed=204)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/amd-B-60:20:20-CharacterAtomizer:1024-204.model\n",
      "[[79  0]\n",
      " [66  0]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/amd-B-60:20:20-CharacterAtomizer:1024-205.model\n",
      "[[73  0]\n",
      " [55  0]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/amd-B-60:20:20-CharacterAtomizer:1024-206.model\n",
      "[[77  0]\n",
      " [54  0]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/amd-B-60:20:20-CharacterAtomizer:1024-207.model\n",
      "[[79  0]\n",
      " [50  0]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/amd-B-60:20:20-CharacterAtomizer:1024-208.model\n",
      "[[86  0]\n",
      " [53  0]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/amd-B-60:20:20-CharacterAtomizer:1024-209.model\n",
      "[[81  0]\n",
      " [64  0]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/amd-B-60:20:20-CharacterAtomizer:1024-210.model\n",
      "[[77  0]\n",
      " [57  0]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/amd-B-60:20:20-CharacterAtomizer:1024-211.model\n",
      "[[91  0]\n",
      " [56  0]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/amd-B-60:20:20-CharacterAtomizer:1024-212.model\n",
      "[[93  0]\n",
      " [57  0]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/amd-B-60:20:20-CharacterAtomizer:1024-213.model\n",
      "[[75  0]\n",
      " [53  0]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/nvidia-B-60:20:20-CharacterAtomizer:1024-204.model\n",
      "[[ 0 56]\n",
      " [ 0 89]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/nvidia-B-60:20:20-CharacterAtomizer:1024-205.model\n",
      "[[ 0 60]\n",
      " [ 0 68]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/nvidia-B-60:20:20-CharacterAtomizer:1024-206.model\n",
      "[[ 0 58]\n",
      " [ 0 73]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/nvidia-B-60:20:20-CharacterAtomizer:1024-207.model\n",
      "[[ 0 53]\n",
      " [ 0 76]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/nvidia-B-60:20:20-CharacterAtomizer:1024-208.model\n",
      "[[ 0 57]\n",
      " [ 0 82]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/nvidia-B-60:20:20-CharacterAtomizer:1024-209.model\n",
      "[[ 0 58]\n",
      " [ 0 87]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/nvidia-B-60:20:20-CharacterAtomizer:1024-210.model\n",
      "[[ 0 52]\n",
      " [ 0 82]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/nvidia-B-60:20:20-CharacterAtomizer:1024-211.model\n",
      "[[ 0 63]\n",
      " [ 0 84]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/nvidia-B-60:20:20-CharacterAtomizer:1024-212.model\n",
      "[[ 0 69]\n",
      " [ 0 81]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/zero_r/nvidia-B-60:20:20-CharacterAtomizer:1024-213.model\n",
      "[[ 0 54]\n",
      " [ 0 74]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/amd-B-60:20:20-CharacterAtomizer:1024-204.model\n",
      "[[70  9]\n",
      " [17 49]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/amd-B-60:20:20-CharacterAtomizer:1024-205.model\n",
      "[[56 17]\n",
      " [13 42]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/amd-B-60:20:20-CharacterAtomizer:1024-206.model\n",
      "[[71  6]\n",
      " [16 38]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/amd-B-60:20:20-CharacterAtomizer:1024-207.model\n",
      "[[69 10]\n",
      " [11 39]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/amd-B-60:20:20-CharacterAtomizer:1024-208.model\n",
      "[[67 19]\n",
      " [13 40]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/amd-B-60:20:20-CharacterAtomizer:1024-209.model\n",
      "[[71 10]\n",
      " [17 47]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/amd-B-60:20:20-CharacterAtomizer:1024-210.model\n",
      "[[63 14]\n",
      " [16 41]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/amd-B-60:20:20-CharacterAtomizer:1024-211.model\n",
      "[[71 20]\n",
      " [13 43]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/amd-B-60:20:20-CharacterAtomizer:1024-212.model\n",
      "[[79 14]\n",
      " [15 42]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/amd-B-60:20:20-CharacterAtomizer:1024-213.model\n",
      "[[65 10]\n",
      " [10 43]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/nvidia-B-60:20:20-CharacterAtomizer:1024-204.model\n",
      "[[48  8]\n",
      " [16 73]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/nvidia-B-60:20:20-CharacterAtomizer:1024-205.model\n",
      "[[49 11]\n",
      " [13 55]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/nvidia-B-60:20:20-CharacterAtomizer:1024-206.model\n",
      "[[43 15]\n",
      " [18 55]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/nvidia-B-60:20:20-CharacterAtomizer:1024-207.model\n",
      "[[41 12]\n",
      " [ 7 69]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/nvidia-B-60:20:20-CharacterAtomizer:1024-208.model\n",
      "[[46 11]\n",
      " [13 69]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/nvidia-B-60:20:20-CharacterAtomizer:1024-209.model\n",
      "[[44 14]\n",
      " [19 68]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/nvidia-B-60:20:20-CharacterAtomizer:1024-210.model\n",
      "[[38 14]\n",
      " [16 66]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/nvidia-B-60:20:20-CharacterAtomizer:1024-211.model\n",
      "[[47 16]\n",
      " [ 9 75]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/nvidia-B-60:20:20-CharacterAtomizer:1024-212.model\n",
      "[[48 21]\n",
      " [11 70]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/cgo13/nvidia-B-60:20:20-CharacterAtomizer:1024-213.model\n",
      "[[40 14]\n",
      " [21 53]]\n",
      "num instances 680 (0 synthetic, 680 benchmarks)\n",
      "unique kernels 247\n",
      "vocab size 84\n",
      "pad val 84\n",
      "padded seq length 1024\n",
      "model loaded from models/harry/amd-B-60:20:20-CharacterAtomizer:1024-204.model\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[1,0] = 84 is not in [0, 84)\n\t [[Node: Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_2_W/read, _recv_code_in_0)]]\n\nCaused by op 'Gather', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/cec/clgen/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-9f4b6bf73378>\", line 33, in <module>\n    r = load_and_test(m, platform, source, split=split, seed=seed)\n  File \"/home/cec/phd/lab/clgen/classification/lib/preamble.py\", line 473, in load_and_test\n    model = load_fn(inpath)\n  File \"<ipython-input-4-618d0ef7efac>\", line 56, in load_fn\n    return load_model(inpath)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/models.py\", line 142, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/models.py\", line 193, in model_from_config\n    return layer_from_config(config, custom_objects=custom_objects)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/utils/layer_utils.py\", line 40, in layer_from_config\n    custom_objects=custom_objects)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 2582, in from_config\n    process_layer(layer_data)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 2577, in process_layer\n    layer(input_tensors[0])\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 128, in call\n    out = K.gather(W, x)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 960, in gather\n    return tf.gather(reference, indices)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1293, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[1,0] = 84 is not in [0, 84)\n\t [[Node: Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_2_W/read, _recv_code_in_0)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[1,0] = 84 is not in [0, 84)\n\t [[Node: Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_2_W/read, _recv_code_in_0)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-9f4b6bf73378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplatform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acc_perc\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/phd/lab/clgen/classification/lib/preamble.py\u001b[0m in \u001b[0;36mload_and_test\u001b[0;34m(model_desc, platform, source, split, atomizer, maxlen, seed)\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;31m# test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m     \u001b[0mtest_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-618d0ef7efac>\u001b[0m in \u001b[0;36mtest_fn\u001b[0;34m(model, test, seed, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;34m\"\"\" make predictions for test data \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         predictions = np.array(model.predict({\"data_in\": test[\"x_2\"], \"code_in\": test[\"x_seq\"]},\n\u001b[0;32m---> 46\u001b[0;31m                                              batch_size=BATCH_SIZE, verbose=0))\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mclipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mclipped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1272\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[1,0] = 84 is not in [0, 84)\n\t [[Node: Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_2_W/read, _recv_code_in_0)]]\n\nCaused by op 'Gather', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/cec/clgen/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-42-9f4b6bf73378>\", line 33, in <module>\n    r = load_and_test(m, platform, source, split=split, seed=seed)\n  File \"/home/cec/phd/lab/clgen/classification/lib/preamble.py\", line 473, in load_and_test\n    model = load_fn(inpath)\n  File \"<ipython-input-4-618d0ef7efac>\", line 56, in load_fn\n    return load_model(inpath)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/models.py\", line 142, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/models.py\", line 193, in model_from_config\n    return layer_from_config(config, custom_objects=custom_objects)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/utils/layer_utils.py\", line 40, in layer_from_config\n    custom_objects=custom_objects)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 2582, in from_config\n    process_layer(layer_data)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 2577, in process_layer\n    layer(input_tensors[0])\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 572, in __call__\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 635, in add_inbound_node\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/engine/topology.py\", line 166, in create_node\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/layers/embeddings.py\", line 128, in call\n    out = K.gather(W, x)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\", line 960, in gather\n    return tf.gather(reference, indices)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 1293, in gather\n    validate_indices=validate_indices, name=name)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): indices[1,0] = 84 is not in [0, 84)\n\t [[Node: Gather = Gather[Tindices=DT_INT32, Tparams=DT_FLOAT, validate_indices=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding_2_W/read, _recv_code_in_0)]]\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "from itertools import product\n",
    "\n",
    "seeds = list(range(204, 214))\n",
    "source = \"B\"\n",
    "split = (.6, .2, .2)\n",
    "\n",
    "data_in = []\n",
    "\n",
    "def source2str(s):\n",
    "    if s == \"B\":\n",
    "        return \"Benchmarks\"\n",
    "    elif s == \"S\":\n",
    "        return \"CLgen\"\n",
    "    elif s == \"BS\":\n",
    "        return \"w. CLgen\"\n",
    "    else:\n",
    "        raise Exception\n",
    "        \n",
    "def model2str(m):\n",
    "    if m == \"zero_r\":\n",
    "        return \"Zero-R\"\n",
    "    elif m == \"cgo13\":\n",
    "        return \"Grewe et al.\"\n",
    "    else:\n",
    "        return m.title()\n",
    "\n",
    "for model, platform in product([\"zero_r\", \"cgo13\", \"harry\", \"sally\"], [\"amd\", \"nvidia\"]):\n",
    "    for seed in seeds:\n",
    "        m = globals().get(model)()\n",
    "        model_path = get_model_path(m, platform, source, split, seed=seed)\n",
    "        if fs.exists(model_path):\n",
    "            r = load_and_test(m, platform, source, split=split, seed=seed)\n",
    "            r[\"acc_perc\"] = r[\"accuracy\"] * 100\n",
    "            r[\"model\"] = model\n",
    "            r[\"model_name\"] = model.upper()\n",
    "            r[\"platform\"] = platform\n",
    "            r[\"platform_name\"] = platform.upper()\n",
    "            r[\"oracle_perc\"] = r[\"speedup_geo\"] * 100\n",
    "            r[\"source\"] = source\n",
    "            r[\"source_name\"] = source2str(source)\n",
    "            r[\"split\"] = split\n",
    "            data_in.append(r)\n",
    "        else:\n",
    "            print(\"warning: no model file\", model_path, file=sys.stderr)\n",
    "\n",
    "data = pd.DataFrame(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc_perc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>model</th>\n",
       "      <th>model_name</th>\n",
       "      <th>oracle_perc</th>\n",
       "      <th>platform</th>\n",
       "      <th>platform_name</th>\n",
       "      <th>predictions</th>\n",
       "      <th>source</th>\n",
       "      <th>source_name</th>\n",
       "      <th>speedup_avg</th>\n",
       "      <th>speedup_geo</th>\n",
       "      <th>speedup_max</th>\n",
       "      <th>speedup_min</th>\n",
       "      <th>speedups</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54.482759</td>\n",
       "      <td>0.544828</td>\n",
       "      <td>[[79, 0], [66, 0]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>56.544052</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.746740</td>\n",
       "      <td>0.565441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>[0.438757511608, 1.0, 0.451091432397, 1.0, 0.7...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.031250</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>[[73, 0], [55, 0]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>56.914371</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.748669</td>\n",
       "      <td>0.569144</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014138</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58.778626</td>\n",
       "      <td>0.587786</td>\n",
       "      <td>[[77, 0], [54, 0]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>63.603957</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.783781</td>\n",
       "      <td>0.636040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007296</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.440882331158, 1.0, 0.69...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.240310</td>\n",
       "      <td>0.612403</td>\n",
       "      <td>[[79, 0], [50, 0]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>58.382670</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.765481</td>\n",
       "      <td>0.583827</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>[0.171586464762, 0.0655075026966, 1.0, 0.25843...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.870504</td>\n",
       "      <td>0.618705</td>\n",
       "      <td>[[86, 0], [53, 0]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>58.614095</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.761753</td>\n",
       "      <td>0.586141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75107281...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55.862069</td>\n",
       "      <td>0.558621</td>\n",
       "      <td>[[81, 0], [64, 0]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>57.326877</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.748299</td>\n",
       "      <td>0.573269</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.195373591753, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>57.462687</td>\n",
       "      <td>0.574627</td>\n",
       "      <td>[[77, 0], [57, 0]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>55.149443</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.737110</td>\n",
       "      <td>0.551494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>[0.171586464762, 0.0655075026966, 0.4510914323...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>61.904762</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>[[91, 0], [56, 0]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>63.479349</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.781411</td>\n",
       "      <td>0.634793</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028487</td>\n",
       "      <td>[0.438757511608, 1.0, 0.451091432397, 1.0, 1.0...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>[[93, 0], [57, 0]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>60.418912</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.777994</td>\n",
       "      <td>0.604189</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.014138</td>\n",
       "      <td>[1.0, 1.0, 0.195373591753, 0.137392764843, 1.0...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>58.593750</td>\n",
       "      <td>0.585938</td>\n",
       "      <td>[[75, 0], [53, 0]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>62.313701</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.777218</td>\n",
       "      <td>0.623137</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>[1.0, 0.451091432397, 1.0, 1.0, 1.0, 1.0, 0.88...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>61.379310</td>\n",
       "      <td>0.613793</td>\n",
       "      <td>[[0, 56], [0, 89]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>77.467854</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.833625</td>\n",
       "      <td>0.774679</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.213693</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.468750723516, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53.125000</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>[[0, 60], [0, 68]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>71.825041</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.786116</td>\n",
       "      <td>0.718250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.188012</td>\n",
       "      <td>[1.0, 0.188011919019, 1.0, 0.807575924595, 0.2...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>55.725191</td>\n",
       "      <td>0.557252</td>\n",
       "      <td>[[0, 58], [0, 73]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>73.453475</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.799475</td>\n",
       "      <td>0.734535</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.230035</td>\n",
       "      <td>[0.770630015681, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>58.914729</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>[[0, 53], [0, 76]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>73.530083</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.802582</td>\n",
       "      <td>0.735301</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133117</td>\n",
       "      <td>[1.0, 1.0, 0.488564448128, 1.0, 1.0, 0.6407695...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58.992806</td>\n",
       "      <td>0.589928</td>\n",
       "      <td>[[0, 57], [0, 82]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>80.394244</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.850805</td>\n",
       "      <td>0.803942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.133117</td>\n",
       "      <td>[1.0, 1.0, 0.468750723516, 1.0, 0.830912303924...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>[[0, 58], [0, 87]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>76.965188</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.826459</td>\n",
       "      <td>0.769652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.131774</td>\n",
       "      <td>[0.188011919019, 0.488564448128, 1.0, 1.0, 1.0...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>61.194030</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>[[0, 52], [0, 82]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>80.439242</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.851319</td>\n",
       "      <td>0.804392</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.217894</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>57.142857</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>[[0, 63], [0, 84]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>73.709709</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.808168</td>\n",
       "      <td>0.737097</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.135809</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.188011919019, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>[[0, 69], [0, 81]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>74.806222</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.806580</td>\n",
       "      <td>0.748062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.213693</td>\n",
       "      <td>[1.0, 0.224207485771, 1.0, 1.0, 1.0, 1.0, 0.64...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>57.812500</td>\n",
       "      <td>0.578125</td>\n",
       "      <td>[[0, 54], [0, 74]]</td>\n",
       "      <td>zero_r</td>\n",
       "      <td>ZERO_R</td>\n",
       "      <td>74.282636</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.809949</td>\n",
       "      <td>0.742826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.224207</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.640769572226, 1.0,...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>82.068966</td>\n",
       "      <td>0.820690</td>\n",
       "      <td>[[70, 9], [17, 49]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>55.554543</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.721234</td>\n",
       "      <td>0.555545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>[1.0, 1.0, 0.451091432397, 1.0, 1.0, 0.1316795...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>76.562500</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>[[56, 17], [13, 42]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>49.987366</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.681538</td>\n",
       "      <td>0.499874</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>[0.323580224223, 1.0, 0.214895836815, 0.536177...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>83.206107</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>[[71, 6], [16, 38]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>53.722326</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.713134</td>\n",
       "      <td>0.537223</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>[1.0, 1.0, 0.571092618539, 1.0, 0.440882331158...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>83.720930</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>[[69, 10], [11, 39]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>53.220060</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.722085</td>\n",
       "      <td>0.532201</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>[0.171586464762, 1.0, 0.281343001688, 0.258430...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>76.978417</td>\n",
       "      <td>0.769784</td>\n",
       "      <td>[[67, 19], [13, 40]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>46.266035</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.657697</td>\n",
       "      <td>0.462660</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 0.267487411524, 0.4823544...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>81.379310</td>\n",
       "      <td>0.813793</td>\n",
       "      <td>[[71, 10], [17, 47]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>46.423658</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.665865</td>\n",
       "      <td>0.464237</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>[1.0, 1.0, 0.24786721565, 1.0, 0.181449500077,...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>77.611940</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>[[63, 14], [16, 41]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>50.798474</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.688783</td>\n",
       "      <td>0.507985</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008380</td>\n",
       "      <td>[0.171586464762, 0.0655075026966, 1.0, 0.15516...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>77.551020</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>[[71, 20], [13, 43]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>47.502745</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.663604</td>\n",
       "      <td>0.475027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>[1.0, 1.0, 0.451091432397, 0.09906937338, 0.15...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>80.666667</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>[[79, 14], [15, 42]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>50.626798</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.701294</td>\n",
       "      <td>0.506268</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008067</td>\n",
       "      <td>[1.0, 0.0714775564125, 0.195373591753, 0.13739...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>84.375000</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>[[65, 10], [10, 43]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>52.052469</td>\n",
       "      <td>amd</td>\n",
       "      <td>AMD</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.700169</td>\n",
       "      <td>0.520525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008888</td>\n",
       "      <td>[1.0, 0.451091432397, 1.0, 1.0, 0.24786721565,...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>83.448276</td>\n",
       "      <td>0.834483</td>\n",
       "      <td>[[48, 8], [16, 73]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>58.004174</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.743574</td>\n",
       "      <td>0.580042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>[1.0, 1.0, 0.32878717957, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>81.250000</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>[[49, 11], [13, 55]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>56.478166</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.713703</td>\n",
       "      <td>0.564782</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>[1.0, 1.0, 1.0, 0.807575924595, 0.224207485771...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>74.809160</td>\n",
       "      <td>0.748092</td>\n",
       "      <td>[[43, 15], [18, 55]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>58.180254</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.731119</td>\n",
       "      <td>0.581803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>[0.770630015681, 1.0, 1.0, 0.468999140808, 0.1...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>85.271318</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>[[41, 12], [7, 69]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>54.484705</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.704558</td>\n",
       "      <td>0.544847</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>[1.0, 1.0, 0.488564448128, 0.686462767572, 1.0...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>82.733813</td>\n",
       "      <td>0.827338</td>\n",
       "      <td>[[46, 11], [13, 69]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>56.411379</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.736567</td>\n",
       "      <td>0.564114</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.006965</td>\n",
       "      <td>[0.474282433984, 0.402918546761, 1.0, 1.0, 0.8...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>77.241379</td>\n",
       "      <td>0.772414</td>\n",
       "      <td>[[44, 14], [19, 68]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>64.407698</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.760598</td>\n",
       "      <td>0.644077</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036938</td>\n",
       "      <td>[0.188011919019, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>77.611940</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>[[38, 14], [16, 66]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>62.888956</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.764182</td>\n",
       "      <td>0.628890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036231</td>\n",
       "      <td>[0.0669826756024, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>82.993197</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>[[47, 16], [9, 75]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>66.030287</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.778299</td>\n",
       "      <td>0.660303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.027895</td>\n",
       "      <td>[1.0, 0.474282433984, 1.0, 0.188011919019, 1.0...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>78.666667</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>[[48, 21], [11, 70]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>71.884921</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.823651</td>\n",
       "      <td>0.718849</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010890</td>\n",
       "      <td>[1.0, 0.224207485771, 1.0, 1.0, 0.114906970864...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>72.656250</td>\n",
       "      <td>0.726562</td>\n",
       "      <td>[[40, 14], [21, 53]]</td>\n",
       "      <td>cgo13</td>\n",
       "      <td>CGO13</td>\n",
       "      <td>66.536604</td>\n",
       "      <td>nvidia</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>[0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, ...</td>\n",
       "      <td>B</td>\n",
       "      <td>Benchmarks</td>\n",
       "      <td>0.776268</td>\n",
       "      <td>0.665366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.013950</td>\n",
       "      <td>[0.474282433984, 1.0, 0.477096682384, 1.0, 0.4...</td>\n",
       "      <td>(0.6, 0.2, 0.2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     acc_perc  accuracy      confusion_matrix   model model_name  oracle_perc  \\\n",
       "0   54.482759  0.544828    [[79, 0], [66, 0]]  zero_r     ZERO_R    56.544052   \n",
       "1   57.031250  0.570312    [[73, 0], [55, 0]]  zero_r     ZERO_R    56.914371   \n",
       "2   58.778626  0.587786    [[77, 0], [54, 0]]  zero_r     ZERO_R    63.603957   \n",
       "3   61.240310  0.612403    [[79, 0], [50, 0]]  zero_r     ZERO_R    58.382670   \n",
       "4   61.870504  0.618705    [[86, 0], [53, 0]]  zero_r     ZERO_R    58.614095   \n",
       "5   55.862069  0.558621    [[81, 0], [64, 0]]  zero_r     ZERO_R    57.326877   \n",
       "6   57.462687  0.574627    [[77, 0], [57, 0]]  zero_r     ZERO_R    55.149443   \n",
       "7   61.904762  0.619048    [[91, 0], [56, 0]]  zero_r     ZERO_R    63.479349   \n",
       "8   62.000000  0.620000    [[93, 0], [57, 0]]  zero_r     ZERO_R    60.418912   \n",
       "9   58.593750  0.585938    [[75, 0], [53, 0]]  zero_r     ZERO_R    62.313701   \n",
       "10  61.379310  0.613793    [[0, 56], [0, 89]]  zero_r     ZERO_R    77.467854   \n",
       "11  53.125000  0.531250    [[0, 60], [0, 68]]  zero_r     ZERO_R    71.825041   \n",
       "12  55.725191  0.557252    [[0, 58], [0, 73]]  zero_r     ZERO_R    73.453475   \n",
       "13  58.914729  0.589147    [[0, 53], [0, 76]]  zero_r     ZERO_R    73.530083   \n",
       "14  58.992806  0.589928    [[0, 57], [0, 82]]  zero_r     ZERO_R    80.394244   \n",
       "15  60.000000  0.600000    [[0, 58], [0, 87]]  zero_r     ZERO_R    76.965188   \n",
       "16  61.194030  0.611940    [[0, 52], [0, 82]]  zero_r     ZERO_R    80.439242   \n",
       "17  57.142857  0.571429    [[0, 63], [0, 84]]  zero_r     ZERO_R    73.709709   \n",
       "18  54.000000  0.540000    [[0, 69], [0, 81]]  zero_r     ZERO_R    74.806222   \n",
       "19  57.812500  0.578125    [[0, 54], [0, 74]]  zero_r     ZERO_R    74.282636   \n",
       "20  82.068966  0.820690   [[70, 9], [17, 49]]   cgo13      CGO13    55.554543   \n",
       "21  76.562500  0.765625  [[56, 17], [13, 42]]   cgo13      CGO13    49.987366   \n",
       "22  83.206107  0.832061   [[71, 6], [16, 38]]   cgo13      CGO13    53.722326   \n",
       "23  83.720930  0.837209  [[69, 10], [11, 39]]   cgo13      CGO13    53.220060   \n",
       "24  76.978417  0.769784  [[67, 19], [13, 40]]   cgo13      CGO13    46.266035   \n",
       "25  81.379310  0.813793  [[71, 10], [17, 47]]   cgo13      CGO13    46.423658   \n",
       "26  77.611940  0.776119  [[63, 14], [16, 41]]   cgo13      CGO13    50.798474   \n",
       "27  77.551020  0.775510  [[71, 20], [13, 43]]   cgo13      CGO13    47.502745   \n",
       "28  80.666667  0.806667  [[79, 14], [15, 42]]   cgo13      CGO13    50.626798   \n",
       "29  84.375000  0.843750  [[65, 10], [10, 43]]   cgo13      CGO13    52.052469   \n",
       "30  83.448276  0.834483   [[48, 8], [16, 73]]   cgo13      CGO13    58.004174   \n",
       "31  81.250000  0.812500  [[49, 11], [13, 55]]   cgo13      CGO13    56.478166   \n",
       "32  74.809160  0.748092  [[43, 15], [18, 55]]   cgo13      CGO13    58.180254   \n",
       "33  85.271318  0.852713   [[41, 12], [7, 69]]   cgo13      CGO13    54.484705   \n",
       "34  82.733813  0.827338  [[46, 11], [13, 69]]   cgo13      CGO13    56.411379   \n",
       "35  77.241379  0.772414  [[44, 14], [19, 68]]   cgo13      CGO13    64.407698   \n",
       "36  77.611940  0.776119  [[38, 14], [16, 66]]   cgo13      CGO13    62.888956   \n",
       "37  82.993197  0.829932   [[47, 16], [9, 75]]   cgo13      CGO13    66.030287   \n",
       "38  78.666667  0.786667  [[48, 21], [11, 70]]   cgo13      CGO13    71.884921   \n",
       "39  72.656250  0.726562  [[40, 14], [21, 53]]   cgo13      CGO13    66.536604   \n",
       "\n",
       "   platform platform_name                                        predictions  \\\n",
       "0       amd           AMD  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1       amd           AMD  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2       amd           AMD  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3       amd           AMD  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4       amd           AMD  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "5       amd           AMD  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "6       amd           AMD  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "7       amd           AMD  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "8       amd           AMD  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "9       amd           AMD  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "10   nvidia        NVIDIA  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "11   nvidia        NVIDIA  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "12   nvidia        NVIDIA  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "13   nvidia        NVIDIA  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "14   nvidia        NVIDIA  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "15   nvidia        NVIDIA  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "16   nvidia        NVIDIA  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "17   nvidia        NVIDIA  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "18   nvidia        NVIDIA  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "19   nvidia        NVIDIA  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "20      amd           AMD  [1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, ...   \n",
       "21      amd           AMD  [1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, ...   \n",
       "22      amd           AMD  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, ...   \n",
       "23      amd           AMD  [0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, ...   \n",
       "24      amd           AMD  [0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, ...   \n",
       "25      amd           AMD  [0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, ...   \n",
       "26      amd           AMD  [0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, ...   \n",
       "27      amd           AMD  [1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, ...   \n",
       "28      amd           AMD  [0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, ...   \n",
       "29      amd           AMD  [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, ...   \n",
       "30   nvidia        NVIDIA  [1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, ...   \n",
       "31   nvidia        NVIDIA  [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, ...   \n",
       "32   nvidia        NVIDIA  [1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, ...   \n",
       "33   nvidia        NVIDIA  [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "34   nvidia        NVIDIA  [0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, ...   \n",
       "35   nvidia        NVIDIA  [1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, ...   \n",
       "36   nvidia        NVIDIA  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, ...   \n",
       "37   nvidia        NVIDIA  [1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, ...   \n",
       "38   nvidia        NVIDIA  [1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, ...   \n",
       "39   nvidia        NVIDIA  [0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, ...   \n",
       "\n",
       "   source source_name  speedup_avg  speedup_geo  speedup_max  speedup_min  \\\n",
       "0       B  Benchmarks     0.746740     0.565441          1.0     0.006489   \n",
       "1       B  Benchmarks     0.748669     0.569144          1.0     0.014138   \n",
       "2       B  Benchmarks     0.783781     0.636040          1.0     0.007296   \n",
       "3       B  Benchmarks     0.765481     0.583827          1.0     0.006489   \n",
       "4       B  Benchmarks     0.761753     0.586141          1.0     0.006489   \n",
       "5       B  Benchmarks     0.748299     0.573269          1.0     0.006489   \n",
       "6       B  Benchmarks     0.737110     0.551494          1.0     0.028333   \n",
       "7       B  Benchmarks     0.781411     0.634793          1.0     0.028487   \n",
       "8       B  Benchmarks     0.777994     0.604189          1.0     0.014138   \n",
       "9       B  Benchmarks     0.777218     0.623137          1.0     0.028333   \n",
       "10      B  Benchmarks     0.833625     0.774679          1.0     0.213693   \n",
       "11      B  Benchmarks     0.786116     0.718250          1.0     0.188012   \n",
       "12      B  Benchmarks     0.799475     0.734535          1.0     0.230035   \n",
       "13      B  Benchmarks     0.802582     0.735301          1.0     0.133117   \n",
       "14      B  Benchmarks     0.850805     0.803942          1.0     0.133117   \n",
       "15      B  Benchmarks     0.826459     0.769652          1.0     0.131774   \n",
       "16      B  Benchmarks     0.851319     0.804392          1.0     0.217894   \n",
       "17      B  Benchmarks     0.808168     0.737097          1.0     0.135809   \n",
       "18      B  Benchmarks     0.806580     0.748062          1.0     0.213693   \n",
       "19      B  Benchmarks     0.809949     0.742826          1.0     0.224207   \n",
       "20      B  Benchmarks     0.721234     0.555545          1.0     0.009559   \n",
       "21      B  Benchmarks     0.681538     0.499874          1.0     0.007199   \n",
       "22      B  Benchmarks     0.713134     0.537223          1.0     0.008380   \n",
       "23      B  Benchmarks     0.722085     0.532201          1.0     0.006489   \n",
       "24      B  Benchmarks     0.657697     0.462660          1.0     0.006489   \n",
       "25      B  Benchmarks     0.665865     0.464237          1.0     0.006489   \n",
       "26      B  Benchmarks     0.688783     0.507985          1.0     0.008380   \n",
       "27      B  Benchmarks     0.663604     0.475027          1.0     0.007370   \n",
       "28      B  Benchmarks     0.701294     0.506268          1.0     0.008067   \n",
       "29      B  Benchmarks     0.700169     0.520525          1.0     0.008888   \n",
       "30      B  Benchmarks     0.743574     0.580042          1.0     0.010616   \n",
       "31      B  Benchmarks     0.713703     0.564782          1.0     0.010616   \n",
       "32      B  Benchmarks     0.731119     0.581803          1.0     0.006739   \n",
       "33      B  Benchmarks     0.704558     0.544847          1.0     0.006739   \n",
       "34      B  Benchmarks     0.736567     0.564114          1.0     0.006965   \n",
       "35      B  Benchmarks     0.760598     0.644077          1.0     0.036938   \n",
       "36      B  Benchmarks     0.764182     0.628890          1.0     0.036231   \n",
       "37      B  Benchmarks     0.778299     0.660303          1.0     0.027895   \n",
       "38      B  Benchmarks     0.823651     0.718849          1.0     0.010890   \n",
       "39      B  Benchmarks     0.776268     0.665366          1.0     0.013950   \n",
       "\n",
       "                                             speedups            split  \n",
       "0   [0.438757511608, 1.0, 0.451091432397, 1.0, 0.7...  (0.6, 0.2, 0.2)  \n",
       "1   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  (0.6, 0.2, 0.2)  \n",
       "2   [1.0, 1.0, 1.0, 1.0, 0.440882331158, 1.0, 0.69...  (0.6, 0.2, 0.2)  \n",
       "3   [0.171586464762, 0.0655075026966, 1.0, 0.25843...  (0.6, 0.2, 0.2)  \n",
       "4   [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75107281...  (0.6, 0.2, 0.2)  \n",
       "5   [1.0, 1.0, 1.0, 0.195373591753, 1.0, 1.0, 1.0,...  (0.6, 0.2, 0.2)  \n",
       "6   [0.171586464762, 0.0655075026966, 0.4510914323...  (0.6, 0.2, 0.2)  \n",
       "7   [0.438757511608, 1.0, 0.451091432397, 1.0, 1.0...  (0.6, 0.2, 0.2)  \n",
       "8   [1.0, 1.0, 0.195373591753, 0.137392764843, 1.0...  (0.6, 0.2, 0.2)  \n",
       "9   [1.0, 0.451091432397, 1.0, 1.0, 1.0, 1.0, 0.88...  (0.6, 0.2, 0.2)  \n",
       "10  [1.0, 1.0, 1.0, 0.468750723516, 1.0, 1.0, 1.0,...  (0.6, 0.2, 0.2)  \n",
       "11  [1.0, 0.188011919019, 1.0, 0.807575924595, 0.2...  (0.6, 0.2, 0.2)  \n",
       "12  [0.770630015681, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  (0.6, 0.2, 0.2)  \n",
       "13  [1.0, 1.0, 0.488564448128, 1.0, 1.0, 0.6407695...  (0.6, 0.2, 0.2)  \n",
       "14  [1.0, 1.0, 0.468750723516, 1.0, 0.830912303924...  (0.6, 0.2, 0.2)  \n",
       "15  [0.188011919019, 0.488564448128, 1.0, 1.0, 1.0...  (0.6, 0.2, 0.2)  \n",
       "16  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  (0.6, 0.2, 0.2)  \n",
       "17  [1.0, 1.0, 1.0, 0.188011919019, 1.0, 1.0, 1.0,...  (0.6, 0.2, 0.2)  \n",
       "18  [1.0, 0.224207485771, 1.0, 1.0, 1.0, 1.0, 0.64...  (0.6, 0.2, 0.2)  \n",
       "19  [1.0, 1.0, 1.0, 1.0, 1.0, 0.640769572226, 1.0,...  (0.6, 0.2, 0.2)  \n",
       "20  [1.0, 1.0, 0.451091432397, 1.0, 1.0, 0.1316795...  (0.6, 0.2, 0.2)  \n",
       "21  [0.323580224223, 1.0, 0.214895836815, 0.536177...  (0.6, 0.2, 0.2)  \n",
       "22  [1.0, 1.0, 0.571092618539, 1.0, 0.440882331158...  (0.6, 0.2, 0.2)  \n",
       "23  [0.171586464762, 1.0, 0.281343001688, 0.258430...  (0.6, 0.2, 0.2)  \n",
       "24  [1.0, 1.0, 1.0, 1.0, 0.267487411524, 0.4823544...  (0.6, 0.2, 0.2)  \n",
       "25  [1.0, 1.0, 0.24786721565, 1.0, 0.181449500077,...  (0.6, 0.2, 0.2)  \n",
       "26  [0.171586464762, 0.0655075026966, 1.0, 0.15516...  (0.6, 0.2, 0.2)  \n",
       "27  [1.0, 1.0, 0.451091432397, 0.09906937338, 0.15...  (0.6, 0.2, 0.2)  \n",
       "28  [1.0, 0.0714775564125, 0.195373591753, 0.13739...  (0.6, 0.2, 0.2)  \n",
       "29  [1.0, 0.451091432397, 1.0, 1.0, 0.24786721565,...  (0.6, 0.2, 0.2)  \n",
       "30  [1.0, 1.0, 0.32878717957, 1.0, 1.0, 1.0, 1.0, ...  (0.6, 0.2, 0.2)  \n",
       "31  [1.0, 1.0, 1.0, 0.807575924595, 0.224207485771...  (0.6, 0.2, 0.2)  \n",
       "32  [0.770630015681, 1.0, 1.0, 0.468999140808, 0.1...  (0.6, 0.2, 0.2)  \n",
       "33  [1.0, 1.0, 0.488564448128, 0.686462767572, 1.0...  (0.6, 0.2, 0.2)  \n",
       "34  [0.474282433984, 0.402918546761, 1.0, 1.0, 0.8...  (0.6, 0.2, 0.2)  \n",
       "35  [0.188011919019, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  (0.6, 0.2, 0.2)  \n",
       "36  [0.0669826756024, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0...  (0.6, 0.2, 0.2)  \n",
       "37  [1.0, 0.474282433984, 1.0, 0.188011919019, 1.0...  (0.6, 0.2, 0.2)  \n",
       "38  [1.0, 0.224207485771, 1.0, 1.0, 0.114906970864...  (0.6, 0.2, 0.2)  \n",
       "39  [0.474282433984, 1.0, 0.477096682384, 1.0, 0.4...  (0.6, 0.2, 0.2)  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAAF+CAYAAAAlVjPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRETkxtjUERERERERubH/AWOeg4+Y//TQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0ae245e978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, platform in enumerate([\"AMD\", \"NVIDIA\"]):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    ax = sns.barplot(x=\"model_name\", y=\"acc_perc\", hue=\"source_name\",\n",
    "                    data=data[data[\"platform_name\"] == platform],\n",
    "                    ci=99, errwidth=2, capsize=.2)\n",
    "    ax.get_legend().set_title(\"\")  # no legend title\n",
    "    plt.ylim((0, 100))\n",
    "    plt.title(\"{platform} Platform\".format(platform=platform.upper()))\n",
    "    plt.ylabel(\"Accuracy (%)\")\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "viz.finalise(figsize=(9,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3UAAAF+CAYAAAAlVjPKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngIkR6gAAAADAxAh1AAAAAGBi/wc/cmX+sG8rQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0ae2642208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, platform in enumerate([\"AMD\", \"NVIDIA\"]):\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    ax = sns.barplot(x=\"model_name\", y=\"oracle_perc\", hue=\"source_name\",\n",
    "                     data=data[data[\"platform_name\"] == platform],\n",
    "                     ci=99, errwidth=2, capsize=.2)\n",
    "    ax.get_legend().set_title(\"\")  # no legend title\n",
    "    plt.ylim((0, 100))\n",
    "    plt.title(\"{platform} Platform\".format(platform=platform.upper()))\n",
    "    plt.ylabel(\"Performance (% oracle)\")\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "viz.finalise(figsize=(9,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLgen",
   "language": "python",
   "name": "clgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
