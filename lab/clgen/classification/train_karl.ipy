%run lib/preamble.py

def karl():
    BATCH_SIZE = 64
    EMBEDDING_VECTOR_LEN = 64

    def create_model(*args, data_desc=None, **kwargs):
        """ instantiate a model """
        atomizer = data_desc["atomizer"]
        seq_length = data_desc["seq_length"]
        vocab_size = atomizer.vocab_size + 1

        data_in = Input(shape=(2,), name="data_in")

        code_in = Input(shape=(seq_length,), dtype="int32", name="code_in")
        right = Embedding(output_dim=EMBEDDING_VECTOR_LEN, input_dim=vocab_size, input_length=seq_length)(code_in)
        right = LSTM(16, consume_less="mem")(right)

        aux_out = Dense(2, activation="sigmoid", name="aux_out")(right)

        x = merge([data_in, right], mode="concat")
        x = BatchNormalization(name="norm")(x)
        x = Dense(18, activation="relu")(x)
        out = Dense(2, activation="sigmoid", name="out")(x)

        model = Model(input=[data_in, code_in], output=[out, aux_out])
        model.compile(optimizer="adam",
                      loss={"out": "categorical_crossentropy", "aux_out": "categorical_crossentropy"},
                      loss_weights={"out": 1., "aux_out": .2},
                      metrics=['accuracy'])
        return model

    def train_fn(model, train, *args, validation=None, **kwargs):
        """ train a model """
        model.fit({"data_in": train["x_2"], "code_in": train["x_seq"]},
                  {"out": train["y_2"], "aux_out": train["y_2"]},
                  nb_epoch=50,
                  batch_size=BATCH_SIZE,
                  validation_data=({"data_in": validation["x_2"], "code_in": validation["x_seq"]},
                                   {"out": validation["y_2"], "aux_out": validation["y_2"]}),
                  verbose=1,
                  shuffle=True)

    def test_fn(model, test, seed, *args, **kwargs):
        """ make predictions for test data """
        predictions = np.array(model.predict({"data_in": test["x_2"], "code_in": test["x_seq"]},
                                             batch_size=BATCH_SIZE, verbose=0))
        clipped = [np.argmax(x) for x in predictions[0]]
        return clipped

    def save_fn(outpath, model):
        """ save a trained model """
        model.save(outpath)

    def load_fn(inpath):
        """ load a trained model """
        return load_model(inpath)

    return {
        "name": "karl",
        "create_model": create_model,
        "train_fn": train_fn,
        "test_fn": test_fn,
        "save_fn": save_fn,
        "load_fn": load_fn
    }

for seed in range(204, 214):
    # train_and_save(karl(), "amd", "B", split=(.6, .2, .2), atomizer="CharacterAtomizer", maxlen=1024, seed=seed)
    train_and_save(karl(), "amd", "B", split=(.6, .2, .2), atomizer="GreedyAtomizer", maxlen=1024, seed=seed)
    # train_and_save(karl(), "nvidia", "B", split=(.6, .2, .2), atomizer="CharacterAtomizer", maxlen=1024, seed=seed)
    train_and_save(karl(), "nvidia", "B", split=(.6, .2, .2), atomizer="GreedyAtomizer", maxlen=1024, seed=seed)
