%run lib/preamble.py

def sally():
    batch_size = 64

    def create_model(*args, data_desc=None, **kwargs):
        """ instantiate a model """
        atomizer = data_desc["atomizer"]
        seq_length = data_desc["seq_length"]

        embedding_vector_length = 64
        vocab_size = atomizer.vocab_size + 1

        dyn_inputs = Input(shape=(2,), name="data_in")
        left = BatchNormalization(name="dynprop_norm")(dyn_inputs)

        seq_inputs = Input(shape=(seq_length,), dtype="int32", name="code_in")
        right = Embedding(output_dim=embedding_vector_length, input_dim=vocab_size, input_length=seq_length)(seq_inputs)
        right = LSTM(32, consume_less="mem", return_sequences=True)(right)
        right = LSTM(32, consume_less="mem")(right)
        right = BatchNormalization(input_shape=(32,), name="lstm_norm")(right)

        aux_out = Dense(2, activation="sigmoid", name="aux_out")(right)

        x = merge([left, right], mode="concat")
        x = Dense(34, activation="relu")(x)
        x = Dense(34, activation="relu")(x)
        out = Dense(2, activation="sigmoid", name="out")(x)

        model = Model(input=[dyn_inputs, seq_inputs], output=[out, aux_out])
        model.compile(optimizer="adam",
                      loss={"out": "categorical_crossentropy", "aux_out": "categorical_crossentropy"},
                      loss_weights={"out": 1., "aux_out": .2},
                      metrics=['accuracy'])
        return model

    def train_fn(model, train, *args, validation=None, **kwargs):
        """ train a model """
        model.fit({"data_in": train["x_2"], "code_in": train["x_seq"]},
                  {"out": train["y_2"], "aux_out": train["y_2"]},
                  nb_epoch=50,
                  batch_size=batch_size,
                  validation_data=({"data_in": validation["x_2"], "code_in": validation["x_seq"]},
                                   {"out": validation["y_2"], "aux_out": validation["y_2"]}),
                  verbose=1,
                  shuffle=True)

    def test_fn(model, test, seed, *args, **kwargs):
        """ make predictions for test data """
        predictions = np.array(model.predict({"data_in": test["x_2"], "code_in": test["x_seq"]},
                                             batch_size=batch_size, verbose=0))
        clipped = [np.argmax(x) for x in predictions[0]]
        return clipped

    def save_fn(outpath, model):
        """ save a trained model """
        model.save(outpath)

    def load_fn(inpath):
        """ load a trained model """
        return load_model(inpath)

    return {
        "name": "sally",
        "create_model": create_model,
        "train_fn": train_fn,
        "test_fn": test_fn,
        "save_fn": save_fn,
        "load_fn": load_fn
    }

for seed in range(204, 214):
    train_and_save(sally(), "amd", "B", split=(.6, .2, .2), atomizer=CharacterAtomizer, maxlen=1024, seed=seed)
    train_and_save(sally(), "amd", "B", split=(.6, .2, .2), atomizer=CharacterAtomizer, maxlen=1024, seed=seed)

    train_and_save(sally(), "nvidia", "B", split=(.6, .2, .2), atomizer=GreedyAtomizer, maxlen=1024, seed=seed)
    train_and_save(sally(), "nvidia", "B", split=(.6, .2, .2), atomizer=GreedyAtomizer, maxlen=1024, seed=seed)
