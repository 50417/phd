{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# preamble\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from labm8 import fs\n",
    "from labm8 import viz\n",
    "\n",
    "import clgen\n",
    "from clgen.atomizer import CharacterAtomizer\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Merge, LSTM, Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods for wrangling data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(D):\n",
    "    return np.array([\n",
    "        D[\"comp\"].values,\n",
    "        D[\"rational\"].values,\n",
    "        D[\"mem\"].values,\n",
    "        D[\"localmem\"].values,\n",
    "        D[\"coalesced\"].values,\n",
    "        D[\"transfer\"].values,\n",
    "        D[\"wgsize\"].values,\n",
    "        (D[\"transfer\"].values / (D[\"comp\"].values + D[\"mem\"].values)),  # F1\n",
    "        (D[\"coalesced\"].values / D[\"mem\"].values),  # F2\n",
    "        ((D[\"localmem\"].values / D[\"mem\"].values) * D[\"wgsize\"].values),  # F3\n",
    "        (D[\"comp\"].values / D[\"mem\"].values),  # F4\n",
    "    ]).T\n",
    "\n",
    "\n",
    "def get_sequences(D, maxlen):\n",
    "    for row in D[\"seq\"].values:\n",
    "        assert(len(row) == maxlen)\n",
    "    data = np.array(D[\"seq\"].values)\n",
    "    data.resize((len(D), maxlen))\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_labels(D):\n",
    "    \"\"\" cpu/gpu to int \"\"\"\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(D[\"oracle\"].values)\n",
    "    return encoder.transform(D[\"oracle\"].values)\n",
    "\n",
    "\n",
    "def get_train_validation_test_splits(D, split=(.6, .2, .2), seed=1):\n",
    "    \"\"\" split dataframe into 3 frames for training, validation, and testing \"\"\"\n",
    "    assert(sum(split) == 1.0)\n",
    "    train_split, validation_split, test_split = split\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    train_msk = np.random.rand(len(D)) < train_split\n",
    "    \n",
    "    train = D[train_msk]\n",
    "    other = D[~train_msk]\n",
    "    \n",
    "    test_msk = np.random.rand(len(other)) < split[2] / sum(split[1:])\n",
    "    test = other[test_msk]\n",
    "    validation = other[~test_msk]\n",
    " \n",
    "    np.random.seed()  # re-seed RNG\n",
    "    return train, validation, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>benchmark</th>\n",
       "      <th>dataset</th>\n",
       "      <th>comp</th>\n",
       "      <th>rational</th>\n",
       "      <th>mem</th>\n",
       "      <th>localmem</th>\n",
       "      <th>coalesced</th>\n",
       "      <th>atomic</th>\n",
       "      <th>transfer</th>\n",
       "      <th>wgsize</th>\n",
       "      <th>...</th>\n",
       "      <th>speedup</th>\n",
       "      <th>penalty</th>\n",
       "      <th>runtime_cpu</th>\n",
       "      <th>ci_cpu</th>\n",
       "      <th>ci_mean_cpu</th>\n",
       "      <th>runtime_gpu</th>\n",
       "      <th>ci_gpu</th>\n",
       "      <th>ci_mean_gpu</th>\n",
       "      <th>kernel_nlines</th>\n",
       "      <th>kernel_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>24576</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.059825</td>\n",
       "      <td>0.027666</td>\n",
       "      <td>0.462449</td>\n",
       "      <td>0.017248</td>\n",
       "      <td>0.003733</td>\n",
       "      <td>0.216431</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>1048576</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>25165824</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.35</td>\n",
       "      <td>3.144270</td>\n",
       "      <td>0.301743</td>\n",
       "      <td>0.095966</td>\n",
       "      <td>8.950547</td>\n",
       "      <td>0.010129</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>128</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3072</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.011245</td>\n",
       "      <td>0.007497</td>\n",
       "      <td>0.666696</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>0.003792</td>\n",
       "      <td>0.235586</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>131072</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3145728</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>3.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.339146</td>\n",
       "      <td>0.098638</td>\n",
       "      <td>0.290842</td>\n",
       "      <td>1.063418</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>16384</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>393216</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.103308</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.022902</td>\n",
       "      <td>0.111744</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.033559</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>2048</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>49152</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>3.77</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.072523</td>\n",
       "      <td>0.039571</td>\n",
       "      <td>0.545634</td>\n",
       "      <td>0.019219</td>\n",
       "      <td>0.004765</td>\n",
       "      <td>0.247932</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>2097152</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>50331648</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>3.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>5.682239</td>\n",
       "      <td>1.689249</td>\n",
       "      <td>0.297286</td>\n",
       "      <td>18.494624</td>\n",
       "      <td>0.106484</td>\n",
       "      <td>0.005758</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>256</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6144</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.014862</td>\n",
       "      <td>0.017560</td>\n",
       "      <td>1.181537</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.257554</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>262144</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6291456</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.713604</td>\n",
       "      <td>0.287843</td>\n",
       "      <td>0.403365</td>\n",
       "      <td>2.103014</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>4096</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>98304</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.049713</td>\n",
       "      <td>0.021731</td>\n",
       "      <td>0.437129</td>\n",
       "      <td>0.021805</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.190369</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>4194304</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>100663296</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.44</td>\n",
       "      <td>0.41</td>\n",
       "      <td>15.178870</td>\n",
       "      <td>1.454770</td>\n",
       "      <td>0.095842</td>\n",
       "      <td>37.009818</td>\n",
       "      <td>0.119273</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>512</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12288</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.026567</td>\n",
       "      <td>0.022454</td>\n",
       "      <td>0.845184</td>\n",
       "      <td>0.016346</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>0.235654</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>524288</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12582912</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.874873</td>\n",
       "      <td>0.351462</td>\n",
       "      <td>0.187459</td>\n",
       "      <td>4.197043</td>\n",
       "      <td>0.000426</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1536</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1.34</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.013172</td>\n",
       "      <td>0.008872</td>\n",
       "      <td>0.673550</td>\n",
       "      <td>0.017613</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.241299</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>65536</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1572864</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.153789</td>\n",
       "      <td>0.050206</td>\n",
       "      <td>0.326460</td>\n",
       "      <td>0.540742</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>005ef03ac277e7418bb806ad623f5066de5031da.cl-A</td>\n",
       "      <td>8192</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>196608</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.091562</td>\n",
       "      <td>0.016925</td>\n",
       "      <td>0.184847</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.076462</td>\n",
       "      <td>8</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>1024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>24576</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>3.95</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.067187</td>\n",
       "      <td>0.021217</td>\n",
       "      <td>0.315790</td>\n",
       "      <td>0.017011</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.186056</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>1048576</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>25165824</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.04</td>\n",
       "      <td>0.49</td>\n",
       "      <td>4.447553</td>\n",
       "      <td>0.494314</td>\n",
       "      <td>0.111143</td>\n",
       "      <td>9.061094</td>\n",
       "      <td>0.013210</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3072</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.012278</td>\n",
       "      <td>0.010781</td>\n",
       "      <td>0.878075</td>\n",
       "      <td>0.014989</td>\n",
       "      <td>0.003044</td>\n",
       "      <td>0.203082</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>131072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3145728</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>4.42</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.240922</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.020347</td>\n",
       "      <td>1.065882</td>\n",
       "      <td>0.001907</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>16384</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>393216</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.094969</td>\n",
       "      <td>0.023943</td>\n",
       "      <td>0.252114</td>\n",
       "      <td>0.111795</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.033937</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>2048</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>49152</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>3.59</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.065777</td>\n",
       "      <td>0.036893</td>\n",
       "      <td>0.560880</td>\n",
       "      <td>0.018317</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.155156</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>2097152</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>50331648</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.46</td>\n",
       "      <td>8.689354</td>\n",
       "      <td>2.972481</td>\n",
       "      <td>0.342083</td>\n",
       "      <td>18.898522</td>\n",
       "      <td>0.651977</td>\n",
       "      <td>0.034499</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6144</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.012990</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.205620</td>\n",
       "      <td>0.015232</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.188353</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>262144</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6291456</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.014953</td>\n",
       "      <td>0.254900</td>\n",
       "      <td>0.251145</td>\n",
       "      <td>2.122406</td>\n",
       "      <td>0.000937</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>4096</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>98304</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.82</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.039641</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.025580</td>\n",
       "      <td>0.021824</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.150797</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>4194304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>100663296</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.39</td>\n",
       "      <td>14.739519</td>\n",
       "      <td>5.189657</td>\n",
       "      <td>0.352091</td>\n",
       "      <td>37.512384</td>\n",
       "      <td>0.482345</td>\n",
       "      <td>0.012858</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12288</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.024584</td>\n",
       "      <td>0.016771</td>\n",
       "      <td>0.682192</td>\n",
       "      <td>0.015309</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>0.201254</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>524288</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12582912</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2.255742</td>\n",
       "      <td>0.500432</td>\n",
       "      <td>0.221848</td>\n",
       "      <td>4.235206</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1536</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>0.002673</td>\n",
       "      <td>0.279369</td>\n",
       "      <td>0.015117</td>\n",
       "      <td>0.002949</td>\n",
       "      <td>0.195078</td>\n",
       "      <td>8</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15889</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3072</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.016370</td>\n",
       "      <td>0.007553</td>\n",
       "      <td>0.461393</td>\n",
       "      <td>0.015430</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.180557</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15890</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>131072</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3145728</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.311014</td>\n",
       "      <td>0.071908</td>\n",
       "      <td>0.231205</td>\n",
       "      <td>1.066246</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15891</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>16384</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>393216</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.114189</td>\n",
       "      <td>0.015375</td>\n",
       "      <td>0.134645</td>\n",
       "      <td>0.111488</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>0.035313</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15892</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>2048</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>49152</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.51</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.044558</td>\n",
       "      <td>0.011303</td>\n",
       "      <td>0.253669</td>\n",
       "      <td>0.017766</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>0.168186</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15893</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>2097152</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>50331648</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.593791</td>\n",
       "      <td>2.660125</td>\n",
       "      <td>0.277276</td>\n",
       "      <td>18.707309</td>\n",
       "      <td>0.010751</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15894</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>256</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6144</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.012627</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.286133</td>\n",
       "      <td>0.015130</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.175677</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15895</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>262144</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6291456</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.37</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.896698</td>\n",
       "      <td>0.684377</td>\n",
       "      <td>0.763219</td>\n",
       "      <td>2.128730</td>\n",
       "      <td>0.001113</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15896</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>98304</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>3.83</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.078725</td>\n",
       "      <td>0.044965</td>\n",
       "      <td>0.571165</td>\n",
       "      <td>0.020570</td>\n",
       "      <td>0.003091</td>\n",
       "      <td>0.150267</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15897</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>4194304</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>100663296</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.34</td>\n",
       "      <td>12.716302</td>\n",
       "      <td>3.232829</td>\n",
       "      <td>0.254227</td>\n",
       "      <td>37.772800</td>\n",
       "      <td>0.310209</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15898</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12288</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.033453</td>\n",
       "      <td>0.021655</td>\n",
       "      <td>0.647326</td>\n",
       "      <td>0.015309</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.208766</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15899</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>524288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12582912</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0.50</td>\n",
       "      <td>2.111466</td>\n",
       "      <td>0.509426</td>\n",
       "      <td>0.241266</td>\n",
       "      <td>4.248058</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15900</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1536</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.021985</td>\n",
       "      <td>0.028733</td>\n",
       "      <td>1.306937</td>\n",
       "      <td>0.015552</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.201389</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15901</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>65536</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1572864</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.183514</td>\n",
       "      <td>0.029063</td>\n",
       "      <td>0.158369</td>\n",
       "      <td>0.541933</td>\n",
       "      <td>0.002750</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15902</th>\n",
       "      <td>a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A</td>\n",
       "      <td>8192</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>196608</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.063499</td>\n",
       "      <td>0.023984</td>\n",
       "      <td>0.377707</td>\n",
       "      <td>0.046630</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>0.056509</td>\n",
       "      <td>8</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15903</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>1024</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>32768</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.050830</td>\n",
       "      <td>0.006814</td>\n",
       "      <td>0.134055</td>\n",
       "      <td>0.018848</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.153544</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15904</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>1048576</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>33554432</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.83</td>\n",
       "      <td>0.35</td>\n",
       "      <td>4.261274</td>\n",
       "      <td>1.679835</td>\n",
       "      <td>0.394210</td>\n",
       "      <td>12.038106</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15905</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>128</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4096</td>\n",
       "      <td>128</td>\n",
       "      <td>...</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.014472</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.210821</td>\n",
       "      <td>0.016762</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.161974</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15906</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>131072</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4194304</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.479261</td>\n",
       "      <td>0.192081</td>\n",
       "      <td>0.400786</td>\n",
       "      <td>1.423091</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15907</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>16384</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>524288</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.111675</td>\n",
       "      <td>0.052032</td>\n",
       "      <td>0.465923</td>\n",
       "      <td>0.145024</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>0.025858</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15908</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>2048</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>65536</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.079199</td>\n",
       "      <td>0.016673</td>\n",
       "      <td>0.210520</td>\n",
       "      <td>0.020320</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.148819</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15909</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>2097152</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>67108864</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.39</td>\n",
       "      <td>9.644468</td>\n",
       "      <td>2.411566</td>\n",
       "      <td>0.250047</td>\n",
       "      <td>24.630560</td>\n",
       "      <td>0.083120</td>\n",
       "      <td>0.003375</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15910</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>256</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8192</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.008730</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.404124</td>\n",
       "      <td>0.017088</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.183052</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15911</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>262144</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8388608</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.011935</td>\n",
       "      <td>0.410509</td>\n",
       "      <td>0.405667</td>\n",
       "      <td>2.830803</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>4096</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>131072</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.102624</td>\n",
       "      <td>0.153334</td>\n",
       "      <td>1.494134</td>\n",
       "      <td>0.023667</td>\n",
       "      <td>0.003586</td>\n",
       "      <td>0.151519</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15913</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>4194304</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>134217728</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.34</td>\n",
       "      <td>16.859569</td>\n",
       "      <td>2.117202</td>\n",
       "      <td>0.125579</td>\n",
       "      <td>50.267021</td>\n",
       "      <td>0.740593</td>\n",
       "      <td>0.014733</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15914</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>512</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>16384</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.018410</td>\n",
       "      <td>0.009306</td>\n",
       "      <td>0.505486</td>\n",
       "      <td>0.017414</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.169691</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15915</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>524288</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>16777216</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.42</td>\n",
       "      <td>2.372446</td>\n",
       "      <td>0.681287</td>\n",
       "      <td>0.287166</td>\n",
       "      <td>5.653888</td>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15916</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2048</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.099202</td>\n",
       "      <td>0.232236</td>\n",
       "      <td>2.341042</td>\n",
       "      <td>0.016806</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15917</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>65536</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2097152</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.269124</td>\n",
       "      <td>0.099806</td>\n",
       "      <td>0.370855</td>\n",
       "      <td>0.720154</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15918</th>\n",
       "      <td>a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A</td>\n",
       "      <td>8192</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>262144</td>\n",
       "      <td>256</td>\n",
       "      <td>...</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.086840</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.095728</td>\n",
       "      <td>0.058579</td>\n",
       "      <td>0.003342</td>\n",
       "      <td>0.057051</td>\n",
       "      <td>8</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15919 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           benchmark  dataset  comp  rational  \\\n",
       "0      005ef03ac277e7418bb806ad623f5066de5031da.cl-A     1024     2         2   \n",
       "1      005ef03ac277e7418bb806ad623f5066de5031da.cl-A  1048576     2         2   \n",
       "2      005ef03ac277e7418bb806ad623f5066de5031da.cl-A      128     2         2   \n",
       "3      005ef03ac277e7418bb806ad623f5066de5031da.cl-A   131072     2         2   \n",
       "4      005ef03ac277e7418bb806ad623f5066de5031da.cl-A    16384     2         2   \n",
       "5      005ef03ac277e7418bb806ad623f5066de5031da.cl-A     2048     2         2   \n",
       "6      005ef03ac277e7418bb806ad623f5066de5031da.cl-A  2097152     2         2   \n",
       "7      005ef03ac277e7418bb806ad623f5066de5031da.cl-A      256     2         2   \n",
       "8      005ef03ac277e7418bb806ad623f5066de5031da.cl-A   262144     2         2   \n",
       "9      005ef03ac277e7418bb806ad623f5066de5031da.cl-A     4096     2         2   \n",
       "10     005ef03ac277e7418bb806ad623f5066de5031da.cl-A  4194304     2         2   \n",
       "11     005ef03ac277e7418bb806ad623f5066de5031da.cl-A      512     2         2   \n",
       "12     005ef03ac277e7418bb806ad623f5066de5031da.cl-A   524288     2         2   \n",
       "13     005ef03ac277e7418bb806ad623f5066de5031da.cl-A       64     2         2   \n",
       "14     005ef03ac277e7418bb806ad623f5066de5031da.cl-A    65536     2         2   \n",
       "15     005ef03ac277e7418bb806ad623f5066de5031da.cl-A     8192     2         2   \n",
       "16     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A     1024     1         1   \n",
       "17     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A  1048576     1         1   \n",
       "18     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A      128     1         1   \n",
       "19     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A   131072     1         1   \n",
       "20     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A    16384     1         1   \n",
       "21     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A     2048     1         1   \n",
       "22     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A  2097152     1         1   \n",
       "23     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A      256     1         1   \n",
       "24     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A   262144     1         1   \n",
       "25     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A     4096     1         1   \n",
       "26     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A  4194304     1         1   \n",
       "27     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A      512     1         1   \n",
       "28     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A   524288     1         1   \n",
       "29     00b2cd9176f8fd8ff41df5853ccc8ba77620d81f.cl-A       64     1         1   \n",
       "...                                              ...      ...   ...       ...   \n",
       "15889  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A      128     0         1   \n",
       "15890  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A   131072     0         1   \n",
       "15891  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A    16384     0         1   \n",
       "15892  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A     2048     0         1   \n",
       "15893  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A  2097152     0         1   \n",
       "15894  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A      256     0         1   \n",
       "15895  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A   262144     0         1   \n",
       "15896  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A     4096     0         1   \n",
       "15897  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A  4194304     0         1   \n",
       "15898  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A      512     0         1   \n",
       "15899  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A   524288     0         1   \n",
       "15900  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A       64     0         1   \n",
       "15901  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A    65536     0         1   \n",
       "15902  a65ec87aaee54b7b387de4a6660ab5738155551a.cl-A     8192     0         1   \n",
       "15903  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A     1024     5         1   \n",
       "15904  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A  1048576     5         1   \n",
       "15905  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A      128     5         1   \n",
       "15906  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A   131072     5         1   \n",
       "15907  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A    16384     5         1   \n",
       "15908  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A     2048     5         1   \n",
       "15909  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A  2097152     5         1   \n",
       "15910  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A      256     5         1   \n",
       "15911  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A   262144     5         1   \n",
       "15912  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A     4096     5         1   \n",
       "15913  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A  4194304     5         1   \n",
       "15914  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A      512     5         1   \n",
       "15915  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A   524288     5         1   \n",
       "15916  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A       64     5         1   \n",
       "15917  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A    65536     5         1   \n",
       "15918  a670e8ff362eaae5eb70bcbaed23cd018fdaeb7b.cl-A     8192     5         1   \n",
       "\n",
       "       mem  localmem  coalesced  atomic   transfer  wgsize     ...       \\\n",
       "0        6         0          5       0      24576     256     ...        \n",
       "1        6         0          5       0   25165824     256     ...        \n",
       "2        6         0          5       0       3072     128     ...        \n",
       "3        6         0          5       0    3145728     256     ...        \n",
       "4        6         0          5       0     393216     256     ...        \n",
       "5        6         0          5       0      49152     256     ...        \n",
       "6        6         0          5       0   50331648     256     ...        \n",
       "7        6         0          5       0       6144     256     ...        \n",
       "8        6         0          5       0    6291456     256     ...        \n",
       "9        6         0          5       0      98304     256     ...        \n",
       "10       6         0          5       0  100663296     256     ...        \n",
       "11       6         0          5       0      12288     256     ...        \n",
       "12       6         0          5       0   12582912     256     ...        \n",
       "13       6         0          5       0       1536      64     ...        \n",
       "14       6         0          5       0    1572864     256     ...        \n",
       "15       6         0          5       0     196608     256     ...        \n",
       "16       5         0          4       0      24576     256     ...        \n",
       "17       5         0          4       0   25165824     256     ...        \n",
       "18       5         0          4       0       3072     128     ...        \n",
       "19       5         0          4       0    3145728     256     ...        \n",
       "20       5         0          4       0     393216     256     ...        \n",
       "21       5         0          4       0      49152     256     ...        \n",
       "22       5         0          4       0   50331648     256     ...        \n",
       "23       5         0          4       0       6144     256     ...        \n",
       "24       5         0          4       0    6291456     256     ...        \n",
       "25       5         0          4       0      98304     256     ...        \n",
       "26       5         0          4       0  100663296     256     ...        \n",
       "27       5         0          4       0      12288     256     ...        \n",
       "28       5         0          4       0   12582912     256     ...        \n",
       "29       5         0          4       0       1536      64     ...        \n",
       "...    ...       ...        ...     ...        ...     ...     ...        \n",
       "15889    3         0          3       0       3072     128     ...        \n",
       "15890    3         0          3       0    3145728     256     ...        \n",
       "15891    3         0          3       0     393216     256     ...        \n",
       "15892    3         0          3       0      49152     256     ...        \n",
       "15893    3         0          3       0   50331648     256     ...        \n",
       "15894    3         0          3       0       6144     256     ...        \n",
       "15895    3         0          3       0    6291456     256     ...        \n",
       "15896    3         0          3       0      98304     256     ...        \n",
       "15897    3         0          3       0  100663296     256     ...        \n",
       "15898    3         0          3       0      12288     256     ...        \n",
       "15899    3         0          3       0   12582912     256     ...        \n",
       "15900    3         0          3       0       1536      64     ...        \n",
       "15901    3         0          3       0    1572864     256     ...        \n",
       "15902    3         0          3       0     196608     256     ...        \n",
       "15903    7         0          6       0      32768     256     ...        \n",
       "15904    7         0          6       0   33554432     256     ...        \n",
       "15905    7         0          6       0       4096     128     ...        \n",
       "15906    7         0          6       0    4194304     256     ...        \n",
       "15907    7         0          6       0     524288     256     ...        \n",
       "15908    7         0          6       0      65536     256     ...        \n",
       "15909    7         0          6       0   67108864     256     ...        \n",
       "15910    7         0          6       0       8192     256     ...        \n",
       "15911    7         0          6       0    8388608     256     ...        \n",
       "15912    7         0          6       0     131072     256     ...        \n",
       "15913    7         0          6       0  134217728     256     ...        \n",
       "15914    7         0          6       0      16384     256     ...        \n",
       "15915    7         0          6       0   16777216     256     ...        \n",
       "15916    7         0          6       0       2048      64     ...        \n",
       "15917    7         0          6       0    2097152     256     ...        \n",
       "15918    7         0          6       0     262144     256     ...        \n",
       "\n",
       "       speedup  penalty  runtime_cpu    ci_cpu ci_mean_cpu  runtime_gpu  \\\n",
       "0         3.47     0.29     0.059825  0.027666    0.462449     0.017248   \n",
       "1         2.85     0.35     3.144270  0.301743    0.095966     8.950547   \n",
       "2         1.43     0.70     0.011245  0.007497    0.666696     0.016096   \n",
       "3         3.14     0.32     0.339146  0.098638    0.290842     1.063418   \n",
       "4         1.08     0.92     0.103308  0.002366    0.022902     0.111744   \n",
       "5         3.77     0.27     0.072523  0.039571    0.545634     0.019219   \n",
       "6         3.25     0.31     5.682239  1.689249    0.297286    18.494624   \n",
       "7         1.08     0.93     0.014862  0.017560    1.181537     0.016051   \n",
       "8         2.95     0.34     0.713604  0.287843    0.403365     2.103014   \n",
       "9         2.28     0.44     0.049713  0.021731    0.437129     0.021805   \n",
       "10        2.44     0.41    15.178870  1.454770    0.095842    37.009818   \n",
       "11        1.63     0.62     0.026567  0.022454    0.845184     0.016346   \n",
       "12        2.24     0.45     1.874873  0.351462    0.187459     4.197043   \n",
       "13        1.34     0.75     0.013172  0.008872    0.673550     0.017613   \n",
       "14        3.52     0.28     0.153789  0.050206    0.326460     0.540742   \n",
       "15        1.94     0.52     0.091562  0.016925    0.184847     0.047200   \n",
       "16        3.95     0.25     0.067187  0.021217    0.315790     0.017011   \n",
       "17        2.04     0.49     4.447553  0.494314    0.111143     9.061094   \n",
       "18        1.22     0.82     0.012278  0.010781    0.878075     0.014989   \n",
       "19        4.42     0.23     0.240922  0.004902    0.020347     1.065882   \n",
       "20        1.18     0.85     0.094969  0.023943    0.252114     0.111795   \n",
       "21        3.59     0.28     0.065777  0.036893    0.560880     0.018317   \n",
       "22        2.17     0.46     8.689354  2.972481    0.342083    18.898522   \n",
       "23        1.17     0.85     0.012990  0.002671    0.205620     0.015232   \n",
       "24        2.09     0.48     1.014953  0.254900    0.251145     2.122406   \n",
       "25        1.82     0.55     0.039641  0.001014    0.025580     0.021824   \n",
       "26        2.55     0.39    14.739519  5.189657    0.352091    37.512384   \n",
       "27        1.61     0.62     0.024584  0.016771    0.682192     0.015309   \n",
       "28        1.88     0.53     2.255742  0.500432    0.221848     4.235206   \n",
       "29        1.58     0.63     0.009568  0.002673    0.279369     0.015117   \n",
       "...        ...      ...          ...       ...         ...          ...   \n",
       "15889     1.06     0.94     0.016370  0.007553    0.461393     0.015430   \n",
       "15890     3.43     0.29     0.311014  0.071908    0.231205     1.066246   \n",
       "15891     1.02     0.98     0.114189  0.015375    0.134645     0.111488   \n",
       "15892     2.51     0.40     0.044558  0.011303    0.253669     0.017766   \n",
       "15893     1.95     0.51     9.593791  2.660125    0.277276    18.707309   \n",
       "15894     1.20     0.83     0.012627  0.003613    0.286133     0.015130   \n",
       "15895     2.37     0.42     0.896698  0.684377    0.763219     2.128730   \n",
       "15896     3.83     0.26     0.078725  0.044965    0.571165     0.020570   \n",
       "15897     2.97     0.34    12.716302  3.232829    0.254227    37.772800   \n",
       "15898     2.19     0.46     0.033453  0.021655    0.647326     0.015309   \n",
       "15899     2.01     0.50     2.111466  0.509426    0.241266     4.248058   \n",
       "15900     1.41     0.71     0.021985  0.028733    1.306937     0.015552   \n",
       "15901     2.95     0.34     0.183514  0.029063    0.158369     0.541933   \n",
       "15902     1.36     0.73     0.063499  0.023984    0.377707     0.046630   \n",
       "15903     2.70     0.37     0.050830  0.006814    0.134055     0.018848   \n",
       "15904     2.83     0.35     4.261274  1.679835    0.394210    12.038106   \n",
       "15905     1.16     0.86     0.014472  0.003051    0.210821     0.016762   \n",
       "15906     2.97     0.34     0.479261  0.192081    0.400786     1.423091   \n",
       "15907     1.30     0.77     0.111675  0.052032    0.465923     0.145024   \n",
       "15908     3.90     0.26     0.079199  0.016673    0.210520     0.020320   \n",
       "15909     2.55     0.39     9.644468  2.411566    0.250047    24.630560   \n",
       "15910     1.96     0.51     0.008730  0.003528    0.404124     0.017088   \n",
       "15911     2.80     0.36     1.011935  0.410509    0.405667     2.830803   \n",
       "15912     4.34     0.23     0.102624  0.153334    1.494134     0.023667   \n",
       "15913     2.98     0.34    16.859569  2.117202    0.125579    50.267021   \n",
       "15914     1.06     0.95     0.018410  0.009306    0.505486     0.017414   \n",
       "15915     2.38     0.42     2.372446  0.681287    0.287166     5.653888   \n",
       "15916     5.90     0.17     0.099202  0.232236    2.341042     0.016806   \n",
       "15917     2.68     0.37     0.269124  0.099806    0.370855     0.720154   \n",
       "15918     1.48     0.67     0.086840  0.008313    0.095728     0.058579   \n",
       "\n",
       "         ci_gpu  ci_mean_gpu  kernel_nlines  kernel_size  \n",
       "0      0.003733     0.216431              8          191  \n",
       "1      0.010129     0.001132              8          191  \n",
       "2      0.003792     0.235586              8          191  \n",
       "3      0.000886     0.000833              8          191  \n",
       "4      0.003750     0.033559              8          191  \n",
       "5      0.004765     0.247932              8          191  \n",
       "6      0.106484     0.005758              8          191  \n",
       "7      0.004134     0.257554              8          191  \n",
       "8      0.000733     0.000349              8          191  \n",
       "9      0.004151     0.190369              8          191  \n",
       "10     0.119273     0.003223              8          191  \n",
       "11     0.003852     0.235654              8          191  \n",
       "12     0.000426     0.000102              8          191  \n",
       "13     0.004250     0.241299              8          191  \n",
       "14     0.003246     0.006003              8          191  \n",
       "15     0.003609     0.076462              8          191  \n",
       "16     0.003165     0.186056              8          173  \n",
       "17     0.013210     0.001458              8          173  \n",
       "18     0.003044     0.203082              8          173  \n",
       "19     0.001907     0.001789              8          173  \n",
       "20     0.003794     0.033937              8          173  \n",
       "21     0.002842     0.155156              8          173  \n",
       "22     0.651977     0.034499              8          173  \n",
       "23     0.002869     0.188353              8          173  \n",
       "24     0.000937     0.000441              8          173  \n",
       "25     0.003291     0.150797              8          173  \n",
       "26     0.482345     0.012858              8          173  \n",
       "27     0.003081     0.201254              8          173  \n",
       "28     0.001434     0.000339              8          173  \n",
       "29     0.002949     0.195078              8          173  \n",
       "...         ...          ...            ...          ...  \n",
       "15889  0.002786     0.180557              8          168  \n",
       "15890  0.001631     0.001530              8          168  \n",
       "15891  0.003937     0.035313              8          168  \n",
       "15892  0.002988     0.168186              8          168  \n",
       "15893  0.010751     0.000575              8          168  \n",
       "15894  0.002658     0.175677              8          168  \n",
       "15895  0.001113     0.000523              8          168  \n",
       "15896  0.003091     0.150267              8          168  \n",
       "15897  0.310209     0.008212              8          168  \n",
       "15898  0.003196     0.208766              8          168  \n",
       "15899  0.000973     0.000229              8          168  \n",
       "15900  0.003132     0.201389              8          168  \n",
       "15901  0.002750     0.005074              8          168  \n",
       "15902  0.002635     0.056509              8          168  \n",
       "15903  0.002894     0.153544              8          222  \n",
       "15904  0.001060     0.000088              8          222  \n",
       "15905  0.002715     0.161974              8          222  \n",
       "15906  0.000471     0.000331              8          222  \n",
       "15907  0.003750     0.025858              8          222  \n",
       "15908  0.003024     0.148819              8          222  \n",
       "15909  0.083120     0.003375              8          222  \n",
       "15910  0.003128     0.183052              8          222  \n",
       "15911  0.001226     0.000433              8          222  \n",
       "15912  0.003586     0.151519              8          222  \n",
       "15913  0.740593     0.014733              8          222  \n",
       "15914  0.002955     0.169691              8          222  \n",
       "15915  0.001324     0.000234              8          222  \n",
       "15916  0.003178     0.189099              8          222  \n",
       "15917  0.002072     0.002877              8          222  \n",
       "15918  0.003342     0.057051              8          222  \n",
       "\n",
       "[15919 rows x 26 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(fs.path(\"~/docs/paper-synthesizing-benchmarks/data/nvidia-clgen.csv\"))\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load source code for kernels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_dir = fs.path(\"~/docs/paper-synthesizing-benchmarks/data/clgen-1000/kernels\")\n",
    "\n",
    "srcs = []\n",
    "\n",
    "for row in dataframe[\"benchmark\"].values:\n",
    "    filename = re.sub(\"-[A-Z]$\", \"\", row)\n",
    "    with open(fs.path(source_dir, filename)) as infile:\n",
    "        src = infile.read()\n",
    "    srcs.append(src)\n",
    "    \n",
    "dataframe[\"src\"] = srcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode and pad sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size 68\n",
      "pad val 69\n",
      "seq length 658\n"
     ]
    }
   ],
   "source": [
    "atomizer = CharacterAtomizer.from_text(''.join(dataframe[\"src\"].values))\n",
    "\n",
    "seqs = [atomizer.atomize(seq) for seq in dataframe[\"src\"].values]\n",
    "seq_length = max(len(s) for s in seqs)\n",
    "pad_val = atomizer.vocab_size + 1\n",
    "dataframe[\"seq\"] = list(pad_sequences(seqs, maxlen=seq_length, value=pad_val))\n",
    "print(\"vocab size\", atomizer.vocab_size)\n",
    "print(\"pad val\", pad_val)\n",
    "print(\"seq length\", maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features and labels for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num features 11\n",
      "Num tokens 69\n",
      "Seq length 658\n",
      "Num classes 2\n",
      "Num instances 15919\n"
     ]
    }
   ],
   "source": [
    "train, validation, test = get_train_validation_test_splits(dataframe)\n",
    "\n",
    "x_train_a = get_features(train)\n",
    "x_train_b = get_sequences(train, seq_length)\n",
    "y_train = get_labels(train)\n",
    "\n",
    "x_val_a = get_features(validation)\n",
    "x_val_b = get_sequences(validation, seq_length)\n",
    "y_val = get_labels(validation)\n",
    "\n",
    "x_test_a = get_features(test)\n",
    "x_test_b = get_sequences(test, seq_length)\n",
    "y_test = get_labels(test)\n",
    "\n",
    "num_features = len(x_train_a[0])\n",
    "num_classes = len(set(y_train))\n",
    "vocab_size = atomizer.vocab_size + 1  # +1 for pad value\n",
    "seq_length = len(x_train_b[0])\n",
    "\n",
    "print(\"Num features\", num_features)\n",
    "print(\"Num tokens\", vocab_size)\n",
    "print(\"Seq length\", seq_length)\n",
    "print(\"Num classes\", num_classes)\n",
    "print(\"Num instances\", len(dataframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAGACAYAAAC5j/bVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nABOEJAAAABOEJAAAABOEJAAAABP/B48EdtPlMrEYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f77fd706438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CPU = sum(1 if x == \"CPU\" else 0 for x in dataframe[\"oracle\"].values)\n",
    "GPU = sum(1 if x == \"GPU\" else 0 for x in dataframe[\"oracle\"].values)\n",
    "\n",
    "assert(CPU + GPU == len(dataframe))\n",
    "\n",
    "ax = sns.barplot([0, 1], [(CPU / len(dataframe)) * 100, (GPU / len(dataframe)) * 100])\n",
    "plt.title(\"Distribution of optimal device mappings\")\n",
    "plt.xticks([0, 1], [\"CPU\", \"GPU\"])\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"%. optimal\")\n",
    "viz.finalise(figsize=(6, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source + dynamic props classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_baseline():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(num_features, input_dim=num_features, init='normal', activation='relu'))\n",
    "#     model.add(Dense(1, init='normal', activation='sigmoid'))\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def evaluate(build_fn, nb_epoch=10):\n",
    "#     np.random.seed(seed)\n",
    "#     estimator = KerasClassifier(build_fn=create_baseline, nb_epoch=10, verbose=0)\n",
    "#     kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "#     return cross_val_score(estimator, X, Y, cv=kfold)\n",
    "\n",
    "# results = evaluate(create_baseline)\n",
    "# print(\"Results: {mean:.2%} (stdev: {std:.2%})\".format(mean=results.mean(), std=results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def evaluate_standardised(build_fn, nb_epoch=10):\n",
    "#     np.random.seed(seed)\n",
    "#     estimators = [\n",
    "#         ('standardize', StandardScaler()),\n",
    "#         ('mlp', KerasClassifier(build_fn=build_fn, nb_epoch=nb_epoch, verbose=0))\n",
    "#     ]\n",
    "#     pipeline = Pipeline(estimators)\n",
    "#     kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "#     return cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "\n",
    "# results = evaluate_standardised(create_baseline)\n",
    "# print(\"Results: {mean:.2%} (stdev: {std:.2%})\".format(mean=results.mean(), std=results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_smaller():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(num_features // 2, input_dim=num_features, init='normal', activation='relu'))\n",
    "#     model.add(Dense(1, init='normal', activation='sigmoid'))\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# results = evaluate_standardised(create_smaller)\n",
    "# print(\"Results: {mean:.2%} (stdev: {std:.2%})\".format(mean=results.mean(), std=results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def create_larger():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(num_features, input_dim=num_features, init='normal', activation='relu'))\n",
    "#     model.add(Dense(num_features // 2, init='normal', activation='relu'))\n",
    "#     model.add(Dense(1, init='normal', activation='sigmoid'))\n",
    "#     model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# results = evaluate_standardised(create_larger)\n",
    "# print(\"Results: {mean:.2%} (stdev: {std:.2%})\".format(mean=results.mean(), std=results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_7 (Dense)                  (None, 11)            132                                          \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 658, 32)       2208                                         \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 100)           53200                                        \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 32)            3584        merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 1)             33          dense_8[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 59,157\n",
      "Trainable params: 59,157\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "left = Sequential()\n",
    "left.add(Dense(num_features, input_dim=num_features, activation=\"sigmoid\"))\n",
    "\n",
    "embedding_vector_length = 32\n",
    "\n",
    "right = Sequential()\n",
    "right.add(Embedding(vocab_size, embedding_vector_length, input_length=seq_length))\n",
    "right.add(LSTM(100, input_dim=embedding_vector_length, input_length=seq_length))\n",
    "# right.add(LSTM(32, input_dim=vocab_size, input_length=seq_length))\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Merge([left, right], mode='concat'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Generate phony data and train:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9559 samples, validate on 3234 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-951c9b379210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m            \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_val_a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val_b\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m            verbose=1)\n\u001b[0m",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    935\u001b[0m                 ' to a larger type (e.g. int64).')\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m           \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cec/clgen/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \"\"\"\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "\n",
    "# generate dummy training data\n",
    "# x_train_a = np.random.random((1000, num_features))\n",
    "# x_train_b = np.random.random((1000, seq_length))\n",
    "# y_train = np.random.random((1000, 1))\n",
    "\n",
    "# generate dummy validation data\n",
    "# x_val_a = np.random.random((100, num_features))\n",
    "# x_val_b = np.random.random((100, seq_length))\n",
    "# y_val = np.random.random((100, 1))\n",
    "\n",
    "model.fit([x_train_a, x_train_b], y_train,\n",
    "           batch_size=64, nb_epoch=5,\n",
    "           validation_data=([x_val_a, x_val_b], y_val),\n",
    "           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLgen",
   "language": "python",
   "name": "clgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
