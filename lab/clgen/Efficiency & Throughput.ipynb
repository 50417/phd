{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Efficiency and Throughput\n",
    "Investigating sample success rate as a product of network size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preamble\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "from labm8 import fs\n",
    "from labm8 import system\n",
    "from labm8.time import nowstr\n",
    "\n",
    "import clgen\n",
    "from clgen import corpus\n",
    "from clgen import dbutil\n",
    "from clgen import sampler\n",
    "from clgen import model\n",
    "from clgen import preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experimental setup:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus size: 20271852\n",
      "Vocab size:  92\n",
      "\n",
      "CLgen:      0.2.1 (with CUDA)\n",
      "Platform:   Linux\n",
      "Memory:     32057 MB\n",
      "\n",
      "Device:     GPU GeForce GTX 1080\n",
      "Compute #.: 20\n",
      "Frequency:  1733 HZ\n",
      "Memory:     8113 MB\n",
      "Driver:     367.57\n",
      "\n",
      "Device:     GPU GeForce GTX 1080\n",
      "Compute #.: 20\n",
      "Frequency:  1733 HZ\n",
      "Memory:     8113 MB\n",
      "Driver:     367.57\n"
     ]
    }
   ],
   "source": [
    "rnn_sizes = [64, 128, 256, 512, 1024, 2048]\n",
    "corpus_opts = {\n",
    "    \"path\": \"~/data/github\"\n",
    "}\n",
    "training_opts = {\n",
    "    \"model_type\": \"lstm\",\n",
    "    \"num_layers\": 3,\n",
    "    \"max_epochs\": 3\n",
    "}\n",
    "s = sampler.from_json({\n",
    "    \"kernels\": {\n",
    "        \"args\": [\n",
    "            \"__global float*\",\n",
    "            \"__global float*\",\n",
    "            \"__global float*\",\n",
    "            \"const int\"\n",
    "        ],\n",
    "        \"max_length\": 5000,\n",
    "        \"temperature\": 1\n",
    "    },\n",
    "    \"sampler\": {\n",
    "        \"batch_size\": 5000,\n",
    "        \"max_batches\": 1,\n",
    "        \"static_checker\": False,\n",
    "        \"dynamic_checker\": False\n",
    "    }\n",
    "})\n",
    "\n",
    "c = corpus.Corpus.from_json(corpus_opts)\n",
    "print(\"Corpus size:\", c.size)\n",
    "print(\"Vocab size: \", c.vocab_size)\n",
    "print()\n",
    "clgen.platform_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experimental methodology:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def evaluate(model, sampler):\n",
    "    \"\"\" evaluate sampling efficiency \"\"\"\n",
    "    model.cache.empty()  # clear checkpoint cache    \n",
    "    tstart = time()  # start timer\n",
    "    model.train(quiet=True)  # train model\n",
    "    training_time = time() - tstart\n",
    "\n",
    "    # clear the sample cache\n",
    "    sampler.cache(model).empty()\n",
    "\n",
    "    # sample kernels and time\n",
    "    tstart = time()\n",
    "    sampler.sample(model, quiet=True)\n",
    "    tend = time()\n",
    "    elapsed = tend - tstart\n",
    "\n",
    "    # preprocess sample\n",
    "    sample_db = sampler.cache(model)[\"kernels.db\"]\n",
    "    preprocess.preprocess_db(sample_db)\n",
    "\n",
    "    num_kernels = dbutil.num_rows_in(sample_db, \"ContentFiles\")\n",
    "    num_good_kernels = dbutil.num_good_kernels(sample_db)\n",
    "    num_ugly_kernels = dbutil.num_rows_in(sample_db, \"PreprocessedFiles\",\n",
    "                                          \"WHERE status=2\")\n",
    "    discard_rate = 1 - (num_good_kernels / num_kernels)\n",
    "    ugly_rate = 1 - (num_ugly_kernels / num_kernels)\n",
    "\n",
    "\n",
    "    total_charcount = dbutil.cc(sample_db, \"ContentFiles\")\n",
    "    good_charcount = dbutil.cc(sample_db, \"PreprocessedFiles\",\n",
    "                               condition=\"WHERE status=0\")\n",
    "\n",
    "    efficiency = good_charcount / total_charcount\n",
    "    throughput = good_charcount / elapsed\n",
    "\n",
    "    return {\n",
    "        \"training_time\": training_time,\n",
    "        \"sampling_time\": elapsed,\n",
    "        \"num_kernels\": num_kernels,\n",
    "        \"num_good_kernels\": num_good_kernels,\n",
    "        \"discard_rate\": discard_rate,\n",
    "        \"ugly_rate\": ugly_rate,\n",
    "        \"total_charcount\": total_charcount,\n",
    "        \"good_charcount\": good_charcount,\n",
    "        \"efficiency\": efficiency,  # good_chars / total_chars\n",
    "        \"throughput\": throughput,  # good_chars / second\n",
    "        \"corpus_dir\": model.corpus.cache.path,\n",
    "        \"model_dir\": model.cache.path,\n",
    "        \"sampler_dir\": sampler.cache(model).path,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experimental results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting result for 64 ...\n"
     ]
    }
   ],
   "source": [
    "data_file = \"./sampling-{host}.json\".format(host=system.HOSTNAME)\n",
    "fs.rm(data_file)  # reset experimental data\n",
    "data = clgen.load_json_file(data_file, must_exist=False)\n",
    "\n",
    "for rnn_size in rnn_sizes:\n",
    "    key = str(rnn_size)\n",
    "    if key not in data:\n",
    "        print(\"collecting result for\", rnn_size, \"...\")\n",
    "        training_opts[\"rnn_size\"] = rnn_size\n",
    "        m = model.from_json({\n",
    "            \"corpus\": corpus_opts,\n",
    "            \"train_opts\": training_opts\n",
    "        })\n",
    "        data[key] = evaluate(m, s)\n",
    "    print(\"result\", rnn_size, clgen.format_json(data[key]))\n",
    "    clgen.write_file(data_file, clgen.format_json(data))\n",
    "print(\"done\", nowstr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experimental results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from labm8 import viz\n",
    "plt.style.use([\"seaborn-white\", \"seaborn-paper\"])\n",
    "\n",
    "plt.subplots(2, 2)\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "x, y = zip(*[(int(x), data[x][\"training_time\"] / training_opts[\"max_epochs\"])\n",
    "             for x in sorted(data.keys(), key=lambda x: int(x))])\n",
    "sns.barplot(x, y)\n",
    "plt.title(\"Time per. epoch\")\n",
    "plt.xlabel(\"Nodes per layer\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "x, y = zip(*[(int(x), data[x][\"sampling_time\"] / data[x][\"num_kernels\"])\n",
    "             for x in sorted(data.keys(), key=lambda x: int(x))])\n",
    "sns.barplot(x, y)\n",
    "plt.title(\"Time per. sample\")\n",
    "plt.xlabel(\"Nodes per layer\")\n",
    "plt.ylabel(\"Time (seconds)\")\n",
    "    \n",
    "plt.subplot(2, 2, 3)\n",
    "x, y = zip(*[(int(x), data[x][\"efficiency\"] * 100)\n",
    "             for x in sorted(data.keys(), key=lambda x: int(x))])\n",
    "sns.barplot(x, y)\n",
    "plt.title(\"Efficiency\")\n",
    "plt.xlabel(\"Nodes per layer\")\n",
    "plt.ylabel(\"% good chars\")\n",
    "    \n",
    "plt.subplot(2, 2, 4)\n",
    "x, y = zip(*[(int(x), data[x][\"throughput\"])\n",
    "             for x in sorted(data.keys(), key=lambda x: int(x))])\n",
    "sns.barplot(x, y)\n",
    "plt.title(\"Throughput\")\n",
    "plt.xlabel(\"Nodes per layer\")\n",
    "plt.ylabel(\"good chars / second\")\n",
    "\n",
    "viz.finalise(figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLgen",
   "language": "python",
   "name": "clgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
