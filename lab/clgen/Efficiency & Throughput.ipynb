{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preamble\n",
    "from time import time\n",
    "\n",
    "import clgen\n",
    "from clgen import dbutil\n",
    "from clgen import sampler\n",
    "from clgen import model\n",
    "from clgen import preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluation function\n",
    "def evaluate(model, sampler):\n",
    "    # sample kernels in 1 batch without checking\n",
    "    sampler.batch_size = 50 # 5000\n",
    "    sampler.max_batches = 1\n",
    "    sampler.static_checker = False\n",
    "    sampler.dynamic_checker = False\n",
    "\n",
    "    # clear the caches\n",
    "    sampler.cache(model).empty()\n",
    "\n",
    "    # sample kernels and time\n",
    "    tstart = time()\n",
    "    sampler.sample(model, quiet=True)\n",
    "    tend = time()\n",
    "    elapsed = tend - tstart\n",
    "\n",
    "    # preprocess sample\n",
    "    sample_db = sampler.cache(model)[\"kernels.db\"]\n",
    "    preprocess.preprocess_db(sample_db)\n",
    "\n",
    "    num_kernels = dbutil.num_rows_in(sample_db, \"ContentFiles\")\n",
    "    num_good_kernels = dbutil.num_good_kernels(sample_db)\n",
    "    num_ugly_kernels = dbutil.num_rows_in(sample_db, \"PreprocessedFiles\",\n",
    "                                          \"WHERE status=2\")\n",
    "    discard_rate = 1 - (num_good_kernels / num_kernels)\n",
    "    ugly_rate = 1 - (num_ugly_kernels / num_kernels)\n",
    "\n",
    "\n",
    "    total_charcount = dbutil.cc(sample_db, \"ContentFiles\")\n",
    "    good_charcount = dbutil.cc(sample_db, \"PreprocessedFiles\",\n",
    "                               condition=\"WHERE status=0\")\n",
    "\n",
    "    efficiency = good_charcount / total_charcount\n",
    "    throughput = good_charcount / elapsed\n",
    "\n",
    "    return {\n",
    "        \"elapsed\": elapsed,\n",
    "        \"num_kernels\": num_kernels,\n",
    "        \"num_good_kernels\": num_good_kernels,\n",
    "        \"discard_rate\": discard_rate,\n",
    "        \"ugly_rate\": ugly_rate,\n",
    "        \"total_charcount\": total_charcount,\n",
    "        \"good_charcount\": good_charcount,\n",
    "        \"efficiency\": efficiency,  # good_chars/total_chars\n",
    "        \"throughput\": throughput,  # good_chars/second\n",
    "        \"corpus_dir\": model.corpus.cache.path,\n",
    "        \"model_dir\": model.cache.path,\n",
    "        \"sampler_dir\": sampler.cache(model).path,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning batch 1 ...\n",
      " - sample 1\n",
      " - sample 2\n",
      " - sample 3\n",
      " - sample 4\n",
      " - sample 5\n",
      " - sample 6\n",
      " - sample 7\n",
      " - sample 8\n",
      " - sample 9\n",
      " - sample 10\n",
      " - sample 11\n",
      " - sample 12\n",
      " - sample 13\n",
      " - sample 14\n",
      " - sample 15\n",
      " - sample 16\n",
      " - sample 17\n",
      " - sample 18\n",
      " - sample 19\n",
      " - sample 20\n",
      " - sample 21\n",
      " - sample 22\n",
      " - sample 23\n",
      " - sample 24\n",
      " - sample 25\n",
      " - sample 26\n",
      " - sample 27\n",
      " - sample 28\n",
      " - sample 29\n",
      " - sample 30\n",
      " - sample 31\n",
      " - sample 32\n",
      " - sample 33\n",
      " - sample 34\n",
      " - sample 35\n",
      " - sample 36\n",
      " - sample 37\n",
      " - sample 38\n",
      " - sample 39\n",
      " - sample 40\n",
      " - sample 41\n",
      " - sample 42\n",
      " - sample 43\n",
      " - sample 44\n",
      " - sample 45\n",
      " - sample 46\n",
      " - sample 47\n",
      " - sample 48\n",
      " - sample 49\n",
      " - sample 50\n",
      "\n",
      "\n",
      "Number of content files:            78\n",
      "\n",
      "Number of unique content files:     78 (100%)\n",
      "Total content line count:           1,097\n",
      "Content file line counts:           min: 2, med: 10, avg: 14, max: 84\n",
      "\n",
      "Number of good preprocessed files:  0 (0%)\n",
      "Lines of good preprocessed code:    0 (0%)\n",
      "Good preprocessed line counts:      min: 0, med: 0, avg: 0, max: 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'corpus_dir': '/Users/cec/.cache/clgen/0.1.7/corpus/db160e3638cf02daa0cde17b260e3337c8f855ed',\n",
       " 'discard_rate': 0.9871794871794872,\n",
       " 'efficiency': 0.004441624365482234,\n",
       " 'elapsed': 31.363599061965942,\n",
       " 'good_charcount': 119,\n",
       " 'model_dir': '/Users/cec/.cache/clgen/0.1.7/model/380265ee43862639af2a551c78aa7f2b46dd1166',\n",
       " 'num_good_kernels': 1,\n",
       " 'num_kernels': 78,\n",
       " 'sampler_dir': '/Users/cec/.cache/clgen/0.1.7/sampler/b0616bd26abb92c3127d790b958f586dd40b51b2',\n",
       " 'throughput': 3.794207411110197,\n",
       " 'total_charcount': 26792,\n",
       " 'ugly_rate': 0.8717948717948718}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = model.from_json({\n",
    "    \"corpus\": {\n",
    "        \"path\": \"~/clgen-data/corpus\",\n",
    "        \"github\": False\n",
    "    },\n",
    "    \"train_opts\": {\n",
    "        \"model_type\": \"lstm\",\n",
    "        \"rnn_size\": 128,\n",
    "        \"num_layers\": 2,\n",
    "        \"max_epochs\": 5\n",
    "    }\n",
    "})\n",
    "s = sampler.from_json({\n",
    "    \"kernels\": {\n",
    "        \"args\": [\n",
    "            \"__global float*\",\n",
    "            \"__global float*\",\n",
    "            \"__global float*\",\n",
    "            \"const int\"\n",
    "        ],\n",
    "        \"max_length\": 5000,\n",
    "        \"temperature\": 1\n",
    "    },\n",
    "    \"sampler\": {}\n",
    "})\n",
    "\n",
    "info = evaluate(m, s)\n",
    "info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLgen",
   "language": "python",
   "name": "clgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
