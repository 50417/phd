{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLgen Sampling\n",
    "-----\n",
    "Dec 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preamble\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from labm8 import fs\n",
    "from labm8 import viz\n",
    "\n",
    "import clgen\n",
    "from clgen import corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental methodology\n",
    "\n",
    "Experimental platforms: cc[123]. NVIDIA GTX 1080.\n",
    "\n",
    "* Train on GitHub corpus.\n",
    "* Generate 1000 samples.\n",
    "* Reject bad samples.\n",
    "\n",
    "Commands:\n",
    "\n",
    "```\n",
    "$ export CUDA_VISIBLE_DEVICES=0\n",
    "$ export MODEL=model-128x3x50\n",
    "$ cd ~/phd/lab/clgen/inference\n",
    "$ python ./inference.py $MODEL.json 2>&1 | tee inference-$MODEL.log\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLgen:       0.2.1\n",
      "Corpus size: 20271852\n",
      "Vocab size:  92\n"
     ]
    }
   ],
   "source": [
    "c = corpus.Corpus.from_json({\"path\": \"~/data/github\"})\n",
    "print(\"CLgen:      \", clgen.version())\n",
    "print(\"Corpus size:\", c.size)\n",
    "print(\"Vocab size: \", c.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.22049405306496 \t const int a, __global int* b, __global int* c\n",
      "9.423604757548034 \t \n",
      "3.476669716376944 \t __global int* a\n",
      "3.43092406221409 \t __global float* a, __global float* b, __global float* c\n",
      "2.2872827081427265 \t __global int* a, __global int* b\n",
      "1.9670631290027447 \t __global float* a, __global float* b, __global int* c\n",
      "1.8298261665141813 \t __global float* a, __global float* b\n",
      "1.7840805123513266 \t __global float4* a, __global float4* b, __global float4* c, __global float4* d, __global float4* e, float f\n",
      "1.6925892040256174 \t __local int* a\n",
      "1.2808783165599267 \t __global float* a\n",
      "1.0064043915827996 \t __global uint* a, __global uint* b\n",
      "0.869167429094236 \t __global int* a, __global int* b, __global int* c\n",
      "0.777676120768527 \t __global float4* a, __global float4* b, __global float4* c, __global float4* d, int e, int f, float g, float h\n",
      "0.777676120768527 \t __global float4* q, __global float4* r, __global float4* s, __global float4* t, int u, int e, int v, float f, float g, float h, float i, float j\n",
      "0.6861848124428179 \t __global const float* a, __global const float* b, __global float* c, int d\n",
      "0.5946935041171089 \t __global float* a, __global float* b, __global float* c, __global int* d\n",
      "0.5489478499542544 \t __global float4* a\n",
      "0.5489478499542544 \t __global int* d\n",
      "0.5489478499542544 \t int a\n",
      "0.5032021957913998 \t __global int* a, const __global int* b, const __global int* c, const unsigned int d\n",
      "# prototypes 2186\n"
     ]
    }
   ],
   "source": [
    "p, num_prototypes = corpus.most_common_prototypes(c, 20)\n",
    "for row in p:\n",
    "    ratio, prototype = row\n",
    "    print(ratio * 100, '\\t', prototype)\n",
    "\n",
    "print(\"# prototypes\", num_prototypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 8 data files\n"
     ]
    }
   ],
   "source": [
    "def parse_file(path):\n",
    "    \"\"\" return model size, num layers, and epochs \"\"\"\n",
    "    import re\n",
    "    m = re.search(r\"([0-9]+)x([0-9]+)x([0-9]+)\", path)\n",
    "    return m.group(1), m.group(2), m.group(3) \n",
    "\n",
    "data_files = [\"benchmark/\" + x for x in fs.ls(\"benchmark\")\n",
    "              if x.startswith(\"benchmark-\") and x.endswith(\".json\")]\n",
    "data = dict((parse_file(x), clgen.load_json_file(x)) for x in data_files)\n",
    "print(\"read {} data files\".format(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from labm8 import viz\n",
    "plt.style.use([\"seaborn-white\", \"seaborn-paper\"])\n",
    "\n",
    "def label(path):\n",
    "    return '-'.join([str(x) for x in path])\n",
    "\n",
    "# sort key values\n",
    "sorted_keys = sorted(data.keys(), key=lambda x: [int(y) for y in x])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLgen",
   "language": "python",
   "name": "clgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
