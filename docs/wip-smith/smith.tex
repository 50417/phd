% -*- ispell-dictionary:"american" -*-
%
% The following \documentclass options may be useful:
%
% preprint      Remove this option only once the paper is in final form.
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.
\documentclass[preprint,nonatbib,10pt,nocopyrightspace]{sigplanconf}

%%%%%%%%%%%%%%%%%%%%%%%%%
%% Document and Layout %%
%%%%%%%%%%%%%%%%%%%%%%%%%

% Fix for multiple "No room for a new \dimen" errors.
%
% See: http://tex.stackexchange.com/questions/38607/no-room-for-a-new-dimen
%
\usepackage{etex}

\usepackage[utf8]{inputenc}

% Fix for "'babel/polyglossia' detected but 'csquotes' missing"
% warning. NOTE: Include after inputenc.
%
\usepackage{csquotes}

\usepackage{booktabs}

% Required for full page-width tables.
\usepackage{tabularx}

% Define column types L, C, R with known text justification and fixed
% widths:
\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

% Make internal macro definitions accessible,
% e.g. \@title, \@date \@author.
\makeatletter

% Uncomment the following line to remove column separation:
%
%\setlength{\columnsep}{5mm}

\usepackage{color}
\newcommand{\fix}[1]{\textcolor{red}{\em\footnotesize#1}}


%%%%%%%%%%%%%%%%
% Bibliography %
%%%%%%%%%%%%%%%%
\usepackage[%
    backend=biber,%bibtex,
    style=numeric-comp,
    % style=numeric-comp,  % numerical-compressed
    sorting=none,        % nty,nyt,nyvt,anyt,anyvt,ynt,ydnt,none
    sortcites=true,      % sort \cite{b a d c}: true,false
    block=none,          % space between blocks: none,space,par,nbpar,ragged
    indexing=false,      % indexing options: true,false,cite,bib
    citereset=none,      % don't reset cites
    isbn=false,          % print ISBN?
    url=true,            % print URL?
    doi=false,           % print DOI?
    natbib=true,         % natbib compatability
    maxbibnames=99       % no 'et-al' in the bibliography pls
  ]{biblatex}

\addbibresource{../../../library.bib}

% Reduce the font size of the bibliography:
\renewcommand{\bibfont}{\normalfont\scriptsize}

% No italics in \paragraph{title} style:
\usepackage{titlesec}
\titleformat*{\paragraph}{\bfseries}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Figures, footnotes and listings %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[perpage]{footmisc}

% Pre-requisites for rendering upquotes in listings package.
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{textcomp}

% Source code listings.
\usepackage{listings}
\lstset{%
  basicstyle=\scriptsize,%
  breaklines=true,%
  postbreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\color{red}\hookrightarrow\space}},% red arrow at line breaks
  captionpos=b%
}

% OpenCL listings
%
% From: http://gpumodeling.blogspot.com/2011/06/opencl-programs-in-latex-listings.html
 \lstdefinelanguage[OpenCL]{C}[ANSI]{C}
{morekeywords={__kernel,kernel,__local,local,__global,global,%
__constant,constant,__private,private,%
char2,char3,char4,char8,char16,%
uchar2,uchar3,uchar4,uchar8,uchar16,%
short2,short3,short4,short8,short16,%
ushort2,ushort3,ushort4,ushort8,ushort16,%
int2,int3,int4,int8,int16,%
uint2,uint3,uint4,uint8,uint16,%
long2,long3,long4,long8,long16,%
ulong2,ulong3,ulong4,ulong8,ulong16,%
float2,float3,float4,float8,float16,%
image2d_t,image3d_t,sampler_t,event_t,%
bool2,bool3,bool4,bool8,bool16,%
half2,half3,half4,half8,half16,%
quad,quad2,quad3,quad4,quad8,quad16,%
complex,imaginary},%
}%

% Pseudo-code listings.
\usepackage{algorithm}
\usepackage{algpseudocode}
\newcommand{\Break}{\State \textbf{break} }
\algblockdefx[Loop]{Loop}{EndLoop}[1][]{\textbf{Loop} #1}{\textbf{End
    Loop}}

\algrenewcommand\ALG@beginalgorithmic{\footnotesize}

% Plots:
\usepackage{filecontents}
\usepackage{pgfplots, pgfplotstable}
\usepgfplotslibrary{statistics}


%%%%%%%%%%%%%%%%%%%%%%%%
%% Graphics and maths %%
%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{amsmath}
\usepackage{tikz}

% Tikz flowchart configuration.
\usetikzlibrary{shapes,arrows,shadows,fit,backgrounds}
\tikzstyle{decision} = [diamond,
                        draw,
                        text width=4.5em,
                        text badly centered,
                        node distance=3cm,
                        inner sep=0pt]
\tikzstyle{block}    = [rectangle,
                        draw,
                        text width=5em,
                        text centered,
                        node distance=3cm,
                        minimum height=4em,
                        inner sep=.2cm]
\tikzstyle{line}     = [draw, -latex']

% Smaller font:
\pgfplotsset{every tick label/.append style={font=\scriptsize}}

% Vector notation, e.g. \vv{x}:
%
\usepackage{esvect}

% Additional amsmath symbols, see:
%
% http://texblog.org/2007/08/27/number-sets-prime-natural-integer-rational-real-and-complex-in-latex/
%
\usepackage{amsfonts}
\usepackage{amssymb}

\usepackage{graphicx}
\usepackage{mathtools}

% Provide bold font face in maths.
\usepackage{bm}

\usepackage{subcaption}
\expandafter\def\csname ver@subfig.sty\endcsname{}

% Define an 'myalignat' command which behave as 'alignat' without the
% vertical top and bottom padding. See:
%     http://www.latex-community.org/forum/viewtopic.php?f=5&t=1890
\newenvironment{myalignat}[1]{%
  \setlength{\abovedisplayskip}{-.7\baselineskip}%
  \setlength{\abovedisplayshortskip}{\abovedisplayskip}%
  \start@align\z@\st@rredtrue#1
}%
{\endalign}

% Define additional operators:
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}

\DeclareMathOperator*{\gain}{Gain}

% Skeleton operators.
\DeclareMathOperator*{\map}{Map}
\DeclareMathOperator*{\reduce}{Reduce}
\DeclareMathOperator*{\scan}{Scan}
\DeclareMathOperator*{\stencil}{Stencil}
\DeclareMathOperator*{\zip}{Zip}
\DeclareMathOperator*{\allpairs}{All\,Pairs}

% Define a command to allow word breaking.
\newcommand*\wrapletters[1]{\wr@pletters#1\@nil}
\def\wr@pletters#1#2\@nil{#1\allowbreak\if&#2&\else\wr@pletters#2\@nil\fi}

% Define a command to create centred page titles.
\newcommand{\centredtitle}[1]{
  \begin{center}
    \large
    \vspace{0.9cm}
    \textbf{#1}
  \end{center}}

% Provide generic commands \degree, \celsius, \perthousand, \micro
% and \ohm which work both in text and maths mode.
\usepackage{gensymb}

\begin{document}

\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{Work in progress}{Month d--d, 20yy, City, ST, Country}
\copyrightyear{2016}
\copyrightdata{978-1-nnnn-nnnn-n/yy/mm}
\doi{nnnnnnn.nnnnnnn}

% Uncomment one of the following two, if you are not going for the
% traditional copyright transfer agreement.

%\exclusivelicense                % ACM gets exclusive license to publish,
                                  % you retain copyright

%\permissiontopublish             % ACM gets nonexclusive license to publish
                                  % (paid open-access papers,
                                  % short abstracts)

% \titlebanner{banner above paper title}        % These are ignored unless
% \preprintfooter{}   % 'preprint' option specified.

\title{Curing the Benchmark Deficit: On-Demand Compute Kernel
  Synthesis using Deep Learning}

% \subtitle{Subtitle Text, if any}

\authorinfo{Chris Cummins}
           {University of Edinburgh}
           {c.cummins@ed.ac.uk}
\authorinfo{Pavlos Petoumenos}
           {University of Edinburgh}
           {ppetoume@inf.ed.ac.uk}
\authorinfo{Zheng Wang}
           {Lancaster University}
           {z.wang@lancaster.ac.uk}
\authorinfo{Hugh Leather}
           {University of Edinburgh}
           {hleather@inf.ed.ac.uk}

\maketitle

\begin{abstract}
  The quality of predictive performance modeling is bound by the
  quantity and quality of benchmarks used as training data. Too few
  benchmarks leads to overfitting; non-representative benchmarks leads
  to poor heuristics. This paper presents a novel methodology for
  generating representative benchmarks which solves two open issues
  for predictive modeling: the limited quantity of benchmarks
  available, and the need to behavior that is representative of common
  use cases. The new approach applies deep learning across the
  implementation space of a corpus of example programs, learning a
  language model from which we obtain new programs through a process
  of rejection sampling. We demonstrate this approach for a
  state-of-the-art machine learning OpenCL autotuner. With the
  addition of synthesized compute kernels, we improve the accuracy of
  learned predictions from XXX\% to XXX\%, demonstrating up to
  $X\times$ speedup over the hand-selected benchmarks.
\end{abstract}

% \category{CR-number}{subcategory}{third-level}

% % general terms are not compulsory anymore,
% % you may leave them out
% \terms
% term1, term2

\keywords
Synthetic program generation, %
OpenCL, %
Deep Learning, %
GPUs

\section{Introduction}\label{sec:introduction}

Predictive modeling is an effective method for building heuristics
over large optimization spaces which often exceeds human experts and
reduces development
time~\cite{Micolet2016,Wen2015,Magni2014,Falch2015,Cummins2016}. Whereas
traditionally optimization heuristics are crafted at the expense of
months of developer effort, with predictive modeling, the optimization
space is empirically and automatically explored to generate a set of
training data over which machine learning is applied.

The challenge of predictive modeling is to explore a sufficiently
large subset of a given optimization space so as to be able to make
meaningful predictions. This is achieved by collecting performance
data from some finite combination of programs, datasets, and
optimizations. In the program space, this means the curation and
selection of a number of programs to act as ``representative
benchmarks.'' The curation of representative benchmarks is challenging
and time consuming. As such, suites of of pre-packaged benchmarks are
in widespread use. The quality and quantity of these benchmark suites
provides an upper bound on the quality of the learned
heuristics. Using too few benchmarks leads to heuristics which overfit
the properties of specific programs; using unsuitable benchmarks leads
to heuristics which generalize poorly over other points in the program
space. In this paper we propose a new technique which aims to address
shortcomings of the current state-of-practice by allowing
representative benchmarks to be synthesized on-demand.

Our idea is to apply deep learning over a large corpus of compute
kernels mined from GitHub in order to learn a language distribution
over the implementation space. We then sample from this learned
distribution to generate new kernels on-demand, validating the
synthesized kernels using a process of rejection sampling.
%
% \paragraph{Research Questions}
We frame our work in terms of two research questions. The first
question addressed is:

\begin{quote}
  \emph{RQ1: Given a program checker and a corpus of example programs,
    can deep learning be used to synthesize new programs?}
\end{quote}

\noindent
Where a \emph{program checker} accepts as input a source code in the
language of the example programs, and returns whether or not it is
well formed (i.e. syntactically correct and free from undefined
behavior). This second question addressed in this paper is:

\begin{quote}
  \emph{RQ2: Can the performance of predictive modeling be improved
    with the addition of synthesized programs?}
\end{quote}

\noindent
To answer this question we use synthesized compute kernels to the
augment the training set of a state-of-the-art autotuner for OpenCL
kernels, in order to test the change in predictive modeling accuracy.

% For predictive modeling, we are interested not just in fully
% exploring the performance spectrum (this has been addressed in the
% literature~\cite{Ryoo2015}), but in weighting the exploration of the
% performance space towards the most frequently used patterns in

% two approaches to selecting benchmarks: benchmark suites and
% template substitution.

% NOCITE: Benchmarking OpenCL~\cite{Tobergte2013a}.

\noindent
\paragraph{Contributions} This paper makes the following
contributions:%
\begin{itemize}
\item To the best of our knowledge, we are the first to apply machine
  learning over open source repositories in order to model the
  patterns of usage in a programming language.
\item Our novel system for synthesizing representative compute kernels
  using deep learning solves two issues for representative
  benchmarking: the limited quantity of benchmarks available, and the
  need to behavior that is representative of common use cases.
\item Experimental results show that the performance of a
  state-of-the-art autotuner is improved by XXX\% with the addition of
  benchmarks generated using our system.
\end{itemize}


\section{Motivation}\label{sec:motivation}

% OpenCL benchmark suites:
% % Parsec~\cite{Bienia2009},
% Rodinia~\cite{Che2009}, %
% Parboil~\cite{Stratton2012}, %
% Polybench~\cite{Grauer-Gray2012}, %
% SHOC~\cite{Danalis2010}, %
% AMD SDK\footnote{\url{http://developer.amd.com/}} %
% and NVIDIA
% SDK\footnote{\url{https://developer.nvidia.com/opencl/}}. %

To motivate the need for compute kernel synthesis we surveyed the
benchmarking methodologies of research papers in the field of GPGPU
performance tuning from top tier conferences between 2013--2016: CGO,
HiPC, PACT, and PPoPP. We selected 27 papers, and noted the quantity
and sources of all kernels used as benchmarks for
each\footnote{Anonymized raw data available at:
  \url{http://bit.ly/TODO}}. %

Figure~\ref{fig:benchmark-quantity-distribution} shows the
distribution of kernel quantities. The median number of kernels used
is 14. Of those, four benchmark suites account for 74\% of all kernels
used. In descending order of popularity, they are:
Rodinia~\cite{Che2009}, the NVIDIA
SDK\footnote{\url{https://developer.nvidia.com/opencl/}},
Parboil~\cite{Stratton2012}, and the AMD
SDK\footnote{\url{http://developer.amd.com/}}. Figure~\ref{fig:benchmark-suite-distribution}
shows the breakdown of kernel sources.

TODO: state-of-the-art is laborious and error prone stochastic
template substitution.

Note that our survey was directed only at the selection of programs
used as benchmarks. For an excellent review of state of practice in
reporting benchmark results, see~\cite{Belli2015}.

\begin{figure}%[t]
  \includegraphics[width=\columnwidth]{img/benchmark-quantitiy-distribution}
  % \begin{tikzpicture}
  %   \tikzstyle{every node}=[font=\scriptsize]
  %   \begin{axis}[
  %     width=\columnwidth,
  %     height=4cm,
  %     ybar,
  %     ymin=0,
  %     xlabel={\#. benchmark kernels},
  %     ylabel={\#. papers},
  %     ],
  %     \addplot +[
  %     hist={
  %       bins=5,
  %       data min=0,
  %       data max=50
  %     }
  %     ] table [y index=0] {data/benchmark-quantities.csv};
  %   \end{axis}
  % \end{tikzpicture}
  \caption{%
    Number of benchmark kernels used in GPGPU research papers. The
    median value is 14.%
  }
  \label{fig:benchmark-quantity-distribution}
\end{figure}

\begin{figure}%[t]
  \includegraphics[width=\columnwidth]{img/benchmark-suite-distribution}
  \caption{%
    Origins of benchmark kernels used in GPGPU research papers. The 4
    most frequently used benchmark suites account for 74\% of all
    kernels used.%
  }
  \label{fig:benchmark-suite-distribution}
\end{figure}

\section{Synthesizing Compute Kernels}\label{sec:}

Overview of methodology. Figure~\ref{fig:structure}.

\paragraph{Assembling the Language Corpus} Mining GitHub, noisy
dataset.


\paragraph{Learning the Implementation Space} Program rewriting, LSTM,
character-level language model.


\paragraph{Synthesizing Compute Kernels} Sampling learned model using
function prototypes, rejection sampler, program checker.


\begin{figure*}%[t]
  \centering
  \input{fig/structure}
  \caption{%
    The kernel synthesis pipeline.%
  }
\label{fig:structure}
\end{figure*}


\section{Training Corpus Selection}\label{sec:}

We collect a large code corpus from
GitHub\footnote{\url{https://github.com/}}. This took 2 days on a
single machine.

Rejection sampling to remove noise from dataset. Check that compiles.

Alternative source of data: \emph{GHTorrent}~\cite{Gousios2014a}.

\section{Learning the Implementation Space}\label{sec:ml}

Minimizing non-functional variance using clang libraries and tools:
\begin{itemize}
\item Pre-process source to remove macros and conditional
  compilation.
\item Loss-less vocabulary size reduction with AST rewriting of
  identifiers.
\item Automatically enforcing code style with formatting tools.
\end{itemize}

Pre-processing pipeline: Implemented on
LLVM\footnote{\url{http://llvm.org/}},
clang%\footnote{\url{http://clang.llvm.org/}}
, and libclc%\footnote{\url{http://libclc.llvm.org/}}
.

\begin{figure}%[t]
\includegraphics[width=\columnwidth]{img/undeclared-identifiers.png}
\caption{%
  Undeclared identifier occurrences in OpenCL sources.
  % all 1023 unique identifiers in the OpenCL source codes set. The most
  % frequently used undeclared identifier is \texttt{LOCAL\_SIZE\_LIMIT}
  % (462 occurrences). The 60 most used identifiers account for 50\% of
  % errors.%
}
\end{figure}

Compile to LLVM byte code using libclc. Through analyzing 148k lines of
compilation errors, we created a shim header to include common missing
things. Include shim header which adds inferred values for common
typedefs (e.g. FLOAT\_T to float), and best guesses for common
constants (e.g. WGSIZE). Listing~\ref{lst:shim}

Preprocessor is a unique challenge to C family of languages. Shim
decreases the discard rate from 40\% to 32\% (responsible for an
additional 88k lines of code in the language corpus). These macros may
be harmlessly redefined within files.

\lstset{language=[OpenCL]C}
\begin{lstlisting}[%
  float,%
%  floatplacement=t,%
  frame=single,%
  caption=The shim header file.
]
// Enable OpenCL features
#define cl_clang_storage_class_specifiers
#define cl_khr_fp64
#include <clc/clc.h>

// Inferred types
typedef float FLOAT_T;
typedef unsigned int INDEX_TYPE;
... (36 more)

// Inferred constants
#define M_PI 3.14025
#define WG_SIZE 128
... (185 more)
\end{lstlisting}

\subsection{Machine Learning Model}

We use the Long Short-Term Memory (LSTM)~\cite{Hochreiter1997}
architecture of Recurrent Neural Network
(RNN)~\cite{Mikolov2015}. LSTMs are proving to be a powerful learning
tool with applications from speech recognition to image
captioning. LSTMs for language modeling~\cite{Sundermeyer2012}. No
features.

LSTM
implementation\footnote{\url{https://github.com/jcjohnson/torch-rnn}}. LSTM
network: 2048 nodes, 3 layers, sequence length 50, batch size 50, no
dropout. Trained for 100 epochs using an initial learning rate of
0.002, decaying by a factor of a half every 5 epochs. Around 10 days
training on an NVIDIA GTX Titan.

Vocabulary size XXX. Training set XXX. Learned model XXX MB.


\section{Sampling Implementation Space}\label{sec:}

Given a function prototype.

Sample kernels with balanced brackets.

Rejection sampler.

Undefined behavior.

Driver program (and dataset).

Approximately XX days on single machine.

\lstset{language=[OpenCL]C}
\begin{lstlisting}[%
  float,%
%  floatplacement=t,%
  frame=single,%
  caption=Parboil SGEMM benchmark.
]
__kernel void mysgemmNT( __global const float *A, int lda, __global const float *B, int ldb, __global float* C, int ldc, int k, float alpha, float beta )
{
    float c = 0.0f;
    int m = get_global_id(0);
    int n = get_global_id(1);

    for (int i = 0; i < k; ++i) {
	float a = A[m + i * lda];
	float b = B[n + i * ldb];
	c += a * b;
    }
    C[m+n*ldc] = C[m+n*ldc] * beta + alpha * c;
}
\end{lstlisting}


\lstset{language=[OpenCL]C}
\begin{lstlisting}[%
  float,%
%  floatplacement=t,%
  frame=single,%
  caption=Transformed SGEMM implementation from preprocessing pipeline.
]
__kernel void A(__global const float *a, int b, __global const float *c, int d,
                __global float *e, int f, int g, float h, float i) {
  float j = 0.0f;
  int k = get_global_id(0);
  int l = get_global_id(1);

  for (int m = 0; m < g; ++m) {
    float n = a[k + m * b];
    float o = c[l + m * d];
    j += n * o;
  }
  e[k + l * f] = e[k + l * f] * i + h * j;
}
\end{lstlisting}


\lstset{language=[OpenCL]C}
\begin{lstlisting}[%
  float,%
%  floatplacement=t,%
  frame=single,%
  caption=Example kernel synthesised from SGEMM function prototype.
]
TODO
\end{lstlisting}


\section{Experimental Methodology}\label{sec:evaluation}

To evaluate the effectiveness

we reproduce from \citeauthor{Grewe2013}~\cite{Grewe2013}.

\subsection{Experimental Setup}\label{subsec:}

\paragraph{Platforms} We evaluate our approach on two 64-bit CPU-GPU
systems, detailed in Table~\ref{tab:platforms}. Platform A uses
OpenSUSE 12.3 and GCC 4.7.2; Platform B uses Ubuntu 14.04 and GCC
x. The AMD implementation of OpenCL 1.2 is used for both.


% OLD PLATFORMS: cecplay + monza
% \begin{table*}% tab:platforms
%   \scriptsize
%   \centering
%   \begin{tabular}{l c c c c}%C{1.65cm} C{1.65cm} C{1.65cm} C{1.65cm}}
%     \toprule
%     & \multicolumn{2}{c}{Platform A} & \multicolumn{2}{c}{Platform B} \\
%     % & \textbf{CPU} & \textbf{GPU} & \textbf{CPU} & \textbf{GPU} \\
%     & \textbf{Intel i7-3820} & \textbf{AMD Tahiti 7970} & \textbf{Intel i7-6700K} & \textbf{AMD HD 5450} \\
%     \midrule
%     \textbf{Frequency} & 3.6 GHz & 1000 MHz & 4.0 GHz & 650 MHz \\
%     \textbf{\#. Cores} & 4 & 2048 & 8 & 80 \\
%     \textbf{Memory} & 8 GB & 3 GB & 32 GB & 1024 MB \\
%     \textbf{Throughput} & 95 GFLOPS & 3.79 TFLOPS & 81 GFLOPS & 104 GFLOPS
%     \\
%     % \midrule
%     % \textbf{Operating System} & \multicolumn{2}{c}{OpenSUSE 12.3} & \multicolumn{2}{c}{Ubuntu 14.04} \\
%     % \textbf{Compiler} & \multicolumn{2}{c}{GCC 4.7.2} & \multicolumn{2}{c}{GCC x} \\
%     \bottomrule
%   \end{tabular}
%   \caption{Experimental platforms.}
%   \label{tab:platforms}
% \end{table*}

% PLATFORMS: monza CPU, monza GPU, diana GPU
\begin{table}% tab:platforms
  \scriptsize
  \centering
  \begin{tabular}{l l l l}
    \toprule
    & \textbf{Intel CPU} & \textbf{AMD GPU} & \textbf{NVIDIA GPU} \\
    \midrule
    \textbf{Model} & Core i7-3820 & Tahiti 7970 & GTX 970 \\
    \textbf{Frequency} & 3.6 GHz & 1000 MHz & 1050 MHz \\
    \textbf{\#. Cores} & 4 & 2048 & 1664 \\
    \textbf{Memory} & 8 GB & 3 GB & 4 GB \\
    \textbf{Throughput} & 105 GFLOPS & 3.79 TFLOPS & 3.90 TFLOPS \\
    \bottomrule
  \end{tabular}
  \caption{Experimental platforms.}
  \label{tab:platforms}
\end{table}


\paragraph{Benchmarks}

\begin{table}% tab:%benchmarks
  \scriptsize
  \centering
  \begin{tabular}{l r R{2cm} R{2cm}}
    \toprule
    & \textbf{Version} & \textbf{\#. seed kernels} & \textbf{\#. generated kernels}\\
    \midrule
    % \textbf{NPB~\cite{Seo2011}} & 1.0.3 & x & x \\
    \textbf{Parboil~\cite{Stratton2012}} & 0.2 & 7 & x \\
    % \textbf{PolyBench~\cite{Grauer-Gray2012}} & 1.0 & 30 & x \\
    \textbf{Rodinia~\cite{Che2009}} & 3.1 & 50 & x \\
    % \textbf{SHOC~\cite{Danalis2010}} & 1.1.5 & 53 & x \\
    \textbf{AMD SDK} & 3.0 & x & x \\
    \textbf{NVIDIA SDK} & 4.2 & 36 & x \\
    \textbf{Synthetic} & - & - & x \\
    \bottomrule
  \end{tabular}
  \caption{%
    Benchmark kernels used.
  }
  \label{tab:benchmarks}
\end{table}

Table~\ref{tab:benchmarks}. Notes: Parboil: opencl\_base
implementation. Ignored benchmarks from the SDKs which were
inappropriate (e.g. testing multi-GPU support, or some
platform-specific extension).

Rewrote typedefs.

Limitation of system: can't use synthesize kernels with struct
arguments. Ignored kernels with struct args: %
parboil-bfs, %
parboil-mri-q, %
rodinia-b-tree, %
rodinia-dwt2d, %
rodinia-heartwall, %
rodinia-lavamd, %
rodinia nearest neighbor.


\paragraph{Datasets}


\subsection{Methodology}

Followed the methodology of~\cite{Grewe2013}.

Statistical soundness.

Leave-one-out cross validation.


\section{Experimental Results}\label{sec:evaluation}


\subsection{Generated Compute Kernels}\label{subsec:}

Evaluating \emph{RQ1}. What's the ratio of ``good'' code? How long did
it take to sample?

TODO: Plot distribution of static features from benchmark suites,
GitHub, and generated synthesis.


\subsection{Qualitatively Evaluating Generated Code}\label{subsec:}

Human or
Robot\footnote{\url{http://humanorrobot.uk/game?g=opencl&m=nitt}}. Related
works which have used Non-Interactive Turing
Tests~\cite{Gao2015a,Zhang2016}.


\subsection{Predicting Execution Device}\label{subsec:}

Evaluating \emph{RQ2}. Classification accuracy.


\subsection{Comparison with State-of-the-Art}\label{subsec:}

Compare prediction performance with and without additional synthetic
benchmarks.


\section{Related Work}\label{sec:related-work}

Are benchmarks suites representative? Exploring the full performance
spectrum~\cite{Ryoo2015}. Characterizing workloads of Rodinia and
Parsec~\cite{Che2010}.

In previous work we used stochastic template substitution to generate
stencil benchmarks for autotuning~\cite{Cummins2015a}. This template
based approach is not general purpose, requires laborious human
effort, and does not guarantee to generate representative benchmarks.

Misc: Verifying GPU kernels~\cite{Betts2012}. Simulating OpenCL
kernels~\cite{Price2015}.

Machine Learning-based Performance Tuning:~\cite{Wen2015},
\cite{Magni2014}, \cite{Falch2015}. Domain specific:
Stencils~\cite{Garvey2015b}, \cite{Cummins2015a}. Input sensitive
autotuning~\cite{Ding2015}. Benchmark reduction~\cite{Castro2014}.


\paragraph{Representative Benchmarking} Designing
workloads~\cite{Eeckhout2002}. Characterization of NAS
Opencl~\cite{Seo2011}. Characterization of
Rodinia~\cite{Che2010,Ryoo2015}.


\paragraph{Program Generation} Template-based:
GENESIS~\cite{Chiu2015}.  Grammar-based: Csmith~\cite{Yang2012},
CLsmith~\cite{Pflanzer2016}. Mutation-based: JVM
fuzzing~\cite{Chena}. Goal-oriented: Generating linear
transforms~\cite{Voronenko2009}, synthesizing MapReduce
programs~\cite{Smith}, generating data structure
implementations~\cite{Loncaric2016}.


\paragraph{Mining Source Codes} Neural Networks for representing
programs~\cite{Bunel}.

Promises and perils of mining GitHub~\cite{Bird2009}.

Mining source code repositories at large
scale~\cite{Allamanis2013a,White2015a}. Machine learning for analyzing
code~\cite{Allamanis2014a,Raychev}. Aiding software
engineering~\cite{Allamanis2014,Bird2015}.

Previous studies have involved data mining of GitHub for analysis of
software engineering
practices~\cite{Wu2014,Guzman2014,Baishakhi2014a,Vasilescu2015}.


\paragraph{Deep Learning} This is the first application of deep
learning for synthesizing programs.

Deep Learning has been successful for synthesizing graphics
textures~\cite{Gatys2015a}, image captions~\cite{Vinyals}, colors for
black and white photographs~\cite{Zhang2016}, and artistic
style~\cite{Gatys2015}.

DeepAPI learns API usage from annotated snippets from
GitHub~\cite{Zhang2015a}.


\section{Conclusion}\label{sec:conclusion}

Future work: probabilistic grammar.


\acks

This work was supported by the UK Engineering and Physical Sciences
Research Council under grants EP/L01503X/1 (CDT in Pervasive
Parallelism), EP/H044752/1 (ALEA), and EP/M015793/1 (DIVIDEND).

\label{bibliography}
\printbibliography


\end{document}
