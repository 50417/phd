\section{Introduction}\label{sec:intro}

\noindent
Compilers should produce correct code for valid inputs, and meaningful errors for invalid inputs. Properly testing compilers is hard --- modern optimizing compilers are large and complex programs, and their input space is huge. Random test case generation --- \emph{fuzzing} --- is a well established and effective method for identifying compiler bugs. When fuzzing, randomly generated valid or semi-valid inputs are fed to the compiler. Any kind of unexpected behavior, including crashes, freezes, or wrong binaries, indicates a compiler bug. Differential Testing can be used to find compiler bugs in generated binaries without the need for an oracle by comparing program outputs across compilers. The generated code and a set of inputs form a \emph{test case} which is compiled and executed on multiple \emph{testbeds}. If the test case should have deterministic behavior, but the output differs between testbeds, then a bug has been discovered.

CSmith, a state-of-the-art fuzzer which randomly enumerates programs from a subset of the C programming language grammar, has been successfully used to identify hundreds of bugs in C compilers, but developing such a fuzzer is a huge undertaking. CSmith was developed over the course of years, and consists of over 41k lines of handwritten C++ code. By tightly coupling the generation logic with the target programming language, each feature of the grammar must be painstakingly and expertly engineered for each new target language. For example, lifting CSmith from C to OpenCL~\cite{Lidbury2015a} --- a superficially simple task --- took 9 months and an additional 8k lines of code. Given the difficulty of defining a new grammar, typically only a subset of the language is implemented. 

We propose a fast, effective, and low effort approach to the generation of random programs for compiler fuzzing. Our methodology uses recent advances in deep learning to automatically construct probabilistic models of how humans write code, instead of painstakingly defining a grammar to the same end. By training a deep neural network on a corpus of handwritten code, it is able to infer both the syntax and semantics of the programming language. Our approach essentially frames the generation of random programs as a language modeling problem. This greatly simplifies and accelerates the process. The expressiveness of the generated programs is limited only by what is contained in the corpus, not the developer's expertise or available time. We make the following contributions:
\vspace{-.2em}
\begin{itemize}
\itemsep0em 
\item a novel, automatic, and fast approach for the generation of expressive random programs for compiler fuzzing. We \emph{infer} programming language syntax, structure, and use from real-world examples, not through an expert-defined grammar. Our system needs two orders of magnitude less code than the state-of-the-art, and takes less than a day to train;
\item we discover a similar number of bugs as the state-of-the-art, but also find bugs which prior work cannot, covering more components of the compiler;
\item in modeling real handwritten code, our test cases are more interpretable than other approaches. Average test case size is two orders of magnitude smaller than state-of-the-art, without any expensive reduction process.
\end{itemize}
\vspace{-1em}