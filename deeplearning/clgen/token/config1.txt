# A tiny corpus of OpenCL kernels and a correspondingly small model.
# It should take around 30 minutes to train on a reasonably powerful GPU,
# and maybe around an hour on a CPU.
# File: //deeplearning/deepsmith/proto/clgen.proto
# Proto: clgen.Instance
working_dir: "/var/phd/clgen/mdl"
model {
  corpus {
    local_tar_archive: "$PWD/20mdl.tar.bz2"
    # ascii_character_atomizer: true
    greedy_multichar_atomizer {