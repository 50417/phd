       # -*- coding: utf-8 -*-
       #
       # Secret Labs' Regular Expression Engine
       #
       # convert template to internal format
       #
       # Copyright (c) 1997-2001 by Secret Labs AB.  All rights reserved.
       #
       # See the sre.py file for information on usage and redistribution.
       #
       
>>>>>> """Internal support module for sre"""
       
>>>>>> import _sre, sys
>>>>>> import sre_parse
>>>>>> from sre_constants import *
       
>>>>>> assert _sre.MAGIC == MAGIC, "SRE module mismatch"
       
>>>>>> if _sre.CODESIZE == 2:
>>>>>>     MAXCODE = 65535
       else:
>>>>>>     MAXCODE = 0xFFFFFFFFL
       
>>>>>> _LITERAL_CODES = set([LITERAL, NOT_LITERAL])
>>>>>> _REPEATING_CODES = set([REPEAT, MIN_REPEAT, MAX_REPEAT])
>>>>>> _SUCCESS_CODES = set([SUCCESS, FAILURE])
>>>>>> _ASSERT_CODES = set([ASSERT, ASSERT_NOT])
       
       # Sets of lowercase characters which have the same uppercase.
       _equivalences = (
           # LATIN SMALL LETTER I, LATIN SMALL LETTER DOTLESS I
>>>>>>     (0x69, 0x131), # iı
           # LATIN SMALL LETTER S, LATIN SMALL LETTER LONG S
>>>>>>     (0x73, 0x17f), # sſ
           # MICRO SIGN, GREEK SMALL LETTER MU
>>>>>>     (0xb5, 0x3bc), # µμ
           # COMBINING GREEK YPOGEGRAMMENI, GREEK SMALL LETTER IOTA, GREEK PROSGEGRAMMENI
>>>>>>     (0x345, 0x3b9, 0x1fbe), # \u0345ιι
           # GREEK SMALL LETTER BETA, GREEK BETA SYMBOL
>>>>>>     (0x3b2, 0x3d0), # βϐ
           # GREEK SMALL LETTER EPSILON, GREEK LUNATE EPSILON SYMBOL
>>>>>>     (0x3b5, 0x3f5), # εϵ
           # GREEK SMALL LETTER THETA, GREEK THETA SYMBOL
>>>>>>     (0x3b8, 0x3d1), # θϑ
           # GREEK SMALL LETTER KAPPA, GREEK KAPPA SYMBOL
>>>>>>     (0x3ba, 0x3f0), # κϰ
           # GREEK SMALL LETTER PI, GREEK PI SYMBOL
>>>>>>     (0x3c0, 0x3d6), # πϖ
           # GREEK SMALL LETTER RHO, GREEK RHO SYMBOL
>>>>>>     (0x3c1, 0x3f1), # ρϱ
           # GREEK SMALL LETTER FINAL SIGMA, GREEK SMALL LETTER SIGMA
>>>>>>     (0x3c2, 0x3c3), # ςσ
           # GREEK SMALL LETTER PHI, GREEK PHI SYMBOL
>>>>>>     (0x3c6, 0x3d5), # φϕ
           # LATIN SMALL LETTER S WITH DOT ABOVE, LATIN SMALL LETTER LONG S WITH DOT ABOVE
>>>>>>     (0x1e61, 0x1e9b), # ṡẛ
       )
       
       # Maps the lowercase code to lowercase codes which have the same uppercase.
>>>>>> _ignorecase_fixes = {i: tuple(j for j in t if i != j)
>>>>>>                      for t in _equivalences for i in t}
       
>>>>>> def _compile(code, pattern, flags):
           # internal: compile a (sub)pattern
28254:     emit = code.append
28254:     _len = len
28254:     LITERAL_CODES = _LITERAL_CODES
28254:     REPEATING_CODES = _REPEATING_CODES
28254:     SUCCESS_CODES = _SUCCESS_CODES
28254:     ASSERT_CODES = _ASSERT_CODES
28254:     if (flags & SRE_FLAG_IGNORECASE and
 3545:             not (flags & SRE_FLAG_LOCALE) and
 3267:             flags & SRE_FLAG_UNICODE):
  339:         fixes = _ignorecase_fixes
           else:
27915:         fixes = None
134663:     for op, av in pattern:
106409:         if op in LITERAL_CODES:
87491:             if flags & SRE_FLAG_IGNORECASE:
 5669:                 lo = _sre.getlower(av, flags)
 5669:                 if fixes and lo in fixes:
   11:                     emit(OPCODES[IN_IGNORE])
   11:                     skip = _len(code); emit(0)
   11:                     if op is NOT_LITERAL:
>>>>>>                         emit(OPCODES[NEGATE])
   33:                     for k in (lo,) + fixes[lo]:
   22:                         emit(OPCODES[LITERAL])
   22:                         emit(k)
   11:                     emit(OPCODES[FAILURE])
   11:                     code[skip] = _len(code) - skip
                       else:
 5658:                     emit(OPCODES[OP_IGNORE[op]])
 5658:                     emit(lo)
                   else:
81822:                 emit(OPCODES[op])
81822:                 emit(av)
18918:         elif op is IN:
 3046:             if flags & SRE_FLAG_IGNORECASE:
  855:                 emit(OPCODES[OP_IGNORE[op]])
  855:                 def fixup(literal, flags=flags):
 4663:                     return _sre.getlower(literal, flags)
                   else:
 2191:                 emit(OPCODES[op])
 2191:                 fixup = None
 3046:             skip = _len(code); emit(0)
 3046:             _compile_charset(av, flags, code, fixup, fixes)
 3046:             code[skip] = _len(code) - skip
15872:         elif op is ANY:
 5729:             if flags & SRE_FLAG_DOTALL:
 5191:                 emit(OPCODES[ANY_ALL])
                   else:
  538:                 emit(OPCODES[ANY])
10143:         elif op in REPEATING_CODES:
 3851:             if flags & SRE_FLAG_TEMPLATE:
>>>>>>                 raise error, "internal: unsupported template operator"
>>>>>>                 emit(OPCODES[REPEAT])
>>>>>>                 skip = _len(code); emit(0)
>>>>>>                 emit(av[0])
>>>>>>                 emit(av[1])
>>>>>>                 _compile(code, av[2], flags)
>>>>>>                 emit(OPCODES[SUCCESS])
>>>>>>                 code[skip] = _len(code) - skip
 3851:             elif _simple(av) and op is not REPEAT:
 3333:                 if op is MAX_REPEAT:
 3154:                     emit(OPCODES[REPEAT_ONE])
                       else:
  179:                     emit(OPCODES[MIN_REPEAT_ONE])
 3333:                 skip = _len(code); emit(0)
 3333:                 emit(av[0])
 3333:                 emit(av[1])
 3333:                 _compile(code, av[2], flags)
 3333:                 emit(OPCODES[SUCCESS])
 3333:                 code[skip] = _len(code) - skip
                   else:
  518:                 emit(OPCODES[REPEAT])
  518:                 skip = _len(code); emit(0)
  518:                 emit(av[0])
  518:                 emit(av[1])
  518:                 _compile(code, av[2], flags)
  518:                 code[skip] = _len(code) - skip
  518:                 if op is MAX_REPEAT:
  476:                     emit(OPCODES[MAX_UNTIL])
                       else:
   42:                     emit(OPCODES[MIN_UNTIL])
 6292:         elif op is SUBPATTERN:
 3203:             if av[0]:
 2925:                 emit(OPCODES[MARK])
 2925:                 emit((av[0]-1)*2)
                   # _compile_info(code, av[1], flags)
 3203:             _compile(code, av[1], flags)
 3203:             if av[0]:
 2925:                 emit(OPCODES[MARK])
 2925:                 emit((av[0]-1)*2+1)
 3089:         elif op in SUCCESS_CODES:
>>>>>>             emit(OPCODES[op])
 3089:         elif op in ASSERT_CODES:
  159:             emit(OPCODES[op])
  159:             skip = _len(code); emit(0)
  159:             if av[0] >= 0:
   94:                 emit(0) # look ahead
                   else:
   65:                 lo, hi = av[1].getwidth()
   65:                 if lo != hi:
>>>>>>                     raise error, "look-behind requires fixed-width pattern"
   65:                 emit(lo) # look behind
  159:             _compile(code, av[1], flags)
  159:             emit(OPCODES[SUCCESS])
  159:             code[skip] = _len(code) - skip
 2930:         elif op is CALL:
>>>>>>             emit(OPCODES[op])
>>>>>>             skip = _len(code); emit(0)
>>>>>>             _compile(code, av, flags)
>>>>>>             emit(OPCODES[SUCCESS])
>>>>>>             code[skip] = _len(code) - skip
 2930:         elif op is AT:
 1776:             emit(OPCODES[op])
 1776:             if flags & SRE_FLAG_MULTILINE:
  359:                 av = AT_MULTILINE.get(av, av)
 1776:             if flags & SRE_FLAG_LOCALE:
   61:                 av = AT_LOCALE.get(av, av)
 1715:             elif flags & SRE_FLAG_UNICODE:
   64:                 av = AT_UNICODE.get(av, av)
 1776:             emit(ATCODES[av])
 1154:         elif op is BRANCH:
  995:             emit(OPCODES[op])
  995:             tail = []
  995:             tailappend = tail.append
13699:             for av in av[1]:
12704:                 skip = _len(code); emit(0)
                       # _compile_info(code, av, flags)
12704:                 _compile(code, av, flags)
12704:                 emit(OPCODES[JUMP])
12704:                 tailappend(_len(code)); emit(0)
12704:                 code[skip] = _len(code) - skip
  995:             emit(0) # end of branch
13699:             for tail in tail:
12704:                 code[tail] = _len(code) - tail
  159:         elif op is CATEGORY:
>>>>>>             emit(OPCODES[op])
>>>>>>             if flags & SRE_FLAG_LOCALE:
>>>>>>                 av = CH_LOCALE[av]
>>>>>>             elif flags & SRE_FLAG_UNICODE:
>>>>>>                 av = CH_UNICODE[av]
>>>>>>             emit(CHCODES[av])
  159:         elif op is GROUPREF:
  141:             if flags & SRE_FLAG_IGNORECASE:
   38:                 emit(OPCODES[OP_IGNORE[op]])
                   else:
  103:                 emit(OPCODES[op])
  141:             emit(av-1)
   18:         elif op is GROUPREF_EXISTS:
   18:             emit(OPCODES[op])
   18:             emit(av[0]-1)
   18:             skipyes = _len(code); emit(0)
   18:             _compile(code, av[1], flags)
   18:             if av[2]:
   14:                 emit(OPCODES[JUMP])
   14:                 skipno = _len(code); emit(0)
   14:                 code[skipyes] = _len(code) - skipyes + 1
   14:                 _compile(code, av[2], flags)
   14:                 code[skipno] = _len(code) - skipno
                   else:
    4:                 code[skipyes] = _len(code) - skipyes + 1
               else:
>>>>>>             raise ValueError, ("unsupported operand type", op)
       
>>>>>> def _compile_charset(charset, flags, code, fixup=None, fixes=None):
           # compile charset subprogram
 3354:     emit = code.append
 3354:     for op, av in _optimize_charset(charset, fixup, fixes,
 7635:                                     flags & SRE_FLAG_UNICODE):
 4281:         emit(OPCODES[op])
 4281:         if op is NEGATE:
  214:             pass
 4067:         elif op is LITERAL:
 1228:             emit(av)
 2839:         elif op is RANGE:
  929:             emit(av[0])
  929:             emit(av[1])
 1910:         elif op is CHARSET:
  308:             code.extend(av)
 1602:         elif op is BIGCHARSET:
   13:             code.extend(av)
 1589:         elif op is CATEGORY:
 1589:             if flags & SRE_FLAG_LOCALE:
   23:                 emit(CHCODES[CH_LOCALE[av]])
 1566:             elif flags & SRE_FLAG_UNICODE:
   84:                 emit(CHCODES[CH_UNICODE[av]])
                   else:
 1482:                 emit(CHCODES[av])
               else:
>>>>>>             raise error, "internal: unsupported set operator"
 3354:     emit(OPCODES[FAILURE])
       
>>>>>> def _optimize_charset(charset, fixup, fixes, isunicode):
           # internal: optimize character set
 3354:     out = []
 3354:     tail = []
 3354:     charmap = bytearray(256)
20284:     for op, av in charset:
16950:         while True:
16950:             try:
16950:                 if op is LITERAL:
14131:                     if fixup:
  560:                         i = fixup(av)
  560:                         charmap[i] = 1
  559:                         if fixes and i in fixes:
    8:                             for k in fixes[i]:
    5:                                 charmap[k] = 1
                           else:
13571:                         charmap[av] = 1
 2819:                 elif op is RANGE:
 1016:                     r = range(av[0], av[1]+1)
 1016:                     if fixup:
  391:                         r = map(fixup, r)
 1016:                     if fixup and fixes:
  414:                         for i in r:
  394:                             charmap[i] = 1
  390:                             if i in fixes:
   31:                                 for k in fixes[i]:
   18:                                     charmap[k] = 1
                           else:
19320:                         for i in r:
18333:                             charmap[i] = 1
 1803:                 elif op is NEGATE:
  214:                     out.append((op, av))
                       else:
 1589:                     tail.append((op, av))
   20:             except IndexError:
   20:                 if len(charmap) == 256:
                           # character set contains non-UCS1 character codes
   20:                     charmap += b'\0' * 0xff00
   20:                     continue
                       # character set contains non-BMP character codes
>>>>>>                 if fixup and isunicode and op is RANGE:
>>>>>>                     lo, hi = av
>>>>>>                     ranges = [av]
                           # There are only two ranges of cased astral characters:
                           # 10400-1044F (Deseret) and 118A0-118DF (Warang Citi).
>>>>>>                     _fixup_range(max(0x10000, lo), min(0x11fff, hi),
>>>>>>                                  ranges, fixup)
>>>>>>                     for lo, hi in ranges:
>>>>>>                         if lo == hi:
>>>>>>                             tail.append((LITERAL, hi))
                               else:
>>>>>>                             tail.append((RANGE, (lo, hi)))
                       else:
>>>>>>                     tail.append((op, av))
16930:             break
       
           # compress character map
 3354:     runs = []
 3354:     q = 0
 6136:     while True:
 6136:         p = charmap.find(b'\1', q)
 6136:         if p < 0:
 3016:             break
 3120:         if len(runs) >= 2:
  321:             runs = None
  321:             break
 2799:         q = charmap.find(b'\0', p)
 2799:         if q < 0:
   17:             runs.append((p, len(charmap)))
   17:             break
 2782:         runs.append((p, q))
 3354:     if runs is not None:
               # use literal/range
 5190:         for p, q in runs:
 2157:             if q - p == 1:
 1228:                 out.append((LITERAL, p))
                   else:
  929:                 out.append((RANGE, (p, q - 1)))
 3033:         out += tail
               # if the case was changed or new representation is more compact
 3033:         if fixup or len(out) < len(charset):
 1049:             return out
               # else original character set is good enough
 1984:         return charset
       
           # use bitmap
  321:     if len(charmap) == 256:
  308:         data = _mk_bitmap(charmap)
  308:         out.append((CHARSET, data))
  308:         out += tail
  308:         return out
       
           # To represent a big charset, first a bitmap of all characters in the
           # set is constructed. Then, this bitmap is sliced into chunks of 256
           # characters, duplicate chunks are eliminated, and each chunk is
           # given a number. In the compiled expression, the charset is
           # represented by a 32-bit word sequence, consisting of one word for
           # the number of different chunks, a sequence of 256 bytes (64 words)
           # of chunk numbers indexed by their original chunk position, and a
           # sequence of 256-bit chunks (8 words each).
       
           # Compression is normally good: in a typical charset, large ranges of
           # Unicode will be either completely excluded (e.g. if only cyrillic
           # letters are to be matched), or completely included (e.g. if large
           # subranges of Kanji match). These ranges will be represented by
           # chunks of all one-bits or all zero-bits.
       
           # Matching can be also done efficiently: the more significant byte of
           # the Unicode character is an index into the chunk number, and the
           # less significant byte is a bit index in the chunk (just like the
           # CHARSET matching).
       
           # In UCS-4 mode, the BIGCHARSET opcode still supports only subsets
           # of the basic multilingual plane; an efficient representation
           # for all of Unicode has not yet been developed.
       
   13:     charmap = bytes(charmap) # should be hashable
   13:     comps = {}
   13:     mapping = bytearray(256)
   13:     block = 0
   13:     data = bytearray()
 3341:     for i in range(0, 65536, 256):
 3328:         chunk = charmap[i: i + 256]
 3328:         if chunk in comps:
 2779:             mapping[i // 256] = comps[chunk]
               else:
  549:             mapping[i // 256] = comps[chunk] = block
  549:             block += 1
  549:             data += chunk
   13:     data = _mk_bitmap(data)
   13:     data[0:0] = [block] + _bytes_to_codes(mapping)
   13:     out.append((BIGCHARSET, data))
   13:     out += tail
   13:     return out
       
>>>>>> def _fixup_range(lo, hi, ranges, fixup):
>>>>>>     for i in map(fixup, range(lo, hi+1)):
>>>>>>         for k, (lo, hi) in enumerate(ranges):
>>>>>>             if i < lo:
>>>>>>                 if l == lo - 1:
>>>>>>                     ranges[k] = (i, hi)
                       else:
>>>>>>                     ranges.insert(k, (i, i))
>>>>>>                 break
>>>>>>             elif i > hi:
>>>>>>                 if i == hi + 1:
>>>>>>                     ranges[k] = (lo, i)
>>>>>>                     break
                   else:
>>>>>>                 break
               else:
>>>>>>             ranges.append((i, i))
       
>>>>>> _CODEBITS = _sre.CODESIZE * 8
>>>>>> _BITS_TRANS = b'0' + b'1' * 255
>>>>>> def _mk_bitmap(bits, _CODEBITS=_CODEBITS, _int=int):
  321:     s = bytes(bits).translate(_BITS_TRANS)[::-1]
  321:     return [_int(s[i - _CODEBITS: i], 2)
 7177:             for i in range(len(s), 0, -_CODEBITS)]
       
>>>>>> def _bytes_to_codes(b):
           # Convert block indices to word array
   13:     import array
   13:     if _sre.CODESIZE == 2:
>>>>>>         code = 'H'
           else:
   13:         code = 'I'
   13:     a = array.array(code, bytes(b))
   13:     assert a.itemsize == _sre.CODESIZE
   13:     assert len(a) * a.itemsize == len(b)
   13:     return a.tolist()
       
>>>>>> def _simple(av):
           # check if av is a "simple" operator
 3851:     lo, hi = av[2].getwidth()
 3851:     return lo == hi == 1 and av[2][0][0] != SUBPATTERN
       
>>>>>> def _compile_info(code, pattern, flags):
           # internal: compile an info block.  in the current version,
           # this contains min/max pattern width, and an optional literal
           # prefix or a character map
 8305:     lo, hi = pattern.getwidth()
 8305:     if not lo and hi:
  224:         return # not worth it
           # look for a literal prefix
 8081:     prefix = []
 8081:     prefixappend = prefix.append
 8081:     prefix_skip = 0
 8081:     charset = [] # not used
 8081:     charsetappend = charset.append
 8081:     if not (flags & SRE_FLAG_IGNORECASE):
               # look for literal prefix
34892:         for op, av in pattern.data:
30394:             if op is LITERAL:
27558:                 if len(prefix) == prefix_skip:
27535:                     prefix_skip = prefix_skip + 1
27558:                 prefixappend(av)
 2836:             elif op is SUBPATTERN and len(av[1]) == 1:
  750:                 op, av = av[1][0]
  750:                 if op is LITERAL:
  165:                     prefixappend(av)
                       else:
  585:                     break
                   else:
 2086:                 break
               # if no prefix, look for charset prefix
 7169:         if not prefix and pattern.data:
 1768:             op, av = pattern.data[0]
 1768:             if op is SUBPATTERN and av[1]:
  420:                 op, av = av[1][0]
  420:                 if op is LITERAL:
  107:                     charsetappend((op, av))
  313:                 elif op is BRANCH:
  143:                     c = []
  143:                     cappend = c.append
  315:                     for p in av[1]:
  244:                         if not p:
    8:                             break
  236:                         op, av = p[0]
  236:                         if op is LITERAL:
  172:                             cappend((op, av))
                               else:
   64:                             break
                           else:
   71:                         charset = c
 1348:             elif op is BRANCH:
   48:                 c = []
   48:                 cappend = c.append
10086:                 for p in av[1]:
10070:                     if not p:
>>>>>>                         break
10070:                     op, av = p[0]
10070:                     if op is LITERAL:
10038:                         cappend((op, av))
                           else:
   32:                         break
                       else:
   16:                     charset = c
 1300:             elif op is IN:
  114:                 charset = av
       ##     if prefix:
       ##         print "*** PREFIX", prefix, prefix_skip
       ##     if charset:
       ##         print "*** CHARSET", charset
           # add an info block
 8081:     emit = code.append
 8081:     emit(OPCODES[INFO])
 8081:     skip = len(code); emit(0)
           # literal flag
 8081:     mask = 0
 8081:     if prefix:
 5334:         mask = SRE_INFO_PREFIX
 5334:         if len(prefix) == prefix_skip == len(pattern.data):
 4412:             mask = mask + SRE_INFO_LITERAL
 2747:     elif charset:
  308:         mask = mask + SRE_INFO_CHARSET
 8081:     emit(mask)
           # pattern length
 8081:     if lo < MAXCODE:
 8081:         emit(lo)
           else:
>>>>>>         emit(MAXCODE)
>>>>>>         prefix = prefix[:MAXCODE]
 8081:     if hi < MAXCODE:
 6560:         emit(hi)
           else:
 1521:         emit(0)
           # add literal prefix
 8081:     if prefix:
 5334:         emit(len(prefix)) # length
 5334:         emit(prefix_skip) # skip
 5334:         code.extend(prefix)
               # generate overlap table
 5334:         table = [-1] + ([0]*len(prefix))
33057:         for i in xrange(len(prefix)):
27723:             table[i+1] = table[i]+1
49776:             while table[i+1] > 0 and prefix[i] != prefix[table[i+1]-1]:
22053:                 table[i+1] = table[table[i+1]-1]+1
 5334:         code.extend(table[1:]) # don't store first entry
 2747:     elif charset:
  308:         _compile_charset(charset, flags, code)
 8081:     code[skip] = len(code) - skip
       
>>>>>> try:
>>>>>>     unicode
>>>>>> except NameError:
>>>>>>     STRING_TYPES = (type(""),)
       else:
>>>>>>     STRING_TYPES = (type(""), type(unicode("")))
       
>>>>>> def isstring(obj):
18083:     for tp in STRING_TYPES:
18080:         if isinstance(obj, tp):
16756:             return 1
    3:     return 0
       
>>>>>> def _code(p, flags):
       
 8305:     flags = p.pattern.flags | flags
 8305:     code = []
       
           # compile info block
 8305:     _compile_info(code, p, flags)
       
           # compile the pattern
 8305:     _compile(code, p.data, flags)
       
 8305:     code.append(OPCODES[SUCCESS])
       
 8305:     return code
       
>>>>>> def compile(p, flags=0):
           # internal: convert pattern list to internal format
       
 8379:     if isstring(p):
 8378:         pattern = p
 8378:         p = sre_parse.parse(p, flags)
           else:
    1:         pattern = None
       
 8305:     code = _code(p, flags)
       
           # print code
       
           # XXX: <fl> get rid of this limitation!
 8305:     if p.pattern.groups > 100:
>>>>>>         raise AssertionError(
>>>>>>             "sorry, but this version only supports 100 named groups"
                   )
       
           # map in either direction
 8305:     groupindex = p.pattern.groupdict
 8305:     indexgroup = [None] * p.pattern.groups
 8865:     for k, i in groupindex.items():
  560:         indexgroup[i] = k
       
 8305:     return _sre.compile(
 8305:         pattern, flags | p.pattern.flags, code,
 8305:         p.pattern.groups-1,
 8305:         groupindex, indexgroup
               )
