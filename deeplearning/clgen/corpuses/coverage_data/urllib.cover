       """Open an arbitrary URL.
       
       See the following document for more info on URLs:
       "Names and Addresses, URIs, URLs, URNs, URCs", at
       http://www.w3.org/pub/WWW/Addressing/Overview.html
       
       See also the HTTP spec (from which the error codes are derived):
       "HTTP - Hypertext Transfer Protocol", at
       http://www.w3.org/pub/WWW/Protocols/
       
       Related standards and specs:
       - RFC1808: the "relative URL" spec. (authoritative status)
       - RFC1738 - the "URL standard". (authoritative status)
       - RFC1630 - the "URI spec". (informational status)
       
       The object returned by URLopener().open(file) will differ per
       protocol.  All you know is that is has methods read(), readline(),
       readlines(), fileno(), close() and info().  The read*(), fileno()
       and close() methods work like those of open files.
       The info() method returns a mimetools.Message object which can be
       used to query various info about the object, if available.
       (mimetools.Message objects are queried with the getheader() method.)
    1: """
       
    1: import string
    1: import socket
    1: import os
    1: import time
    1: import sys
    1: import base64
    1: import re
       
    1: from urlparse import urljoin as basejoin
       
    1: __all__ = ["urlopen", "URLopener", "FancyURLopener", "urlretrieve",
    1:            "urlcleanup", "quote", "quote_plus", "unquote", "unquote_plus",
    1:            "urlencode", "url2pathname", "pathname2url", "splittag",
    1:            "localhost", "thishost", "ftperrors", "basejoin", "unwrap",
    1:            "splittype", "splithost", "splituser", "splitpasswd", "splitport",
    1:            "splitnport", "splitquery", "splitattr", "splitvalue",
    1:            "getproxies"]
       
    1: __version__ = '1.17'    # XXX This version is not always updated :-(
       
    1: MAXFTPCACHE = 10        # Trim the ftp cache beyond this size
       
       # Helper for non-unix systems
    1: if os.name == 'nt':
>>>>>>     from nturl2path import url2pathname, pathname2url
    1: elif os.name == 'riscos':
>>>>>>     from rourl2path import url2pathname, pathname2url
       else:
    1:     def url2pathname(pathname):
               """OS-specific conversion from a relative URL of the 'file' scheme
               to a file system path; not recommended for general use."""
   37:         return unquote(pathname)
       
    1:     def pathname2url(pathname):
               """OS-specific conversion from a file system path to a relative URL
               of the 'file' scheme; not recommended for general use."""
    9:         return quote(pathname)
       
       # This really consists of two pieces:
       # (1) a class which handles opening of all sorts of URLs
       #     (plus assorted utilities etc.)
       # (2) a set of functions for parsing URLs
       # XXX Should these be separated out into different modules?
       
       
       # Shortcut for basic usage
    1: _urlopener = None
    1: def urlopen(url, data=None, proxies=None, context=None):
           """Create a file-like object for the specified URL to read from."""
   33:     from warnings import warnpy3k
   33:     warnpy3k("urllib.urlopen() has been removed in Python 3.0 in "
   33:              "favor of urllib2.urlopen()", stacklevel=2)
       
           global _urlopener
   33:     if proxies is not None or context is not None:
>>>>>>         opener = FancyURLopener(proxies=proxies, context=context)
   33:     elif not _urlopener:
    1:         opener = FancyURLopener()
    1:         _urlopener = opener
           else:
   32:         opener = _urlopener
   33:     if data is None:
   33:         return opener.open(url)
           else:
>>>>>>         return opener.open(url, data)
    1: def urlretrieve(url, filename=None, reporthook=None, data=None, context=None):
           global _urlopener
    8:     if context is not None:
>>>>>>         opener = FancyURLopener(context=context)
    8:     elif not _urlopener:
>>>>>>         _urlopener = opener = FancyURLopener()
           else:
    8:         opener = _urlopener
    8:     return opener.retrieve(url, filename, reporthook, data)
    1: def urlcleanup():
  392:     if _urlopener:
   33:         _urlopener.cleanup()
  392:     _safe_quoters.clear()
  392:     ftpcache.clear()
       
       # check for SSL
    1: try:
    1:     import ssl
>>>>>> except:
>>>>>>     _have_ssl = False
       else:
    1:     _have_ssl = True
       
       # exception raised when downloaded size does not match content-length
    2: class ContentTooShortError(IOError):
    1:     def __init__(self, message, content):
    2:         IOError.__init__(self, message)
    2:         self.content = content
       
    1: ftpcache = {}
    2: class URLopener:
           """Class to open URLs.
           This is a class rather than just a subroutine because we may need
           more than one set of global protocol-specific options.
           Note -- this is a base class for those who don't want the
           automatic handling of errors type 302 (relocated) and 401
    1:     (authorization needed)."""
       
    1:     __tempfiles = None
       
    1:     version = "Python-urllib/%s" % __version__
       
           # Constructor
    1:     def __init__(self, proxies=None, context=None, **x509):
    5:         if proxies is None:
    5:             proxies = getproxies()
    5:         assert hasattr(proxies, 'has_key'), "proxies must be a mapping"
    5:         self.proxies = proxies
    5:         self.key_file = x509.get('key_file')
    5:         self.cert_file = x509.get('cert_file')
    5:         self.context = context
    5:         self.addheaders = [('User-Agent', self.version), ('Accept', '*/*')]
    5:         self.__tempfiles = []
    5:         self.__unlink = os.unlink # See cleanup()
    5:         self.tempcache = None
               # Undocumented feature: if you assign {} to tempcache,
               # it is used to cache files retrieved with
               # self.retrieve().  This is not enabled by default
               # since it does not work for changing documents (and I
               # haven't got the logic to check expiration headers
               # yet).
    5:         self.ftpcache = ftpcache
               # Undocumented feature: you can use a different
               # ftp cache by assigning to the .ftpcache member;
               # in case you want logically independent URL openers
               # XXX This is not threadsafe.  Bah.
       
    1:     def __del__(self):
    4:         self.close()
       
    1:     def close(self):
    4:         self.cleanup()
       
    1:     def cleanup(self):
               # This code sometimes runs when the rest of this module
               # has already been deleted, so it can't use any globals
               # or import anything.
   37:         if self.__tempfiles:
    3:             for file in self.__tempfiles:
    2:                 try:
    2:                     self.__unlink(file)
>>>>>>                 except OSError:
>>>>>>                     pass
    1:             del self.__tempfiles[:]
   37:         if self.tempcache:
>>>>>>             self.tempcache.clear()
       
    1:     def addheader(self, *args):
               """Add a header to be used by the HTTP interface only
               e.g. u.addheader('Accept', 'sound/basic')"""
>>>>>>         self.addheaders.append(args)
       
           # External interface
    1:     def open(self, fullurl, data=None):
               """Use URLopener().open(file) instead of open(file, 'r')."""
   43:         fullurl = unwrap(toBytes(fullurl))
               # percent encode url, fixing lame server errors for e.g, like space
               # within url paths.
   43:         fullurl = quote(fullurl, safe="%/:=&?~#+!$,;'@()*[]|")
   43:         if self.tempcache and fullurl in self.tempcache:
>>>>>>             filename, headers = self.tempcache[fullurl]
>>>>>>             fp = open(filename, 'rb')
>>>>>>             return addinfourl(fp, headers, fullurl)
   43:         urltype, url = splittype(fullurl)
   43:         if not urltype:
    1:             urltype = 'file'
   43:         if urltype in self.proxies:
>>>>>>             proxy = self.proxies[urltype]
>>>>>>             urltype, proxyhost = splittype(proxy)
>>>>>>             host, selector = splithost(proxyhost)
>>>>>>             url = (host, fullurl) # Signal special case to open_*()
               else:
   43:             proxy = None
   43:         name = 'open_' + urltype
   43:         self.type = urltype
   43:         name = name.replace('-', '_')
   43:         if not hasattr(self, name):
>>>>>>             if proxy:
>>>>>>                 return self.open_unknown_proxy(proxy, fullurl, data)
                   else:
>>>>>>                 return self.open_unknown(fullurl, data)
   43:         try:
   43:             if data is None:
   43:                 return getattr(self, name)(url)
                   else:
>>>>>>                 return getattr(self, name)(url, data)
   17:         except socket.error, msg:
>>>>>>             raise IOError, ('socket error', msg), sys.exc_info()[2]
       
    1:     def open_unknown(self, fullurl, data=None):
               """Overridable interface to open unknown URL type."""
>>>>>>         type, url = splittype(fullurl)
>>>>>>         raise IOError, ('url error', 'unknown url type', type)
       
    1:     def open_unknown_proxy(self, proxy, fullurl, data=None):
               """Overridable interface to open unknown URL type."""
>>>>>>         type, url = splittype(fullurl)
>>>>>>         raise IOError, ('url error', 'invalid proxy for %s' % type, proxy)
       
           # External interface
    1:     def retrieve(self, url, filename=None, reporthook=None, data=None):
               """retrieve(url) returns (filename, headers) for a local object
               or (tempfilename, headers) for a remote object."""
    8:         url = unwrap(toBytes(url))
    8:         if self.tempcache and url in self.tempcache:
>>>>>>             return self.tempcache[url]
    8:         type, url1 = splittype(url)
    8:         if filename is None and (not type or type == 'file'):
    1:             try:
    1:                 fp = self.open_local_file(url1)
    1:                 hdrs = fp.info()
    1:                 fp.close()
    1:                 return url2pathname(splithost(url1)[1]), hdrs
>>>>>>             except IOError:
>>>>>>                 pass
    7:         fp = self.open(url, data)
    7:         try:
    7:             headers = fp.info()
    7:             if filename:
    5:                 tfp = open(filename, 'wb')
                   else:
    2:                 import tempfile
    2:                 garbage, path = splittype(url)
    2:                 garbage, path = splithost(path or "")
    2:                 path, garbage = splitquery(path or "")
    2:                 path, garbage = splitattr(path or "")
    2:                 suffix = os.path.splitext(path)[1]
    2:                 (fd, filename) = tempfile.mkstemp(suffix)
    2:                 self.__tempfiles.append(filename)
    2:                 tfp = os.fdopen(fd, 'wb')
    7:             try:
    7:                 result = filename, headers
    7:                 if self.tempcache is not None:
>>>>>>                     self.tempcache[url] = result
    7:                 bs = 1024*8
    7:                 size = -1
    7:                 read = 0
    7:                 blocknum = 0
    7:                 if "content-length" in headers:
    7:                     size = int(headers["Content-Length"])
    7:                 if reporthook:
    5:                     reporthook(blocknum, bs, size)
    7:                 while 1:
   12:                     block = fp.read(bs)
   12:                     if block == "":
    7:                         break
    5:                     read += len(block)
    5:                     tfp.write(block)
    5:                     blocknum += 1
    5:                     if reporthook:
    4:                         reporthook(blocknum, bs, size)
                   finally:
    7:                 tfp.close()
               finally:
    7:             fp.close()
       
               # raise exception if actual size does not match content-length header
    7:         if size >= 0 and read < size:
    2:             raise ContentTooShortError("retrieval incomplete: got only %i out "
    2:                                        "of %i bytes" % (read, size), result)
       
    5:         return result
       
           # Each method named open_<type> knows how to open that type of URL
       
    1:     def open_http(self, url, data=None):
               """Use HTTP protocol."""
   20:         import httplib
   20:         user_passwd = None
   20:         proxy_passwd= None
   20:         if isinstance(url, str):
   20:             host, selector = splithost(url)
   20:             if host:
   20:                 user_passwd, host = splituser(host)
   20:                 host = unquote(host)
   20:             realhost = host
               else:
>>>>>>             host, selector = url
                   # check whether the proxy contains authorization information
>>>>>>             proxy_passwd, host = splituser(host)
                   # now we proceed with the url we want to obtain
>>>>>>             urltype, rest = splittype(selector)
>>>>>>             url = rest
>>>>>>             user_passwd = None
>>>>>>             if urltype.lower() != 'http':
>>>>>>                 realhost = None
                   else:
>>>>>>                 realhost, rest = splithost(rest)
>>>>>>                 if realhost:
>>>>>>                     user_passwd, realhost = splituser(realhost)
>>>>>>                 if user_passwd:
>>>>>>                     selector = "%s://%s%s" % (urltype, realhost, rest)
>>>>>>                 if proxy_bypass(realhost):
>>>>>>                     host = realhost
       
                   #print "proxy via http:", host, selector
   20:         if not host: raise IOError, ('http error', 'no host given')
       
   20:         if proxy_passwd:
>>>>>>             proxy_passwd = unquote(proxy_passwd)
>>>>>>             proxy_auth = base64.b64encode(proxy_passwd).strip()
               else:
   20:             proxy_auth = None
       
   20:         if user_passwd:
    2:             user_passwd = unquote(user_passwd)
    2:             auth = base64.b64encode(user_passwd).strip()
               else:
   18:             auth = None
   20:         h = httplib.HTTP(host)
   20:         if data is not None:
>>>>>>             h.putrequest('POST', selector)
>>>>>>             h.putheader('Content-Type', 'application/x-www-form-urlencoded')
>>>>>>             h.putheader('Content-Length', '%d' % len(data))
               else:
   20:             h.putrequest('GET', selector)
   20:         if proxy_auth: h.putheader('Proxy-Authorization', 'Basic %s' % proxy_auth)
   20:         if auth: h.putheader('Authorization', 'Basic %s' % auth)
   20:         if realhost: h.putheader('Host', realhost)
   60:         for args in self.addheaders: h.putheader(*args)
   20:         h.endheaders(data)
   20:         errcode, errmsg, headers = h.getreply()
   20:         fp = h.getfile()
   20:         if errcode == -1:
    1:             if fp: fp.close()
                   # something went wrong with the HTTP status line
    1:             raise IOError, ('http protocol error', 0,
    1:                             'got a bad status line', None)
               # According to RFC 2616, "2xx" code indicates that the client's
               # request was successfully received, understood, and accepted.
   19:         if (200 <= errcode < 300):
    6:             return addinfourl(fp, headers, "http:" + url, errcode)
               else:
   13:             if data is None:
   13:                 return self.http_error(url, fp, errcode, errmsg, headers)
                   else:
>>>>>>                 return self.http_error(url, fp, errcode, errmsg, headers, data)
       
    1:     def http_error(self, url, fp, errcode, errmsg, headers, data=None):
               """Handle http errors.
               Derived class can override this, or provide specific handlers
               named http_error_DDD where DDD is the 3-digit error code."""
               # First check if there's a specific handler for this error
   13:         name = 'http_error_%d' % errcode
   13:         if hasattr(self, name):
   12:             method = getattr(self, name)
   12:             if data is None:
   12:                 result = method(url, fp, errcode, errmsg, headers)
                   else:
>>>>>>                 result = method(url, fp, errcode, errmsg, headers, data)
>>>>>>             if result: return result
    1:         return self.http_error_default(url, fp, errcode, errmsg, headers)
       
    1:     def http_error_default(self, url, fp, errcode, errmsg, headers):
               """Default error handler: close the connection and raise IOError."""
    1:         fp.close()
    1:         raise IOError, ('http error', errcode, errmsg, headers)
       
    1:     if _have_ssl:
    1:         def open_https(self, url, data=None):
                   """Use HTTPS protocol."""
       
>>>>>>             import httplib
>>>>>>             user_passwd = None
>>>>>>             proxy_passwd = None
>>>>>>             if isinstance(url, str):
>>>>>>                 host, selector = splithost(url)
>>>>>>                 if host:
>>>>>>                     user_passwd, host = splituser(host)
>>>>>>                     host = unquote(host)
>>>>>>                 realhost = host
                   else:
>>>>>>                 host, selector = url
                       # here, we determine, whether the proxy contains authorization information
>>>>>>                 proxy_passwd, host = splituser(host)
>>>>>>                 urltype, rest = splittype(selector)
>>>>>>                 url = rest
>>>>>>                 user_passwd = None
>>>>>>                 if urltype.lower() != 'https':
>>>>>>                     realhost = None
                       else:
>>>>>>                     realhost, rest = splithost(rest)
>>>>>>                     if realhost:
>>>>>>                         user_passwd, realhost = splituser(realhost)
>>>>>>                     if user_passwd:
>>>>>>                         selector = "%s://%s%s" % (urltype, realhost, rest)
                       #print "proxy via https:", host, selector
>>>>>>             if not host: raise IOError, ('https error', 'no host given')
>>>>>>             if proxy_passwd:
>>>>>>                 proxy_passwd = unquote(proxy_passwd)
>>>>>>                 proxy_auth = base64.b64encode(proxy_passwd).strip()
                   else:
>>>>>>                 proxy_auth = None
>>>>>>             if user_passwd:
>>>>>>                 user_passwd = unquote(user_passwd)
>>>>>>                 auth = base64.b64encode(user_passwd).strip()
                   else:
>>>>>>                 auth = None
>>>>>>             h = httplib.HTTPS(host, 0,
>>>>>>                               key_file=self.key_file,
>>>>>>                               cert_file=self.cert_file,
>>>>>>                               context=self.context)
>>>>>>             if data is not None:
>>>>>>                 h.putrequest('POST', selector)
>>>>>>                 h.putheader('Content-Type',
>>>>>>                             'application/x-www-form-urlencoded')
>>>>>>                 h.putheader('Content-Length', '%d' % len(data))
                   else:
>>>>>>                 h.putrequest('GET', selector)
>>>>>>             if proxy_auth: h.putheader('Proxy-Authorization', 'Basic %s' % proxy_auth)
>>>>>>             if auth: h.putheader('Authorization', 'Basic %s' % auth)
>>>>>>             if realhost: h.putheader('Host', realhost)
>>>>>>             for args in self.addheaders: h.putheader(*args)
>>>>>>             h.endheaders(data)
>>>>>>             errcode, errmsg, headers = h.getreply()
>>>>>>             fp = h.getfile()
>>>>>>             if errcode == -1:
>>>>>>                 if fp: fp.close()
                       # something went wrong with the HTTP status line
>>>>>>                 raise IOError, ('http protocol error', 0,
>>>>>>                                 'got a bad status line', None)
                   # According to RFC 2616, "2xx" code indicates that the client's
                   # request was successfully received, understood, and accepted.
>>>>>>             if (200 <= errcode < 300):
>>>>>>                 return addinfourl(fp, headers, "https:" + url, errcode)
                   else:
>>>>>>                 if data is None:
>>>>>>                     return self.http_error(url, fp, errcode, errmsg, headers)
                       else:
>>>>>>                     return self.http_error(url, fp, errcode, errmsg, headers,
>>>>>>                                            data)
       
    1:     def open_file(self, url):
               """Use local file or FTP depending on form of URL."""
   20:         if not isinstance(url, str):
>>>>>>             raise IOError, ('file error', 'proxy support for file protocol currently not implemented')
   20:         if url[:2] == '//' and url[2:3] != '/' and url[2:12].lower() != 'localhost/':
>>>>>>             return self.open_ftp(url)
               else:
   20:             return self.open_local_file(url)
       
    1:     def open_local_file(self, url):
               """Use local file."""
   21:         import mimetypes, mimetools, email.utils
   21:         try:
   21:             from cStringIO import StringIO
>>>>>>         except ImportError:
>>>>>>             from StringIO import StringIO
   21:         host, file = splithost(url)
   21:         localname = url2pathname(file)
   21:         try:
   21:             stats = os.stat(localname)
    2:         except OSError, e:
    2:             raise IOError(e.errno, e.strerror, e.filename)
   19:         size = stats.st_size
   19:         modified = email.utils.formatdate(stats.st_mtime, usegmt=True)
   19:         mtype = mimetypes.guess_type(url)[0]
   19:         headers = mimetools.Message(StringIO(
   19:             'Content-Type: %s\nContent-Length: %d\nLast-modified: %s\n' %
   19:             (mtype or 'text/plain', size, modified)))
   19:         if not host:
   18:             urlfile = file
   18:             if file[:1] == '/':
    5:                 urlfile = 'file://' + file
   13:             elif file[:2] == './':
    1:                 raise ValueError("local file url may start with / or file:. Unknown url of type: %s" % url)
   17:             return addinfourl(open(localname, 'rb'),
   17:                               headers, urlfile)
    1:         host, port = splitport(host)
    1:         if not port \
    1:            and socket.gethostbyname(host) in (localhost(), thishost()):
    1:             urlfile = file
    1:             if file[:1] == '/':
    1:                 urlfile = 'file://' + file
    1:             return addinfourl(open(localname, 'rb'),
    1:                               headers, urlfile)
>>>>>>         raise IOError, ('local file error', 'not on local host')
       
    1:     def open_ftp(self, url):
               """Use FTP protocol."""
    1:         if not isinstance(url, str):
>>>>>>             raise IOError, ('ftp error', 'proxy support for ftp protocol currently not implemented')
    1:         import mimetypes, mimetools
    1:         try:
    1:             from cStringIO import StringIO
>>>>>>         except ImportError:
>>>>>>             from StringIO import StringIO
    1:         host, path = splithost(url)
    1:         if not host: raise IOError, ('ftp error', 'no host given')
    1:         host, port = splitport(host)
    1:         user, host = splituser(host)
    1:         if user: user, passwd = splitpasswd(user)
    1:         else: passwd = None
    1:         host = unquote(host)
    1:         user = user or ''
    1:         passwd = passwd or ''
    1:         host = socket.gethostbyname(host)
    1:         if not port:
    1:             import ftplib
    1:             port = ftplib.FTP_PORT
               else:
>>>>>>             port = int(port)
    1:         path, attrs = splitattr(path)
    1:         path = unquote(path)
    1:         dirs = path.split('/')
    1:         dirs, file = dirs[:-1], dirs[-1]
    1:         if dirs and not dirs[0]: dirs = dirs[1:]
    1:         if dirs and not dirs[0]: dirs[0] = '/'
    1:         key = user, host, port, '/'.join(dirs)
               # XXX thread unsafe!
    1:         if len(self.ftpcache) > MAXFTPCACHE:
                   # Prune the cache, rather arbitrarily
>>>>>>             for k in self.ftpcache.keys():
>>>>>>                 if k != key:
>>>>>>                     v = self.ftpcache[k]
>>>>>>                     del self.ftpcache[k]
>>>>>>                     v.close()
    1:         try:
    1:             if not key in self.ftpcache:
                       self.ftpcache[key] = \
    1:                     ftpwrapper(user, passwd, host, port, dirs)
>>>>>>             if not file: type = 'D'
>>>>>>             else: type = 'I'
>>>>>>             for attr in attrs:
>>>>>>                 attr, value = splitvalue(attr)
>>>>>>                 if attr.lower() == 'type' and \
>>>>>>                    value in ('a', 'A', 'i', 'I', 'd', 'D'):
>>>>>>                     type = value.upper()
>>>>>>             (fp, retrlen) = self.ftpcache[key].retrfile(file, type)
>>>>>>             mtype = mimetypes.guess_type("ftp:" + url)[0]
>>>>>>             headers = ""
>>>>>>             if mtype:
>>>>>>                 headers += "Content-Type: %s\n" % mtype
>>>>>>             if retrlen is not None and retrlen >= 0:
>>>>>>                 headers += "Content-Length: %d\n" % retrlen
>>>>>>             headers = mimetools.Message(StringIO(headers))
>>>>>>             return addinfourl(fp, headers, "ftp:" + url)
    1:         except ftperrors(), msg:
    1:             raise IOError, ('ftp error', msg), sys.exc_info()[2]
       
    1:     def open_data(self, url, data=None):
               """Use "data" URL."""
>>>>>>         if not isinstance(url, str):
>>>>>>             raise IOError, ('data error', 'proxy support for data protocol currently not implemented')
               # ignore POSTed data
               #
               # syntax of data URLs:
               # dataurl   := "data:" [ mediatype ] [ ";base64" ] "," data
               # mediatype := [ type "/" subtype ] *( ";" parameter )
               # data      := *urlchar
               # parameter := attribute "=" value
>>>>>>         import mimetools
>>>>>>         try:
>>>>>>             from cStringIO import StringIO
>>>>>>         except ImportError:
>>>>>>             from StringIO import StringIO
>>>>>>         try:
>>>>>>             [type, data] = url.split(',', 1)
>>>>>>         except ValueError:
>>>>>>             raise IOError, ('data error', 'bad data URL')
>>>>>>         if not type:
>>>>>>             type = 'text/plain;charset=US-ASCII'
>>>>>>         semi = type.rfind(';')
>>>>>>         if semi >= 0 and '=' not in type[semi:]:
>>>>>>             encoding = type[semi+1:]
>>>>>>             type = type[:semi]
               else:
>>>>>>             encoding = ''
>>>>>>         msg = []
>>>>>>         msg.append('Date: %s'%time.strftime('%a, %d %b %Y %H:%M:%S GMT',
>>>>>>                                             time.gmtime(time.time())))
>>>>>>         msg.append('Content-type: %s' % type)
>>>>>>         if encoding == 'base64':
>>>>>>             data = base64.decodestring(data)
               else:
>>>>>>             data = unquote(data)
>>>>>>         msg.append('Content-Length: %d' % len(data))
>>>>>>         msg.append('')
>>>>>>         msg.append(data)
>>>>>>         msg = '\n'.join(msg)
>>>>>>         f = StringIO(msg)
>>>>>>         headers = mimetools.Message(f, 0)
               #f.fileno = None     # needed for addinfourl
>>>>>>         return addinfourl(f, headers, url)
       
       
    2: class FancyURLopener(URLopener):
    1:     """Derived class with handlers for errors we can handle (perhaps)."""
       
    1:     def __init__(self, *args, **kwargs):
    3:         URLopener.__init__(self, *args, **kwargs)
    3:         self.auth_cache = {}
    3:         self.tries = 0
    3:         self.maxtries = 10
       
    1:     def http_error_default(self, url, fp, errcode, errmsg, headers):
               """Default error handling -- don't raise an exception."""
    1:         return addinfourl(fp, headers, "http:" + url, errcode)
       
    1:     def http_error_302(self, url, fp, errcode, errmsg, headers, data=None):
               """Error 302 -- relocated (temporarily)."""
   11:         self.tries += 1
   11:         try:
   11:             if self.maxtries and self.tries >= self.maxtries:
>>>>>>                 if hasattr(self, "http_error_500"):
>>>>>>                     meth = self.http_error_500
                       else:
>>>>>>                     meth = self.http_error_default
>>>>>>                 return meth(url, fp, 500,
>>>>>>                             "Internal Server Error: Redirect Recursion",
>>>>>>                             headers)
   11:             result = self.redirect_internal(url, fp, errcode, errmsg,
   11:                                             headers, data)
>>>>>>             return result
               finally:
   11:             self.tries = 0
       
    1:     def redirect_internal(self, url, fp, errcode, errmsg, headers, data):
   11:         if 'location' in headers:
   11:             newurl = headers['location']
>>>>>>         elif 'uri' in headers:
>>>>>>             newurl = headers['uri']
               else:
>>>>>>             return
   11:         fp.close()
               # In case the server sent a relative URL, join with original:
   11:         newurl = basejoin(self.type + ":" + url, newurl)
       
               # For security reasons we do not allow redirects to protocols
               # other than HTTP, HTTPS or FTP.
   11:         newurl_lower = newurl.lower()
   11:         if not (newurl_lower.startswith('http://') or
   11:                 newurl_lower.startswith('https://') or
   11:                 newurl_lower.startswith('ftp://')):
   11:             raise IOError('redirect error', errcode,
   11:                           errmsg + " - Redirection to url '%s' is not allowed" %
   11:                           newurl,
   11:                           headers)
       
>>>>>>         return self.open(newurl)
       
    1:     def http_error_301(self, url, fp, errcode, errmsg, headers, data=None):
               """Error 301 -- also relocated (permanently)."""
>>>>>>         return self.http_error_302(url, fp, errcode, errmsg, headers, data)
       
    1:     def http_error_303(self, url, fp, errcode, errmsg, headers, data=None):
               """Error 303 -- also relocated (essentially identical to 302)."""
>>>>>>         return self.http_error_302(url, fp, errcode, errmsg, headers, data)
       
    1:     def http_error_307(self, url, fp, errcode, errmsg, headers, data=None):
               """Error 307 -- relocated, but turn POST into error."""
>>>>>>         if data is None:
>>>>>>             return self.http_error_302(url, fp, errcode, errmsg, headers, data)
               else:
>>>>>>             return self.http_error_default(url, fp, errcode, errmsg, headers)
       
    1:     def http_error_401(self, url, fp, errcode, errmsg, headers, data=None):
               """Error 401 -- authentication required.
               This function supports Basic authentication only."""
    1:         if not 'www-authenticate' in headers:
    1:             URLopener.http_error_default(self, url, fp,
    1:                                          errcode, errmsg, headers)
>>>>>>         stuff = headers['www-authenticate']
>>>>>>         import re
>>>>>>         match = re.match('[ \t]*([^ \t]+)[ \t]+realm="([^"]*)"', stuff)
>>>>>>         if not match:
>>>>>>             URLopener.http_error_default(self, url, fp,
>>>>>>                                          errcode, errmsg, headers)
>>>>>>         scheme, realm = match.groups()
>>>>>>         if scheme.lower() != 'basic':
>>>>>>             URLopener.http_error_default(self, url, fp,
>>>>>>                                          errcode, errmsg, headers)
>>>>>>         name = 'retry_' + self.type + '_basic_auth'
>>>>>>         if data is None:
>>>>>>             return getattr(self,name)(url, realm)
               else:
>>>>>>             return getattr(self,name)(url, realm, data)
       
    1:     def http_error_407(self, url, fp, errcode, errmsg, headers, data=None):
               """Error 407 -- proxy authentication required.
               This function supports Basic authentication only."""
>>>>>>         if not 'proxy-authenticate' in headers:
>>>>>>             URLopener.http_error_default(self, url, fp,
>>>>>>                                          errcode, errmsg, headers)
>>>>>>         stuff = headers['proxy-authenticate']
>>>>>>         import re
>>>>>>         match = re.match('[ \t]*([^ \t]+)[ \t]+realm="([^"]*)"', stuff)
>>>>>>         if not match:
>>>>>>             URLopener.http_error_default(self, url, fp,
>>>>>>                                          errcode, errmsg, headers)
>>>>>>         scheme, realm = match.groups()
>>>>>>         if scheme.lower() != 'basic':
>>>>>>             URLopener.http_error_default(self, url, fp,
>>>>>>                                          errcode, errmsg, headers)
>>>>>>         name = 'retry_proxy_' + self.type + '_basic_auth'
>>>>>>         if data is None:
>>>>>>             return getattr(self,name)(url, realm)
               else:
>>>>>>             return getattr(self,name)(url, realm, data)
       
    1:     def retry_proxy_http_basic_auth(self, url, realm, data=None):
>>>>>>         host, selector = splithost(url)
>>>>>>         newurl = 'http://' + host + selector
>>>>>>         proxy = self.proxies['http']
>>>>>>         urltype, proxyhost = splittype(proxy)
>>>>>>         proxyhost, proxyselector = splithost(proxyhost)
>>>>>>         i = proxyhost.find('@') + 1
>>>>>>         proxyhost = proxyhost[i:]
>>>>>>         user, passwd = self.get_user_passwd(proxyhost, realm, i)
>>>>>>         if not (user or passwd): return None
>>>>>>         proxyhost = quote(user, safe='') + ':' + quote(passwd, safe='') + '@' + proxyhost
>>>>>>         self.proxies['http'] = 'http://' + proxyhost + proxyselector
>>>>>>         if data is None:
>>>>>>             return self.open(newurl)
               else:
>>>>>>             return self.open(newurl, data)
       
    1:     def retry_proxy_https_basic_auth(self, url, realm, data=None):
>>>>>>         host, selector = splithost(url)
>>>>>>         newurl = 'https://' + host + selector
>>>>>>         proxy = self.proxies['https']
>>>>>>         urltype, proxyhost = splittype(proxy)
>>>>>>         proxyhost, proxyselector = splithost(proxyhost)
>>>>>>         i = proxyhost.find('@') + 1
>>>>>>         proxyhost = proxyhost[i:]
>>>>>>         user, passwd = self.get_user_passwd(proxyhost, realm, i)
>>>>>>         if not (user or passwd): return None
>>>>>>         proxyhost = quote(user, safe='') + ':' + quote(passwd, safe='') + '@' + proxyhost
>>>>>>         self.proxies['https'] = 'https://' + proxyhost + proxyselector
>>>>>>         if data is None:
>>>>>>             return self.open(newurl)
               else:
>>>>>>             return self.open(newurl, data)
       
    1:     def retry_http_basic_auth(self, url, realm, data=None):
>>>>>>         host, selector = splithost(url)
>>>>>>         i = host.find('@') + 1
>>>>>>         host = host[i:]
>>>>>>         user, passwd = self.get_user_passwd(host, realm, i)
>>>>>>         if not (user or passwd): return None
>>>>>>         host = quote(user, safe='') + ':' + quote(passwd, safe='') + '@' + host
>>>>>>         newurl = 'http://' + host + selector
>>>>>>         if data is None:
>>>>>>             return self.open(newurl)
               else:
>>>>>>             return self.open(newurl, data)
       
    1:     def retry_https_basic_auth(self, url, realm, data=None):
>>>>>>         host, selector = splithost(url)
>>>>>>         i = host.find('@') + 1
>>>>>>         host = host[i:]
>>>>>>         user, passwd = self.get_user_passwd(host, realm, i)
>>>>>>         if not (user or passwd): return None
>>>>>>         host = quote(user, safe='') + ':' + quote(passwd, safe='') + '@' + host
>>>>>>         newurl = 'https://' + host + selector
>>>>>>         if data is None:
>>>>>>             return self.open(newurl)
               else:
>>>>>>             return self.open(newurl, data)
       
    1:     def get_user_passwd(self, host, realm, clear_cache=0):
>>>>>>         key = realm + '@' + host.lower()
>>>>>>         if key in self.auth_cache:
>>>>>>             if clear_cache:
>>>>>>                 del self.auth_cache[key]
                   else:
>>>>>>                 return self.auth_cache[key]
>>>>>>         user, passwd = self.prompt_user_passwd(host, realm)
>>>>>>         if user or passwd: self.auth_cache[key] = (user, passwd)
>>>>>>         return user, passwd
       
    1:     def prompt_user_passwd(self, host, realm):
               """Override this in a GUI environment!"""
>>>>>>         import getpass
>>>>>>         try:
>>>>>>             user = raw_input("Enter username for %s at %s: " % (realm,
>>>>>>                                                                 host))
>>>>>>             passwd = getpass.getpass("Enter password for %s in %s at %s: " %
>>>>>>                 (user, realm, host))
>>>>>>             return user, passwd
>>>>>>         except KeyboardInterrupt:
>>>>>>             print
>>>>>>             return None, None
       
       
       # Utility functions
       
    1: _localhost = None
    1: def localhost():
           """Return the IP address of the magic hostname 'localhost'."""
           global _localhost
    1:     if _localhost is None:
    1:         _localhost = socket.gethostbyname('localhost')
    1:     return _localhost
       
    1: _thishost = None
    1: def thishost():
           """Return the IP address of the current host."""
           global _thishost
    1:     if _thishost is None:
    1:         try:
    1:             _thishost = socket.gethostbyname(socket.gethostname())
>>>>>>         except socket.gaierror:
>>>>>>             _thishost = socket.gethostbyname('localhost')
    1:     return _thishost
       
    1: _ftperrors = None
    1: def ftperrors():
           """Return the set of errors raised by the FTP class."""
           global _ftperrors
    1:     if _ftperrors is None:
    1:         import ftplib
    1:         _ftperrors = ftplib.all_errors
    1:     return _ftperrors
       
    1: _noheaders = None
    1: def noheaders():
           """Return an empty mimetools.Message object."""
           global _noheaders
>>>>>>     if _noheaders is None:
>>>>>>         import mimetools
>>>>>>         try:
>>>>>>             from cStringIO import StringIO
>>>>>>         except ImportError:
>>>>>>             from StringIO import StringIO
>>>>>>         _noheaders = mimetools.Message(StringIO(), 0)
>>>>>>         _noheaders.fp.close()   # Recycle file descriptor
>>>>>>     return _noheaders
       
       
       # Utility classes
       
    2: class ftpwrapper:
    1:     """Class used by open_ftp() for cache of open FTP connections."""
       
           def __init__(self, user, passwd, host, port, dirs,
    1:                  timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
    1:                  persistent=True):
    1:         self.user = user
    1:         self.passwd = passwd
    1:         self.host = host
    1:         self.port = port
    1:         self.dirs = dirs
    1:         self.timeout = timeout
    1:         self.refcount = 0
    1:         self.keepalive = persistent
    1:         try:
    1:             self.init()
    1:         except:
    1:             self.close()
    1:             raise
       
    1:     def init(self):
    1:         import ftplib
    1:         self.busy = 0
    1:         self.ftp = ftplib.FTP()
    1:         self.ftp.connect(self.host, self.port, self.timeout)
>>>>>>         self.ftp.login(self.user, self.passwd)
>>>>>>         _target = '/'.join(self.dirs)
>>>>>>         self.ftp.cwd(_target)
       
    1:     def retrfile(self, file, type):
>>>>>>         import ftplib
>>>>>>         self.endtransfer()
>>>>>>         if type in ('d', 'D'): cmd = 'TYPE A'; isdir = 1
>>>>>>         else: cmd = 'TYPE ' + type; isdir = 0
>>>>>>         try:
>>>>>>             self.ftp.voidcmd(cmd)
>>>>>>         except ftplib.all_errors:
>>>>>>             self.init()
>>>>>>             self.ftp.voidcmd(cmd)
>>>>>>         conn = None
>>>>>>         if file and not isdir:
                   # Try to retrieve as a file
>>>>>>             try:
>>>>>>                 cmd = 'RETR ' + file
>>>>>>                 conn, retrlen = self.ftp.ntransfercmd(cmd)
>>>>>>             except ftplib.error_perm, reason:
>>>>>>                 if str(reason)[:3] != '550':
>>>>>>                     raise IOError, ('ftp error', reason), sys.exc_info()[2]
>>>>>>         if not conn:
                   # Set transfer mode to ASCII!
>>>>>>             self.ftp.voidcmd('TYPE A')
                   # Try a directory listing. Verify that directory exists.
>>>>>>             if file:
>>>>>>                 pwd = self.ftp.pwd()
>>>>>>                 try:
>>>>>>                     try:
>>>>>>                         self.ftp.cwd(file)
>>>>>>                     except ftplib.error_perm, reason:
>>>>>>                         raise IOError, ('ftp error', reason), sys.exc_info()[2]
                       finally:
>>>>>>                     self.ftp.cwd(pwd)
>>>>>>                 cmd = 'LIST ' + file
                   else:
>>>>>>                 cmd = 'LIST'
>>>>>>             conn, retrlen = self.ftp.ntransfercmd(cmd)
>>>>>>         self.busy = 1
>>>>>>         ftpobj = addclosehook(conn.makefile('rb'), self.file_close)
>>>>>>         self.refcount += 1
>>>>>>         conn.close()
               # Pass back both a suitably decorated object and a retrieval length
>>>>>>         return (ftpobj, retrlen)
       
    1:     def endtransfer(self):
    1:         self.busy = 0
       
    1:     def close(self):
    1:         self.keepalive = False
    1:         if self.refcount <= 0:
    1:             self.real_close()
       
    1:     def file_close(self):
>>>>>>         self.endtransfer()
>>>>>>         self.refcount -= 1
>>>>>>         if self.refcount <= 0 and not self.keepalive:
>>>>>>             self.real_close()
       
    1:     def real_close(self):
    1:         self.endtransfer()
    1:         try:
    1:             self.ftp.close()
>>>>>>         except ftperrors():
>>>>>>             pass
       
    2: class addbase:
    1:     """Base class for addinfo and addclosehook."""
       
    1:     def __init__(self, fp):
   79:         self.fp = fp
   79:         self.read = self.fp.read
   79:         self.readline = self.fp.readline
   79:         if hasattr(self.fp, "readlines"): self.readlines = self.fp.readlines
   79:         if hasattr(self.fp, "fileno"):
   67:             self.fileno = self.fp.fileno
               else:
   12:             self.fileno = lambda: None
   79:         if hasattr(self.fp, "__iter__"):
   73:             self.__iter__ = self.fp.__iter__
   73:             if hasattr(self.fp, "next"):
   73:                 self.next = self.fp.next
       
    1:     def __repr__(self):
>>>>>>         return '<%s at %r whose fp = %r>' % (self.__class__.__name__,
>>>>>>                                              id(self), self.fp)
       
    1:     def close(self):
   40:         self.read = None
   40:         self.readline = None
   40:         self.readlines = None
   40:         self.fileno = None
   40:         if self.fp: self.fp.close()
   40:         self.fp = None
       
    2: class addclosehook(addbase):
    1:     """Class to add a close hook to an open file."""
       
    1:     def __init__(self, fp, closehook, *hookargs):
>>>>>>         addbase.__init__(self, fp)
>>>>>>         self.closehook = closehook
>>>>>>         self.hookargs = hookargs
       
    1:     def close(self):
>>>>>>         try:
>>>>>>             closehook = self.closehook
>>>>>>             hookargs = self.hookargs
>>>>>>             if closehook:
>>>>>>                 self.closehook = None
>>>>>>                 self.hookargs = None
>>>>>>                 closehook(*hookargs)
               finally:
>>>>>>             addbase.close(self)
       
       
    2: class addinfo(addbase):
    1:     """class to add an info() method to an open file."""
       
    1:     def __init__(self, fp, headers):
>>>>>>         addbase.__init__(self, fp)
>>>>>>         self.headers = headers
       
    1:     def info(self):
>>>>>>         return self.headers
       
    2: class addinfourl(addbase):
    1:     """class to add info() and geturl() methods to an open file."""
       
    1:     def __init__(self, fp, headers, url, code=None):
   79:         addbase.__init__(self, fp)
   79:         self.headers = headers
   79:         self.url = url
   79:         self.code = code
       
    1:     def info(self):
   54:         return self.headers
       
    1:     def getcode(self):
    4:         return self.code
       
    1:     def geturl(self):
   13:         return self.url
       
       
       # Utilities to parse URLs (most of these return None for missing parts):
       # unwrap('<URL:type://host/path>') --> 'type://host/path'
       # splittype('type:opaquestring') --> 'type', 'opaquestring'
       # splithost('//host[:port]/path') --> 'host[:port]', '/path'
       # splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'
       # splitpasswd('user:passwd') -> 'user', 'passwd'
       # splitport('host:port') --> 'host', 'port'
       # splitquery('/path?query') --> '/path', 'query'
       # splittag('/path#tag') --> '/path', 'tag'
       # splitattr('/path;attr1=value1;attr2=value2;...') ->
       #   '/path', ['attr1=value1', 'attr2=value2', ...]
       # splitvalue('attr=value') --> 'attr', 'value'
       # unquote('abc%20def') -> 'abc def'
       # quote('abc def') -> 'abc%20def')
       
    1: try:
    1:     unicode
>>>>>> except NameError:
>>>>>>     def _is_unicode(x):
>>>>>>         return 0
       else:
    1:     def _is_unicode(x):
  848:         return isinstance(x, unicode)
       
    1: def toBytes(url):
           """toBytes(u"URL") --> 'URL'."""
           # Most URL schemes require ASCII. If that changes, the conversion
           # can be relaxed
   53:     if _is_unicode(url):
    2:         try:
    2:             url = url.encode("ASCII")
    1:         except UnicodeError:
    1:             raise UnicodeError("URL " + repr(url) +
    1:                                " contains non-ASCII characters")
   52:     return url
       
    1: def unwrap(url):
           """unwrap('<URL:type://host/path>') --> 'type://host/path'."""
  416:     url = url.strip()
  416:     if url[:1] == '<' and url[-1:] == '>':
    2:         url = url[1:-1].strip()
  416:     if url[:4] == 'URL:': url = url[4:].strip()
  416:     return url
       
    1: _typeprog = None
    1: def splittype(url):
           """splittype('type:opaquestring') --> 'type', 'opaquestring'."""
           global _typeprog
  296:     if _typeprog is None:
    1:         import re
    1:         _typeprog = re.compile('^([^/:]+):')
       
  296:     match = _typeprog.match(url)
  296:     if match:
  253:         scheme = match.group(1)
  253:         return scheme.lower(), url[len(scheme) + 1:]
   43:     return None, url
       
    1: _hostprog = None
    1: def splithost(url):
           """splithost('//host[:port]/path') --> 'host[:port]', '/path'."""
           global _hostprog
  191:     if _hostprog is None:
    1:         _hostprog = re.compile('//([^/#?]*)(.*)', re.DOTALL)
       
  191:     match = _hostprog.match(url)
  191:     if match:
  176:         host_port = match.group(1)
  176:         path = match.group(2)
  176:         if path and not path.startswith('/'):
    4:             path = '/' + path
  176:         return host_port, path
   15:     return None, url
       
    1: _userprog = None
    1: def splituser(host):
           """splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'."""
           global _userprog
   91:     if _userprog is None:
    1:         import re
    1:         _userprog = re.compile('^(.*)@(.*)$')
       
   91:     match = _userprog.match(host)
   91:     if match: return match.group(1, 2)
   76:     return None, host
       
    1: _passwdprog = None
    1: def splitpasswd(user):
           """splitpasswd('user:passwd') -> 'user', 'passwd'."""
           global _passwdprog
   22:     if _passwdprog is None:
    1:         import re
    1:         _passwdprog = re.compile('^([^:]*):(.*)$',re.S)
       
   22:     match = _passwdprog.match(user)
   22:     if match: return match.group(1, 2)
    4:     return user, None
       
       # splittag('/path#tag') --> '/path', 'tag'
    1: _portprog = None
    1: def splitport(host):
           """splitport('host:port') --> 'host', 'port'."""
           global _portprog
  167:     if _portprog is None:
    1:         import re
    1:         _portprog = re.compile('^(.*):([0-9]*)$')
       
  167:     match = _portprog.match(host)
  167:     if match:
   61:         host, port = match.groups()
   61:         if port:
   60:             return host, port
  107:     return host, None
       
    1: _nportprog = None
    1: def splitnport(host, defport=-1):
           """Split host and port, returning numeric port.
           Return given default port if no ':' found; defaults to -1.
           Return numerical port if a valid number are found after ':'.
           Return None if ':' but not a valid number."""
           global _nportprog
    9:     if _nportprog is None:
    1:         import re
    1:         _nportprog = re.compile('^(.*):(.*)$')
       
    9:     match = _nportprog.match(host)
    9:     if match:
    5:         host, port = match.group(1, 2)
    5:         if port:
    3:             try:
    3:                 nport = int(port)
    2:             except ValueError:
    2:                 nport = None
    3:             return host, nport
    6:     return host, defport
       
    1: _queryprog = None
    1: def splitquery(url):
           """splitquery('/path?query') --> '/path', 'query'."""
           global _queryprog
    6:     if _queryprog is None:
    1:         import re
    1:         _queryprog = re.compile('^(.*)\?([^?]*)$')
       
    6:     match = _queryprog.match(url)
    6:     if match: return match.group(1, 2)
    3:     return url, None
       
    1: _tagprog = None
    1: def splittag(url):
           """splittag('/path#tag') --> '/path', 'tag'."""
           global _tagprog
  369:     if _tagprog is None:
    1:         import re
    1:         _tagprog = re.compile('^(.*)#([^#]*)$')
       
  369:     match = _tagprog.match(url)
  369:     if match: return match.group(1, 2)
  359:     return url, None
       
    1: def splitattr(url):
           """splitattr('/path;attr1=value1;attr2=value2;...') ->
               '/path', ['attr1=value1', 'attr2=value2', ...]."""
   13:     words = url.split(';')
   13:     return words[0], words[1:]
       
    1: _valueprog = None
    1: def splitvalue(attr):
           """splitvalue('attr=value') --> 'attr', 'value'."""
           global _valueprog
    6:     if _valueprog is None:
    1:         import re
    1:         _valueprog = re.compile('^([^=]*)=(.*)$')
       
    6:     match = _valueprog.match(attr)
    6:     if match: return match.group(1, 2)
    1:     return attr, None
       
       # urlparse contains a duplicate of this method to avoid a circular import.  If
       # you update this method, also update the copy in urlparse.  This code
       # duplication does not exist in Python3.
       
    1: _hexdig = '0123456789ABCDEFabcdef'
   24: _hextochr = dict((a + b, chr(int(a + b, 16)))
  507:                  for a in _hexdig for b in _hexdig)
    1: _asciire = re.compile('([\x00-\x7f]+)')
       
    1: def unquote(s):
           """unquote('abc%20def') -> 'abc def'."""
  794:     if _is_unicode(s):
    1:         if '%' not in s:
>>>>>>             return s
    1:         bits = _asciire.split(s)
    1:         res = [bits[0]]
    1:         append = res.append
    2:         for i in range(1, len(bits), 2):
    1:             append(unquote(str(bits[i])).decode('latin1'))
    1:             append(bits[i + 1])
    1:         return ''.join(res)
       
  793:     bits = s.split('%')
           # fastpath
  793:     if len(bits) == 1:
  428:         return s
  365:     res = [bits[0]]
  365:     append = res.append
 1455:     for item in bits[1:]:
 1090:         try:
 1090:             append(_hextochr[item[:2]])
 1087:             append(item[2:])
    3:         except KeyError:
    3:             append('%')
    3:             append(item)
  365:     return ''.join(res)
       
    1: def unquote_plus(s):
           """unquote('%7e/abc+def') -> '~/abc def'"""
  130:     s = s.replace('+', ' ')
  130:     return unquote(s)
       
    1: always_safe = ('ABCDEFGHIJKLMNOPQRSTUVWXYZ'
                      'abcdefghijklmnopqrstuvwxyz'
                      '0123456789' '_.-')
    1: _safe_map = {}
  257: for i, c in zip(xrange(256), str(bytearray(xrange(256)))):
  256:     _safe_map[c] = c if (i < 128 and c in always_safe) else '%{:02X}'.format(i)
    1: _safe_quoters = {}
       
    1: def quote(s, safe='/'):
           """quote('abc def') -> 'abc%20def'
       
           Each part of a URL, e.g. the path info, the query, etc., has a
           different set of reserved characters that must be quoted.
       
           RFC 2396 Uniform Resource Identifiers (URI): Generic Syntax lists
           the following reserved characters.
       
           reserved    = ";" | "/" | "?" | ":" | "@" | "&" | "=" | "+" |
                         "$" | ","
       
           Each of these characters is reserved in some component of a URL,
           but not necessarily in all of them.
       
           By default, the quote function is intended for quoting the path
           section of a URL.  Thus, it will not encode '/'.  This character
           is reserved, but in typical usage the quote function is being
           called on a path where the existing slash characters are used as
           reserved characters.
           """
           # fastpath
  594:     if not s:
   24:         if s is None:
    1:             raise TypeError('None object cannot be quoted')
   23:         return s
  570:     cachekey = (safe, always_safe)
  570:     try:
  570:         (quoter, safe) = _safe_quoters[cachekey]
   17:     except KeyError:
   17:         safe_map = _safe_map.copy()
  105:         safe_map.update([(c, c) for c in safe])
   17:         quoter = safe_map.__getitem__
   17:         safe = always_safe + safe
   17:         _safe_quoters[cachekey] = (quoter, safe)
  570:     if not s.rstrip(safe):
  428:         return s
  142:     return ''.join(map(quoter, s))
       
    1: def quote_plus(s, safe=''):
           """Quote the query fragment of a URL; replacing ' ' with '+'"""
   82:     if ' ' in s:
    8:         s = quote(s, safe + ' ')
    8:         return s.replace(' ', '+')
   74:     return quote(s, safe)
       
    1: def urlencode(query, doseq=0):
           """Encode a sequence of two-element tuples or dictionary into a URL query string.
       
           If any values in the query arg are sequences and doseq is true, each
           sequence element is converted to a separate parameter.
       
           If the query arg is a sequence of two-element tuples, the order of the
           parameters in the output will match the order of parameters in the
           input.
           """
       
    7:     if hasattr(query,"items"):
               # mapping objects
    6:         query = query.items()
           else:
               # it's a bother at times that strings and string-like objects are
               # sequences...
    1:         try:
                   # non-sequence items should not work with len()
                   # non-empty strings will fail this
    1:             if len(query) and not isinstance(query[0], tuple):
>>>>>>                 raise TypeError
                   # zero-length sequences of all types will get here and succeed,
                   # but that's a minor nit - since the original implementation
                   # allowed empty dicts that type of behavior probably should be
                   # preserved for consistency
>>>>>>         except TypeError:
>>>>>>             ty,va,tb = sys.exc_info()
>>>>>>             raise TypeError, "not a valid non-string sequence or mapping object", tb
       
    7:     l = []
    7:     if not doseq:
               # preserve old behavior
   18:         for k, v in query:
   12:             k = quote_plus(str(k))
   12:             v = quote_plus(str(v))
   12:             l.append(k + '=' + v)
           else:
    2:         for k, v in query:
    1:             k = quote_plus(str(k))
    1:             if isinstance(v, str):
>>>>>>                 v = quote_plus(v)
>>>>>>                 l.append(k + '=' + v)
    1:             elif _is_unicode(v):
                       # is there a reasonable way to convert to ASCII?
                       # encode generates a string, but "replace" or "ignore"
                       # lose information and "strict" can raise UnicodeError
>>>>>>                 v = quote_plus(v.encode("ASCII","replace"))
>>>>>>                 l.append(k + '=' + v)
                   else:
    1:                 try:
                           # is this a sufficient test for sequence-ness?
    1:                     len(v)
>>>>>>                 except TypeError:
                           # not a sequence
>>>>>>                     v = quote_plus(str(v))
>>>>>>                     l.append(k + '=' + v)
                       else:
                           # loop over the sequence
    4:                     for elt in v:
    3:                         l.append(k + '=' + quote_plus(str(elt)))
    7:     return '&'.join(l)
       
       # Proxy handling
    1: def getproxies_environment():
           """Return a dictionary of scheme -> proxy server URL mappings.
       
           Scan the environment for variables named <scheme>_proxy;
           this seems to be the standard convention.  In order to prefer lowercase
           variables, we process the environment in two passes, first matches any
           and second matches only lower case proxies.
       
           If you need a different way, you can pass a proxies dictionary to the
           [Fancy]URLopener constructor.
           """
           # Get all variables
   80:     proxies = {}
 1733:     for name, value in os.environ.items():
 1653:         name = name.lower()
 1653:         if value and name[-6:] == '_proxy':
   58:             proxies[name[:-6]] = value
       
           # CVE-2016-1000110 - If we are running as CGI script, forget HTTP_PROXY
           # (non-all-lowercase) as it may be set from the web server by a "Proxy:"
           # header from the client
           # If "proxy" is lowercase, it will still be used thanks to the next block
   80:     if 'REQUEST_METHOD' in os.environ:
    2:         proxies.pop('http', None)
       
           # Get lowercase variables
 1733:     for name, value in os.environ.items():
 1653:         if name[-6:] == '_proxy':
   29:             name = name.lower()
   29:             if value:
    9:                 proxies[name[:-6]] = value
                   else:
   20:                 proxies.pop(name[:-6], None)
       
   80:     return proxies
       
    1: def proxy_bypass_environment(host, proxies=None):
           """Test if proxies should not be used for a particular host.
       
           Checks the proxies dict for the value of no_proxy, which should be a
           list of comma separated DNS suffixes, or '*' for all hosts.
           """
   35:     if proxies is None:
   33:         proxies = getproxies_environment()
           # don't bypass, if no_proxy isn't specified
   35:     try:
   35:         no_proxy = proxies['no']
    2:     except KeyError:
    2:         return 0
           # '*' is special case for always bypass
   33:     if no_proxy == '*':
>>>>>>         return 1
           # strip port off host
   33:     hostonly, port = splitport(host)
           # check if the host ends with any of the DNS suffixes
  148:     no_proxy_list = [proxy.strip() for proxy in no_proxy.split(',')]
   91:     for name in no_proxy_list:
   82:         if name:
   82:             name = name.lstrip('.')  # ignore leading dots
   82:             name = re.escape(name)
   82:             pattern = r'(.+\.)?%s$' % name
   82:             if (re.match(pattern, hostonly, re.I)
   65:                     or re.match(pattern, host, re.I)):
   24:                 return 1
           # otherwise, don't bypass
    9:     return 0
       
       
    1: if sys.platform == 'darwin':
    1:     from _scproxy import _get_proxy_settings, _get_proxies
       
    1:     def proxy_bypass_macosx_sysconf(host):
               """
               Return True iff this host shouldn't be accessed using a proxy
       
               This function uses the MacOSX framework SystemConfiguration
               to fetch the proxy information.
               """
   15:         import re
   15:         import socket
   15:         from fnmatch import fnmatch
       
   15:         hostonly, port = splitport(host)
       
   15:         def ip2num(ipAddr):
   26:             parts = ipAddr.split('.')
   26:             parts = map(int, parts)
   26:             if len(parts) != 4:
   13:                 parts = (parts + [0, 0, 0, 0])[:4]
   26:             return (parts[0] << 24) | (parts[1] << 16) | (parts[2] << 8) | parts[3]
       
   15:         proxy_settings = _get_proxy_settings()
       
               # Check for simple host names:
   15:         if '.' not in host:
    4:             if proxy_settings['exclude_simple']:
>>>>>>                 return True
       
   15:         hostIP = None
       
   45:         for value in proxy_settings.get('exceptions', ()):
                   # Items in the list are strings like these: *.local, 169.254/16
   30:             if not value: continue
       
   30:             m = re.match(r"(\d+(?:\.\d+)*)(/\d+)?", value)
   30:             if m is not None:
   15:                 if hostIP is None:
   15:                     try:
   15:                         hostIP = socket.gethostbyname(hostonly)
   13:                         hostIP = ip2num(hostIP)
    2:                     except socket.error:
    2:                         continue
       
   13:                 base = ip2num(m.group(1))
   13:                 mask = m.group(2)
   13:                 if mask is None:
>>>>>>                     mask = 8 * (m.group(1).count('.') + 1)
       
                       else:
   13:                     mask = int(mask[1:])
   13:                 mask = 32 - mask
       
   13:                 if (hostIP >> mask) == (base >> mask):
>>>>>>                     return True
       
   15:             elif fnmatch(host, value):
>>>>>>                 return True
       
   15:         return False
       
    1:     def getproxies_macosx_sysconf():
               """Return a dictionary of scheme -> proxy server URL mappings.
       
               This function uses the MacOSX framework SystemConfiguration
               to fetch the proxy information.
               """
   22:         return _get_proxies()
       
    1:     def proxy_bypass(host):
               """Return True, if a host should be bypassed.
       
               Checks proxy settings gathered from the environment, if specified, or
               from the MacOSX framework SystemConfiguration.
               """
   17:         proxies = getproxies_environment()
   17:         if proxies:
    2:             return proxy_bypass_environment(host, proxies)
               else:
   15:             return proxy_bypass_macosx_sysconf(host)
       
    1:     def getproxies():
   22:         return getproxies_environment() or getproxies_macosx_sysconf()
       
>>>>>> elif os.name == 'nt':
>>>>>>     def getproxies_registry():
               """Return a dictionary of scheme -> proxy server URL mappings.
       
               Win32 uses the registry to store proxies.
       
               """
>>>>>>         proxies = {}
>>>>>>         try:
>>>>>>             import _winreg
>>>>>>         except ImportError:
                   # Std module, so should be around - but you never know!
>>>>>>             return proxies
>>>>>>         try:
>>>>>>             internetSettings = _winreg.OpenKey(_winreg.HKEY_CURRENT_USER,
>>>>>>                 r'Software\Microsoft\Windows\CurrentVersion\Internet Settings')
>>>>>>             proxyEnable = _winreg.QueryValueEx(internetSettings,
>>>>>>                                                'ProxyEnable')[0]
>>>>>>             if proxyEnable:
                       # Returned as Unicode but problems if not converted to ASCII
>>>>>>                 proxyServer = str(_winreg.QueryValueEx(internetSettings,
>>>>>>                                                        'ProxyServer')[0])
>>>>>>                 if '=' in proxyServer:
                           # Per-protocol settings
>>>>>>                     for p in proxyServer.split(';'):
>>>>>>                         protocol, address = p.split('=', 1)
                               # See if address has a type:// prefix
>>>>>>                         import re
>>>>>>                         if not re.match('^([^/:]+)://', address):
>>>>>>                             address = '%s://%s' % (protocol, address)
>>>>>>                         proxies[protocol] = address
                       else:
                           # Use one setting for all protocols
>>>>>>                     if proxyServer[:5] == 'http:':
>>>>>>                         proxies['http'] = proxyServer
                           else:
>>>>>>                         proxies['http'] = 'http://%s' % proxyServer
>>>>>>                         proxies['https'] = 'https://%s' % proxyServer
>>>>>>                         proxies['ftp'] = 'ftp://%s' % proxyServer
>>>>>>             internetSettings.Close()
>>>>>>         except (WindowsError, ValueError, TypeError):
                   # Either registry key not found etc, or the value in an
                   # unexpected format.
                   # proxies already set up to be empty so nothing to do
>>>>>>             pass
>>>>>>         return proxies
       
>>>>>>     def getproxies():
               """Return a dictionary of scheme -> proxy server URL mappings.
       
               Returns settings gathered from the environment, if specified,
               or the registry.
       
               """
>>>>>>         return getproxies_environment() or getproxies_registry()
       
>>>>>>     def proxy_bypass_registry(host):
>>>>>>         try:
>>>>>>             import _winreg
>>>>>>             import re
>>>>>>         except ImportError:
                   # Std modules, so should be around - but you never know!
>>>>>>             return 0
>>>>>>         try:
>>>>>>             internetSettings = _winreg.OpenKey(_winreg.HKEY_CURRENT_USER,
>>>>>>                 r'Software\Microsoft\Windows\CurrentVersion\Internet Settings')
>>>>>>             proxyEnable = _winreg.QueryValueEx(internetSettings,
>>>>>>                                                'ProxyEnable')[0]
>>>>>>             proxyOverride = str(_winreg.QueryValueEx(internetSettings,
>>>>>>                                                      'ProxyOverride')[0])
                   # ^^^^ Returned as Unicode but problems if not converted to ASCII
>>>>>>         except WindowsError:
>>>>>>             return 0
>>>>>>         if not proxyEnable or not proxyOverride:
>>>>>>             return 0
               # try to make a host list from name and IP address.
>>>>>>         rawHost, port = splitport(host)
>>>>>>         host = [rawHost]
>>>>>>         try:
>>>>>>             addr = socket.gethostbyname(rawHost)
>>>>>>             if addr != rawHost:
>>>>>>                 host.append(addr)
>>>>>>         except socket.error:
>>>>>>             pass
>>>>>>         try:
>>>>>>             fqdn = socket.getfqdn(rawHost)
>>>>>>             if fqdn != rawHost:
>>>>>>                 host.append(fqdn)
>>>>>>         except socket.error:
>>>>>>             pass
               # make a check value list from the registry entry: replace the
               # '<local>' string by the localhost entry and the corresponding
               # canonical entry.
>>>>>>         proxyOverride = proxyOverride.split(';')
               # now check if we match one of the registry values.
>>>>>>         for test in proxyOverride:
>>>>>>             if test == '<local>':
>>>>>>                 if '.' not in rawHost:
>>>>>>                     return 1
>>>>>>             test = test.replace(".", r"\.")     # mask dots
>>>>>>             test = test.replace("*", r".*")     # change glob sequence
>>>>>>             test = test.replace("?", r".")      # change glob char
>>>>>>             for val in host:
                       # print "%s <--> %s" %( test, val )
>>>>>>                 if re.match(test, val, re.I):
>>>>>>                     return 1
>>>>>>         return 0
       
>>>>>>     def proxy_bypass(host):
               """Return True, if the host should be bypassed.
       
               Checks proxy settings gathered from the environment, if specified,
               or the registry.
               """
>>>>>>         proxies = getproxies_environment()
>>>>>>         if proxies:
>>>>>>             return proxy_bypass_environment(host, proxies)
               else:
>>>>>>             return proxy_bypass_registry(host)
       
       else:
           # By default use environment variables
>>>>>>     getproxies = getproxies_environment
>>>>>>     proxy_bypass = proxy_bypass_environment
       
       # Test and time quote() and unquote()
    1: def test1():
>>>>>>     s = ''
>>>>>>     for i in range(256): s = s + chr(i)
>>>>>>     s = s*4
>>>>>>     t0 = time.time()
>>>>>>     qs = quote(s)
>>>>>>     uqs = unquote(qs)
>>>>>>     t1 = time.time()
>>>>>>     if uqs != s:
>>>>>>         print 'Wrong!'
>>>>>>     print repr(s)
>>>>>>     print repr(qs)
>>>>>>     print repr(uqs)
>>>>>>     print round(t1 - t0, 3), 'sec'
       
       
    1: def reporthook(blocknum, blocksize, totalsize):
           # Report during remote transfers
>>>>>>     print "Block number: %d, Block size: %d, Total size: %d" % (
>>>>>>         blocknum, blocksize, totalsize)
