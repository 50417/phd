       # Copyright 2004-2005 Elemental Security, Inc. All Rights Reserved.
       # Licensed to PSF under a Contributor Agreement.
       
       # Modifications:
       # Copyright 2006 Google, Inc. All Rights Reserved.
       # Licensed to PSF under a Contributor Agreement.
       
       """Parser driver.
       
       This provides a high-level interface to parse a file into a syntax tree.
       
    1: """
       
    1: __author__ = "Guido van Rossum <guido@python.org>"
       
    1: __all__ = ["Driver", "load_grammar"]
       
       # Python imports
    1: import codecs
    1: import os
    1: import logging
    1: import StringIO
    1: import sys
       
       # Pgen imports
    1: from . import grammar, parse, token, tokenize, pgen
       
       
    2: class Driver(object):
       
    1:     def __init__(self, grammar, convert=None, logger=None):
 1370:         self.grammar = grammar
 1370:         if logger is None:
  885:             logger = logging.getLogger()
 1370:         self.logger = logger
 1370:         self.convert = convert
       
    1:     def parse_tokens(self, tokens, debug=False):
               """Parse a series of tokens and return the syntax tree."""
               # XXX Move the prefix computation into a wrapper around tokenize.
 3272:         p = parse.Parser(self.grammar, self.convert)
 3272:         p.setup()
 3272:         lineno = 1
 3272:         column = 0
 3272:         type = value = start = end = line_text = None
 3272:         prefix = u""
239179:         for quintuple in tokens:
239179:             type, value, start, end, line_text = quintuple
239179:             if start != (lineno, column):
85014:                 assert (lineno, column) <= start, ((lineno, column), start)
85014:                 s_lineno, s_column = start
85014:                 if lineno < s_lineno:
 5806:                     prefix += "\n" * (s_lineno - lineno)
 5806:                     lineno = s_lineno
 5806:                     column = 0
85014:                 if column < s_column:
84126:                     prefix += line_text[column:s_column]
84126:                     column = s_column
239179:             if type in (tokenize.COMMENT, tokenize.NL):
12343:                 prefix += value
12343:                 lineno, column = end
12343:                 if value.endswith("\n"):
11131:                     lineno += 1
11131:                     column = 0
>>>>>>                 continue
226836:             if type == token.OP:
98346:                 type = grammar.opmap[value]
226836:             if debug:
 3150:                 self.logger.debug("%s %r (prefix=%r)",
 3150:                                   token.tok_name[type], value, prefix)
226836:             if p.addtoken(type, value, (prefix, start)):
 3264:                 if debug:
  216:                     self.logger.debug("Stop.")
 3264:                 break
223564:             prefix = ""
223564:             lineno, column = end
223564:             if value.endswith("\n"):
15307:                 lineno += 1
15307:                 column = 0
               else:
                   # We never broke out -- EOF is too soon (how can this happen???)
>>>>>>             raise parse.ParseError("incomplete input",
>>>>>>                                    type, value, (prefix, start))
 3264:         return p.rootnode
       
    1:     def parse_stream_raw(self, stream, debug=False):
               """Parse a stream and return the syntax tree."""
>>>>>>         tokens = tokenize.generate_tokens(stream.readline)
>>>>>>         return self.parse_tokens(tokens, debug)
       
    1:     def parse_stream(self, stream, debug=False):
               """Parse a stream and return the syntax tree."""
>>>>>>         return self.parse_stream_raw(stream, debug)
       
    1:     def parse_file(self, filename, encoding=None, debug=False):
               """Parse a file and return the syntax tree."""
>>>>>>         stream = codecs.open(filename, "r", encoding)
>>>>>>         try:
>>>>>>             return self.parse_stream(stream, debug)
               finally:
>>>>>>             stream.close()
       
    1:     def parse_string(self, text, debug=False):
               """Parse a string and return the syntax tree."""
 2386:         tokens = tokenize.generate_tokens(StringIO.StringIO(text).readline)
 2386:         return self.parse_tokens(tokens, debug)
       
       
    1: def _generate_pickle_name(gt):
  894:     head, tail = os.path.splitext(gt)
  894:     if tail == ".txt":
  894:         tail = ""
  894:     return head + tail + ".".join(map(str, sys.version_info)) + ".pickle"
       
       
    1: def load_grammar(gt="Grammar.txt", gp=None,
    1:                  save=True, force=False, logger=None):
           """Load the grammar (maybe from a pickle)."""
  891:     if logger is None:
  891:         logger = logging.getLogger()
  891:     gp = _generate_pickle_name(gt) if gp is None else gp
  891:     if force or not _newer(gp, gt):
    3:         logger.info("Generating grammar tables from %s", gt)
    3:         g = pgen.generate_grammar(gt)
    3:         if save:
    2:             logger.info("Writing grammar tables to %s", gp)
    2:             try:
    2:                 g.dump(gp)
>>>>>>             except IOError as e:
>>>>>>                 logger.info("Writing failed: %s", e)
           else:
  888:         g = grammar.Grammar()
  888:         g.load(gp)
  891:     return g
       
       
    1: def _newer(a, b):
           """Inquire whether file a was written since file b."""
  888:     if not os.path.exists(a):
>>>>>>         return False
  888:     if not os.path.exists(b):
    1:         return True
  887:     return os.path.getmtime(a) >= os.path.getmtime(b)
       
       
    1: def main(*args):
           """Main program, when run as a script: produce grammar pickle files.
       
           Calls load_grammar for each argument, a path to a grammar text file.
           """
>>>>>>     if not args:
>>>>>>         args = sys.argv[1:]
>>>>>>     logging.basicConfig(level=logging.INFO, stream=sys.stdout,
>>>>>>                         format='%(message)s')
>>>>>>     for gt in args:
>>>>>>         load_grammar(gt, save=True, force=True)
>>>>>>     return True
       
    1: if __name__ == "__main__":
>>>>>>     sys.exit(int(not main()))
