% The outline proposal needs to identify the research area as
% something rather more specific than (say) Neuroinformatics, Natural
% Language Processing or Automated Reasoning. For those students who
% started the programme with no topic, one would expect an outline
% proposal of around 2-3 pages, detailing the specific research area
% and problem to be addressed, plus a very brief description of the
% idea the student will pursue for solving it.
%
% For those students who started their PhD programme with a specific
% research proposal already, this proposal should be much more fleshed
% out (e.g., 15 pages), providing more details of both the research
% problem and research methods, a more detailed justification of the
% approach and how it will be evaluated, and a scheduled work plan. If
% the student is in a position to write this more detailed proposal at
% this point in the programme, then this can be used as part of the
% deliverable (perhaps with minor amendments) for the formal First
% Year Review in month 9, together with a separate document that
% describes the research achievements to date and how they relate to
% the work plan described in the proposal. Details of the documents to
% be submitted for the First Year Review are given below under “Month
% 9”.
%
% The literature review that forms a part of this submission must be
% relevant to the research area defined in the proposal and serve to
% justify the approach taken in the proposed thesis. The course notes
% for the MSc "Informatics Research Review" course has some notes on
% the form and content of a literature review and how to go about
% tracking down relevant publications.
%
\input{preamble}

% Document starts
\begin{document}

\title{Outline}

\author{Chris Cummins}

\maketitle

\begin{abstract}
  The physical limitations of microprocessor design have forced the
  industry towards increasingly heterogeneous designs to extract
  performance. This trend has not been matched with adequate software
  tools, leading to a growing disparity between the availability of
  parallelism and the ability for application developers to exploit
  it. Algorithmic skeletons simplify parallel programming by providing
  high-level, reusable patterns of computation. Achieving performant
  skeleton implementations is a difficult task; skeleton authors must
  attempt to anticipate and tune for a wide range of architectures and
  use cases. This results in implementations that target the general
  case and cannot provide the performance advantages that are gained
  from tuning low level optimization parameters. Autotuning combined
  with machine learning offers promising performance benefits in these
  situations, but the high cost of training and lack of available
  tools limits the practicality of autotuning for real world
  programming. We believe that performing autotuning at the level of
  the skeleton library can overcome these issues.
\end{abstract}


\section{Introduction}


\section{Background}


\section{Methodology}


\section{Literature Review}


\section{Conclusions}


\label{bibliography}
\printbibliography


\end{document}
