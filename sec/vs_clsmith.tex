\section{Comparison to State-of-the-art}\label{sec:vs_clsmith}

In this section we compare DeepSmith to CLSmith~\cite{Lidbury2015a}, the state-of-the-art in OpenCL compiler testing.

\subsection{Experimental Setup}

We ran each program generator using its default configuration for 48 hours on each of the 10 testbeds of Table~\ref{tab:platforms}. We ran the tests twice, first with optimizations disabled ($-$), then with optimizations enabled ($+$). Total runtime for a test-case consists of the generation time, and the time to execute the test-case. For DeepSmith, the time to generate test-harness is included.


\subsection{Results Overview}

\begin{table*}
  \scriptsize %
  \centering %
  \input{build/tab/outcomes}
  \caption{%
    Results from 48 hours of testing using CLSmith and DeepSmith. Testbed \#. as per Table~\ref{tab:platforms}. $\pm$ denotes optimizations off ($-$) vs on ($+$). The remaining columns denote build failure (\textbf{bf}), build crash (\textbf{bc}), build timeout (\textbf{bto}), runtime crash (\textbf{c}), timeout (\textbf{to}), and passed (\textbf{\cmark}) outcomes for CLSmith and DeepSmith, respectively.%
  }
  \label{tab:outcomes}
\end{table*}

Table~\ref{tab:outcomes} shows the outcomes of 48 hours of consecutive testing for each of the platforms from Table~\ref{tab:platforms}, with compiler optimizations disabled ($-$) and optimizations enabled ($+$).

An average of XX CLSmith and XX DeepSmith test-cases were evaluated on each device, with an average time per test-case of XX and XX respectively. The XX-fold increase in testing throughput achieved by DeepSmith is a result of XXX. Figure~\ref{fig:runtimes} shows the times taken to generate and execute test-cases. DeepSmith generation time is proportional to program length, benchmarked at an average 465 chars / second. For Clsmith, generation time depends on the number of rejections which are required before production of statically verified code is correct \cc{ldots}.

Optimization level generally does not affect testing throughput significantly, with the exception of testbed $7+$, in which the slow compilation of kernels containing structs greatly reduces the number of test-cases evaluated. This is a result of CLSmith's heavy reliance on structs, and is a known issue --- in XX the authors omnit testing on this testbed for this reason.

83.8\% of CLSmith test-cases produce a majority \textbf{\cmark} outcome. Proportionally, DeepSmith test-cases are less likely to produce a majority outcome at 47.9\% of the total. Neither CLSmith or DeepTune guarantee program termination with XX\% of non-\textbf{\{bf,c\}} majority outcomes reaching 60 seconds timeouts.


\subsection{Comparison of Results}

CLSmith crashed 8 of the 20 compilers, DeepSmith crashed all of them. See Section X for examples of bugs found from build crashes.

For all except testbed $3\pm$, DeepSmith exposes more compiler crashes than CLSmith. On average, DeepSmith hangs the compiler more frequently. \cc{\ldots}

The integrated GPU Conifgs.\ we tested ($3\pm$) frequently failed to compile CLSmith kernels, resulting in thousands of compiler crashes \textbf{bc} or timeouts \textbf{bc}.
% SELECT stderr,COUNT(*) FROM CLSmithResults LEFT JOIN CLSmithMetas ON CLSmithResults.id=CLSmithMetas.id WHERE testbed_id=13 AND CLSmithResults.outcome='bc' AND cumtime < 48 * 3600 GROUP BY CLSmithResults.stderr;
Of the build crashes, 68\% failed silently, and the remainder were caused by the same pointer assignment assertion for which DeepSmith generated a 4 line test-case in Figure~\ref{lst:intel-llvm-assertion}. \cc{We also generated silent build crashes, but with an average line count of XX, versus CLSmith's line count of XX.}

% 622 total bc
Testbeds $4$, $5$, $6$, and $7$ have a number CLSmith bc outcomes when optimizations are enabled. Of the non-silent crashes, the cause is the OpenCL vectorizer pass, same as Figure~\ref{lst:intel-vectorizer-segfault}.

\cc{Testbeds $4$, $6$ are the same driver on different hardware, and exhibit similar behavior}


\subsection{Differential Tests}

Table~\ref{tab:classifications} shows the results of applying voting heuristics to the results of Table~\ref{tab:outcomes}.

\begin{figure}
	\centering %
	\includegraphics[width=\columnwidth]{build/img/runtimes}%
	\caption{%
		Runtimes, excluding timeouts. On average, DeepSmith test-cases are evaluated $XX\times$ faster than CLSmith ($2.45\times$, $4.46\times$, and $66.54\times$ for generation, execution and reduction, respectively).%
%    Total speedup is 3.03x
%    CLgen generation is 2.45x faster than CLSmith
%    CLgen execution is 4.46x faster than CLSmith
%    CLgen reduction is 66.54x faster than CLSmith
	}%
	\label{fig:runtimes} %
\end{figure}


\begin{table*}
	\scriptsize %
	\centering %
	\input{build/tab/megatable}
	\caption{Using voting heuristics to expose anomalous results from 48 hours of testing using CLSmith and DeepSmith. Columns denote anomalous-output (ao), anomalous build failure (\textbf{abf}), anomalous runtime crash (\textbf{ac}), and anomalous timeout (\textbf{ato}) classifications for CLSmith and DeepSmith, respectively.}
	\label{tab:classifications}
\end{table*}

The 2357 \textbf{abf} results for CLSmith on Testbeds $4\pm$ and $6\pm$ are all a result of compilers rejecting empty declarations, (e.g. \texttt{int;}) which CLSmith occasionally emits. This is a known CLSmith issue which will likely be addressed.
% https://github.com/ChrisLidbury/CLSmith/issues/7
Similarly, Intel Testbeds 4--7 (but not 3) reject DeepSmith kernels which omit a type specified (e.g. \texttt{\_\_global* a}), whereas all other Testbeds (including 3) emit and warning and default to \texttt{int} type.

% Anomalous build failures
Testbeds $1\pm$, $2\pm$ reject kernels which \texttt{size\_t} parameters.


\subsection{Comparison of Test-cases}

\begin{figure}
	\centering %
	\includegraphics[width=\columnwidth]{build/img/kernel-sizes}%
	\caption{%
		Kernel line counts, grouped by outcome. DeepSmith test-cases are on average two orders of magnitude smaller than CLSmith.%
	}%
	\label{fig:kernel-sizes} %
\end{figure}

\paragraph{Test-case Size}
%SELECT MIN(linecount) as minlen,
%->    AVG(linecount) as meanlen,
%->        MAX(linecount) as maxlen
%-> FROM CLSmithResults results
%-> LEFT JOIN CLSmithMetas meta ON results.id = meta.id
%-> LEFT JOIN CLSmithTestCases testcases ON results.testcase_id = testcases.id
%-> LEFT JOIN CLSmithPrograms programs ON testcases.program_id = programs.id
%-> WHERE cumtime < 48 * 3600;
%+--------+-----------+--------+
%| minlen | meanlen   | maxlen |
%+--------+-----------+--------+
%|     56 | 1186.8496 |  11222 |
%+--------+-----------+--------+
The average CLSmith program is 1189 lines long (excluding headers). CLSmith kernels are unreadable, requiring automatic or manual test-case reduction.
%SELECT MIN(linecount) as minlen,
%->    AVG(linecount) as meanlen,
%->        MAX(linecount) as maxlen
%-> FROM CLgenResults results
%-> LEFT JOIN CLgenMetas meta ON results.id = meta.id
%-> LEFT JOIN CLgenTestCases testcases ON results.testcase_id = testcases.id
%-> LEFT JOIN CLgenPrograms programs ON testcases.program_id = programs.id
%-> WHERE cumtime < 48 * 3600;
%+--------+---------+--------+
%| minlen | meanlen | maxlen |
%+--------+---------+--------+
%|      1 | 20.3163 |    636 |
%+--------+---------+--------+
Average CLgen kernel is 20 lines long.
% SELECT SUM(linecount)
% FROM CLSmithResults results
% INNER JOIN CLSmithMetas meta ON results.id = meta.id
% INNER JOIN CLSmithTestCases testcases ON results.testcase_id = testcases.id
% INNER JOIN CLSmithPrograms programs on testcases.program_id = programs.id
% WHERE cumtime < 48 * 3600;
Over the course of testing, a combined $3.39 \times 10^8$ of CLSmith code was evaluated, compared to $3.76 \times 10^6$ lines of DeepSmith code.

\paragraph{Test-case Reduction} We used a modified version of C-Reduce which supports OpenCL~\cite{Pflanzer2016} to perform automatic test-case, using the default settings. The available implementation supports reduction only of anomalous-output test-cases, though this could be extended to support other outcomes (we did not do this). Test-case reduction is a time-consuming process, even with the parallelized implementation. Figure~\ref{fig:kernel-sizes} shows the runtimes of reductions, and Figure~\cc{TODO} shows the test-case sizes before and after reduction. For CLSmith-generated kernels, test case reduction is necessary to expose the problematic code from within the hundreds of lines of generated program. DeepSmith kernels are on average an order of magnitude smaller. We found that reduction \ldots

% Average GitHub charchounts: 1451
% Average GitHub linecounts: 53

\newsavebox{\IntelPtrAssertion}
\begin{lrbox}{\IntelPtrAssertion}
  \hspace{1.5em}
  \begin{lstlisting}
    __kernel void A(__global int* a, __global int* b) {
      int c = (int)get_global_id(0);
      a[c] += b;
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\IntelScalarAssertion}
\begin{lrbox}{\IntelScalarAssertion}
  \hspace{1.5em}
  \begin{lstlisting}
    __kernel void A(__global float* a, __global float* b, __global float* c, __local float* d, unsigned int e, unsigned int f) {
      for (unsigned int g = get_local_id(0) + get_local_size(0); g < get_local_size(0); g += get_local_size(0)) {
        a[2 * get_local_id(0) + 1] = get_local_id(0);
      }
    }
  \end{lstlisting}
\end{lrbox}

\begin{figure}
  \centering %
  \subfloat[Testbeds $3\pm$ assertion during code generation for pointer assignment.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\IntelPtrAssertion}}}%
    \label{lst:intel-ptr-assertion}
  }\\%
  \subfloat[Testbeds $3\pm$ assertion in scalar type code generation.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\IntelScalarAssertion}}}%
    \label{lst:intel-scalar-assertion}
  }\\%
  \caption{Kernels which trigger compiler assertions which both CLSmith and DeepSmith exposed.}%
  \label{lst:clsmith-compiler-assertions}%
\end{figure}

In 48 hours of testing, DeepSmith triggered 9 distinct compiler assertions, CLSmith 2. Both of the assertions triggered by CLSmith were also triggered by CLgen.
% Test-case sizes:
%
% SELECT assertion, AVG(linecount)
% FROM CLSmithResults results
% LEFT JOIN CLSmithTestCases testcases ON results.testcase_id = testcases.id
% LEFT JOIN CLSmithPrograms programs ON testcases.program_id = programs.id
% INNER JOIN CLSmithAssertions assertions ON results.stderr_id = assertions.id
% GROUP BY assertion;
%
% CLSmith:
% 'ASSERTION FAILED: (isa<AllocaInst>(ptr) || ptrCandidate.empty()) && \"storing/loading pointers only support private array\"', '1410.8486'
% 'ASSERTION FAILED: iter != pointerOrigMap.end()', '889.0990'
%
% CLgen:
% ASSERTION FAILED: (isa<AllocaInst>(ptr) || ptrCandidate.empty()) && "storing/loading pointers only support private array"	12.5382
% ASSERTION FAILED: 0	86.3295
% ASSERTION FAILED: isScalarType(type)	5.0000
% ASSERTION FAILED: iter != pointerOrigMap.end()	9.5455
% ASSERTION FAILED: Missing parameters for sync instruction	10.0000
% ASSERTION FAILED: Not implemented	7.1579
% ASSERTION FAILED: Not supported	4.7857
% ASSERTION FAILED: sel.hasDoubleType()	4.6364
% ASSERTION FAILED: srcType != ir::TYPE_U64	3.0000
The CLSmith kernels which triggered the two assertions were on average 1411 and 889 lines respectively (excluding headers). The same assertions were triggered with DeepSmith kernels of average 13 lines and 10 lines, respectively. \cc{TODO: listings}
%
% SELECT num, src, assertion
%FROM CLgenResults results
%LEFT JOIN CLgenTestCases testcases ON results.testcase_id = testcases.id
%LEFT JOIN CLgenPrograms programs ON testcases.program_id = programs.id
%LEFT JOIN Configurations ON results.testbed_id = Configurations.id
%INNER JOIN CLgenAssertions assertions ON results.stderr_id = assertions.id
%WHERE assertion = 'ASSERTION FAILED: srcType != ir::TYPE_U64';
We were able to trigger the assertion \emph{srcType != ir::TYPE\_U64} in Testbeds $3\pm$ with only a 3 line test-case.
%
DeepSmith also triggered \emph{unreachable!} compiler errors in 180 distinct test cases, CLSmith triggered 0.

\cc{What is the bug rate per line of code?}


\paragraph{Bug Diversity}

Hard to quantify, but our results suggest the value of our syntactic approach.

% How many GitHub kernels contain 'struct's?
% $ ls | xargs grep -l struct -- | wc -l
% 331
CLSmith is biased towards identifying struct miscompilations, though only 7.1\% of OpenCL kernels on GitHub use them.

Our approach is biased towards identifying bugs in compiler front-ends, since not all generated programms are well formed/well typed. Results suggest we cover more areas of the compiler, E.g. compiler crashes, compiler timeouts, etc.

Oclgrind was resilient to CLSmith testing, yet we managed to trip it up during compilation, and discovered the switch race condition.

Overall, CLSmith is better at finding miscompilations. We believe our approach to be complimentary.

%\begin{figure}
%	\centering %
%	\includegraphics[width=\columnwidth]{build/img/total-tests}%
%	\caption{%
%		Test-cases. \cc{TODO: Replot with the fastest and slowest device for each}%
%	}%
%	\label{fig:total-tests} %
%\end{figure}
