\section{Comparison to State-of-the-art}\label{sec:vs_clsmith}

In this section we report on an experiment using both CLSmith and CLgen for 48 hours each.

Total runtime for a test cases consists of the generation time, the time to execute the test harness on a configuration, and, if required, the time to reduce the test case.

Both testing frameworks were used for 48 hours each. CLSmith was configured with default settings. CLReduce was configured with the default settings (four parallel reduction threads).

\subsubsection{Experimental Setup}

All devices were unloaded.

\subsection{Results}

Table~\ref{tab:outcomes} shows the outcomes of test cases. Once voting heuristics have been applied, the result is table~\ref{tab:classifications}.

\begin{table*}
	\scriptsize %
	\centering %
	\input{build/tab/outcomes}
	\caption{Test case outcomes using CLSmith and CLgen for 48 hours each. Configuration \#. as per Table~\ref{tab:platforms}. $\pm$ denotes optimizations off ($-$) vs on ($+$). The remaining columns denote build failure (\textbf{bf}), build crash (\textbf{bc}), build timeout (\textbf{bto}), runtime crash (\textbf{c}), timeout (\textbf{to}), and passed (\textbf{\cmark}) outcomes for CLSmith and CLgen, respectively. \cc{Asterisk in 'total' column means the full 48 hours of data have not yet been collected. All results are excluding reductions.}}
	\label{tab:outcomes}
\end{table*}

\begin{table*}
	\scriptsize %
	\centering %
	\input{build/tab/megatable}
	\caption{Classifying test case outcomes of Table~\ref{tab:outcomes} using voting heuristics. Columns denote wrong-code (w), build failure (\textbf{bf}), runtime crash (\textbf{c}), timeout (\textbf{to}), and passed (\textbf{\cmark}) classifications for CLSmith and CLgen, respectively. \cc{Asterisk in 'total' column means the full 48 hours of data have not yet been collected. All results are excluding reductions.}}
	\label{tab:classifications}
\end{table*}

\cc{TODO: How long do reductions take? How many CLgen test cases can we run in that amount of time? Given the ratio of interesting CLgen test cases, how many more bugs could we find in the amount of time it takes to run a single reduction?}


\subsection{Test Case Size}

Median CLSmith kernel is 1086 lines long (excluding headers).

For ``interesting'' programs: median CLgen kernel size is 12 lines. Median reduced CLSmith kernel size is 43 lines (894 lines before reduction). Figure~\ref{fig:kernel-sizes}.

Potentially interesting questions: What is the total lines of code which get run on each device during the tests? CLgen programs are smaller, but we get through more of them.

\cc{CLgen test cases are two orders of magnitude smaller than CLSmith programs which have been reduced.}

\cc{What is the bug rate per line of code?}

\begin{figure}
	\centering %
	\includegraphics[width=\columnwidth]{build/img/runtimes}%
	\caption{%
		Test case runtimes, excluding timeouts. On average, CLgen test case execution is $x\times$ faster than CLSmith. \cc{TODO: CLgen generation times, CLgen reductions}%
	}%
	\label{fig:runtimes} %
\end{figure}


\begin{figure}
	\centering %
	\includegraphics[width=\columnwidth]{build/img/kernel-sizes}%
	\caption{%
		Kernel line counts, grouped by classification. CLSmith programs with wrong-code (\emph{w}) classifications have been reduced.%
	}%
	\label{fig:kernel-sizes} %
\end{figure}


\begin{figure}
	\centering %
	\includegraphics[width=\columnwidth]{build/img/total-tests}%
	\caption{%
		Test cases. \cc{TODO: Replot with the fastest and slowest device for each}%
	}%
	\label{fig:total-tests} %
\end{figure}