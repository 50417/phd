\section{Overview of Our Approach and Results}\label{sec:overview}

\paragraph{Test case generation} We mine GitHub for OpenCL fragments, which we use to construct a corpus of representative programs. We learn a generative model over this corpus. DeepSmith, our deep learning program generator, automatically generates an unbounded number of OpenCL samples for testing compilers.

\paragraph{OpenCL configurations tested} We conducted testing of 10 different OpenCL configurations, summarized in Table~\ref{tab:platforms}. A \emph{configuration} refers to an OpenCL \emph{<device, driver>} pair. We covered the broadest range of hardware available to us: 3 GPUs, 4 CPUs, an Accelerator, and an Emulator. 7 of the OpenCL implementations are commercial products, 2 of them are open source. We tested both different drivers for the same device, and different devices using the same driver.


\begin{table*}[t!]
	\scriptsize %
	\centering %
	% \rowcolors{2}{white}{gray!25}
	\input{build/tab/platforms}
	\caption{OpenCL configurations we tested, the time spent in automated testing, and the number of bug reports submitted to date.}
	\label{tab:platforms}
\end{table*}


\paragraph{Bugs found} All configurations yielded bugs. Every compiler crashed, and the majority silently generated wrong code. To date, we have submitted XX bug reports to compiler vendors. Of those, 14\% were cases where the compiler silently emits wrong-code, 41\% were compiler crashes, and the remainder were runtime crashes. In comparing our approach against the state-of-the-art in OpenCL compiler test case generation, we found our approach was able to \cc{\ldots}