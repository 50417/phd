\section{Overview of Our Approach and Results}\label{sec:overview}

\paragraph{Test-case generation} We mine GitHub for OpenCL fragments, which we use to construct a corpus of representative programs. We learn a generative model over this corpus. DeepSmith, our deep learning program generator, automatically and rapidly synthesizes an unbounded number of programs for fuzz testing compilers.

\paragraph{OpenCL configurations tested} We conducted testing of 10 different OpenCL configurations, summarized in Table~\ref{tab:platforms}. A \emph{configuration} refers to an OpenCL \emph{<device, driver>} pair. We covered the broadest range of hardware available to us: 3 GPUs, 4 CPUs, an Accelerator, and an Emulator. 8 of the compilers tested commercial products, 2 of them are open source. We tested both different drivers for the same device, and different devices using the same driver.


\begin{table*}[t!]
	\scriptsize %
	\centering %
	% \rowcolors{2}{white}{gray!25}
	\input{build/tab/platforms}
	\caption{OpenCL configurations we tested, the time spent in automated testing, and the number of bug reports submitted to date.}
	\label{tab:platforms}
\end{table*}


\paragraph{Bugs found} All configurations yielded bugs. Every compiler crashed, and every compiler yielded anomalous results --- either programs which crash, or programs which silently compute the wrong result. To date, we have submitted XX bug reports to compiler vendors. Of those, 41\% are cases where the compiler crashes, and the remainder are cases where the generated program either silently emits wrong-code, or crashes at runtime. In comparing our approach against the state-of-the-art in OpenCL compiler test-case generation, we found our approach was able to \cc{\ldots}