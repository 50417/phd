%%% LISTINGS 

\newsavebox{\IntelSizetIntReduced}
\begin{lrbox}{\IntelSizetIntReduced}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global double* a) {
      int b = get_global_id(0);
      if (b < -1)
        a[b] = 1;
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\OclgrindRaceSwitch}
\begin{lrbox}{\OclgrindRaceSwitch}
  \hspace{1.5em}
  \begin{lstlisting}
  kernel void A(global int* a, global int* b) {
    switch (get_global_id(0)) {
      case 0:
        a[get_global_id(0)] = b[get_global_id(0) + 13];
        break;
      case 2:
        a[get_global_id(0)] = b[get_global_id(0) + 11];
        break;
      case 6:
        a[get_global_id(0)] = b[get_global_id(0) + 128];
    }
    barrier(2);
  }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\AlmostEverythingCrash}
\begin{lrbox}{\AlmostEverythingCrash}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A() {
      __builtin_astype(d, uint4);
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\OclgrindSemaAssertion}
\begin{lrbox}{\OclgrindSemaAssertion}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global unsigned char* a, global unsigned char* b) {
      unsigned long c = get_global_id(0);
      d[0] = (mad24(f, (int)(a[0], b[get_global_id(0)])) % (d * (d + 3)) + (c / 2))] * a[c + 1];
    }
  \end{lstlisting}
\end{lrbox}
% This has been forwarded to the LLVM folks https://bugs.llvm.org/show_bug.cgi?id=33897
% __kernel void A(__global float* b) {
%	(float4)(b);
% }

\newsavebox{\IntelPtrCompilerHang}
\begin{lrbox}{\IntelPtrCompilerHang}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global ulong* a) {
      a[get_global_id(0)] = (ulong)(a + 1);
    }
  \end{lstlisting}
\end{lrbox}
% Another 3± hang:
% kernel void A(global const char* a, global char* b, global char* c) {
%   int d = get_global_id(0);
%   c[d] = get_global_id(0) + c;
% }

% Another 3± hang:
% __kernel void A(global int* a) {
%   local int b[4][3][4][5];
%   b[1][2][3][3] = b[3];
% }

\newsavebox{\NvidiaOptLoopHang}
\begin{lrbox}{\NvidiaOptLoopHang}
  \hspace{1.5em}
  % CLgenProgram.id = 6992
  \begin{lstlisting}
    kernel void A(global float* a, global float* b, global float* c) {
      int d, e, f;
      d = get_local_id(0);
      for (int g = 0; g < 100000; g++)
        barrier(1);
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\XeonPhiSpin}
\begin{lrbox}{\XeonPhiSpin}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global unsigned char* a, unsigned b) {
      a[get_global_id(0)] %= 42;
      barrier(1);
    }
  \end{lstlisting}
\end{lrbox}
% LLVM ERROR: LLVM2PIL: Cannot yet select: 0x7f72a45a7ed0: i8,i8 = umul_lohi 0x7f72a45a87d0, 0x7f72a45a88d0 [ORD=16] [ID=22]
% 0x7f72a45a87d0: i8 = srl 0x7f72a45a7dd0, 0x7f72a42fff90 [ORD=16] [ID=21]
% 0x7f72a45a7dd0: i8,ch = load 0x7f72a41d9438, 0x7f72a4300790, 0x7f72a4300590<LD1[%scevgep2]> [ORD=15] [ID=20]
% 0x7f72a4300790: i64 = add 0x7f72a45a83d0, 0x7f72a45a80d0 [ORD=14] [ID=17]
% 0x7f72a45a83d0: i64,ch = CopyFromReg 0x7f72a41d9438, 0x7f72a45a86d0 [ORD=14] [ID=13]
% 0x7f72a45a86d0: i64 = Register %vreg1 [ID=1]
% 0x7f72a45a80d0: i64,ch = CopyFromReg 0x7f72a41d9438, 0x7f72a45a81d0 [ORD=14] [ID=14]
% 0x7f72a45a81d0: i64 = Register %vreg2 [ID=2]
% 0x7f72a4300590: i64 = undef [ID=3]
% 0x7f72a42fff90: i8 = Constant<1> [ID=9]
% 0x7f72a45a88d0: i8 = Constant<49> [ID=10]

\newsavebox{\IntelOptLoopHang}
\begin{lrbox}{\IntelOptLoopHang}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global int* a) {
      int b = get_global_id(0);
      while (b < 512) { }
    }
  \end{lstlisting}
\end{lrbox}
% Another example:
%   kernel void A(long a, long b) {
%     while (a > 273444) { }
%   }


\newsavebox{\NvidiaRecursionSegfault}
\begin{lrbox}{\NvidiaRecursionSegfault}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(float4 a, global float4* b, global float4* c, unsigned int d, global double* e, global int2* f, global int4* g, constant int* h, constant int* i) {
      A(a, b, c, d, d, e, f, g, h);
    }
  \end{lstlisting}
\end{lrbox}
% HAND REDUCED:
%
%   kernel void A(constant int2* a, global int* b) { A(b, a); }
\newsavebox{\NvidiaRecursionSegfaultReduced}
\begin{lrbox}{\NvidiaRecursionSegfaultReduced}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void B(constant int2* a, global int* b) {
      A(b, a);
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\BeignetScalarizeInsert}
\begin{lrbox}{\BeignetScalarizeInsert}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global float4* a) {
      a[get_local_id(0) / 8][get_local_id(0)] = get_local_id(0);
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\OclgrindUncorrectedTypos}
\begin{lrbox}{\OclgrindUncorrectedTypos}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global float* a, global float* b) {
      a[0] = max(a[c], b[2]);
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\BeignetPtrIntSpin}
\begin{lrbox}{\BeignetPtrIntSpin}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global int* a) {
      int b = get_global_id(0);
      a[b] = (6 * 32) + 4 * (32 / 32) + a;
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\NvidiaCompileSegfault}
\begin{lrbox}{\NvidiaCompileSegfault}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global float* a, local float* b, local float* c, int d, int e) {
      int f, g;
      int h = get_local_id(0);
      int i = get_local_id(1);
      int j = get_global_id(0);
      global char* k = c + f * g + f;
      if (f + 1 < h)
        b[f * d + g * h + g] = g * f;
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\XeonPhiSegfault}
\begin{lrbox}{\XeonPhiSegfault}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(void) {
      global int* a;
      unsigned int* b;
      b = a[0];
      a[0] = b;
      a[0] = b;
      barrier(1);
      if (get_global_id(0) == 0)
        *a = 0;
      a[get_local_id(0)] = 0;
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\IntelVectorizerSegfault}
\begin{lrbox}{\IntelVectorizerSegfault}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A() {
      while (true) {
        barrier(1);
      }
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\IntelSizetIntUnreduced}
\begin{lrbox}{\IntelSizetIntUnreduced}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global double* a, global double* b, global double* c, int d, int e) {
      double f;
      int g = get_global_id(0);
      if (g < e - d - 1)
        c[g] = (((e) / d) % 5) % (e + d);
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\PoclUndefinedSymbols}
\begin{lrbox}{\PoclUndefinedSymbols}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(local int* a) {
      for (int b = 0; b < 100; b++)
        B(a);
    }
  \end{lstlisting}
\end{lrbox}


\newsavebox{\BeignetCastError}
\begin{lrbox}{\BeignetCastError}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global float* a, global float* b, global float* c, const int d) {
      int e = get_global_id(0);
      if (e < d)
        c[e] = a[e] + b[e];
      b[e] = (char)(c[e] + d);
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\XeonPhiInvalidWrite}
\begin{lrbox}{\XeonPhiInvalidWrite}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global int* a) {
      a[0] = 1;
      a[-1] = 2;
      a[0] = 3;
    }
  \end{lstlisting}\cc{TODO:}
\end{lrbox}

\newsavebox{\UninitRead}
\begin{lrbox}{\UninitRead}
  \hspace{1.5em}
  \begin{lstlisting}
      kernel void A(global int* a, global int* b) {
        int c[16];
        int d = get_global_id(0);
        a[d] = b[d] + c[d];
      }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\IntelPtrAssertion}
\begin{lrbox}{\IntelPtrAssertion}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global int* a, global int* b) {
      int c = (int)get_global_id(0);
      a[c] += b;
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\IntelScalarAssertion}
\begin{lrbox}{\IntelScalarAssertion}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global float* a, global float* b, global float* c, local float* d, unsigned int e, unsigned int f) {
      for (unsigned int g = get_local_id(0) + get_local_size(0); g < get_local_size(0); g += get_local_size(0))
        a[2 * get_local_id(0) + 1] = get_local_id(0);
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\BeignetTernary}
\begin{lrbox}{\BeignetTernary}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global int* a, global int* b, global int* c) {
      c[0] = (a[0] > b[0]) ? a[0] : 0;
      c[2] = (a[3] <= b[3]) ? a[4] : b[5];
      c[4] = (a[4] <= b[5]) ? a[7] : b[7];
      c[7] = (a[7] < b[0]) ? a[0] : (a[0] > b[1]);
    }
  \end{lstlisting}
\end{lrbox}
% HAND REDUCED:
%
%   kernel void A(global int* a, global int* b, global int* c) {
%     c[0] = 100;
%     c[1] = (a[3] <= b[4]) ? a[4] : b[5];
%   }

\newsavebox{\BeignetTernarySmaller}
\begin{lrbox}{\BeignetTernarySmaller}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global int* a, global int* b, global int* c) {
      c[0] = (a[0] > 0) ? a[0] : b[1];
      c[1] = (a[1] <= b[1]) ? a[0] : b[0];
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\IntelGtDoubleAssertion}
\begin{lrbox}{\IntelGtDoubleAssertion}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(read_only image2d_t a, global double2* b) {
      b[0] = get_global_id(0);
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\IntelDeclDoesntDeclareAnything}
\begin{lrbox}{\IntelDeclDoesntDeclareAnything}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A() {
      char a;
      int b;
      int const;
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\AddressQualifiedAutoVar}
\begin{lrbox}{\AddressQualifiedAutoVar}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global float4* a, global float4* b, global float4* c, global float4* d, global float4* e, float f) {
      unsigned int g = get_global_id(0);
      int h = get_global_size(0);
      constant sampler_t i = 0x0000 | 0x0004 | 0x0000;
      unsigned int j = g * (1 << ((h % 4) - (2)));
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\NvidiaLocalGlobalSegfault}
\begin{lrbox}{\NvidiaLocalGlobalSegfault}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global int* a) {
      local int b[2][3][4][5];
      if (get_global_id(0) == 0)
        a = b[0];
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\NvidiaLocalSegfault}
\begin{lrbox}{\NvidiaLocalSegfault}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global uchar4* a, const int b) {
      local int c[16];
      local float8* d = a + 133;
      atomic_cmpxchg(c, 10, 13);
    }
  \end{lstlisting}
\end{lrbox}


% Program ID: 35612
\newsavebox{\IntelPostDominanceFrontier}
\begin{lrbox}{\IntelPostDominanceFrontier}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A() {
      while (true)
        barrier(1);
    }
  \end{lstlisting}
\end{lrbox}
% Another:
% kernel void A(local int* a) {
%   while (1) {
%   }
% }
%
% And another:
%    kernel void A(global int* a) {
%      bool b;
%      int c;
%      for (b = 0; b < 100; b++)
%        a[c] += a[c];
%    }
%
% One more:
%   kernel void A(global int* a, global int* b) {
%     int c = get_global_id(0);
%     int d = 0;
%     while (d < 1024)
%       a[c] = d;
%   }

\newsavebox{\IntelPredicator}
\begin{lrbox}{\IntelPredicator}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global int* a) {
      int b = get_global_id(0);
      while (b < *a)
        if (a[0] < 0)
          a[1] = b / b * get_local_id(0);
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\IntelPrepareKernelArgs}
\begin{lrbox}{\IntelPrepareKernelArgs}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(int a, global int* b) {
      int c = get_global_id(0);
      int d = work_group_scan_inclusive_max(c);
      b[c] = c;
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\IntelDAGInstrSelection}
\begin{lrbox}{\IntelDAGInstrSelection}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global half* a, global int* b, global bool* c, int d, int e) {
      int f = get_global_id(0);
      int g = get_global_id(1) * e;
      if (f < e)
        a[f] = b[f];
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\IntelSPIRMetadata}
\begin{lrbox}{\IntelSPIRMetadata}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A() {
      local float a;
      A(a);
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\IntelRemoveDupeBarrier}
\begin{lrbox}{\IntelRemoveDupeBarrier}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A() {
      local int a[10];
      local int b[16][16];
      a[1024 + (2 * get_local_id(1) + get_local_id(0)) + get_local_id(0)] = 6;
      barrier(b);
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\IntelCombineRedundant}
\begin{lrbox}{\IntelCombineRedundant}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global float* a, global float* b, global float* c, const int d) {
      for (unsigned int e = get_global_id(0); e < d; e += get_global_size(0))
        for (unsigned f = 0; f < d; ++f)
          e += a[f];
    }
  \end{lstlisting}
\end{lrbox}


\newsavebox{\BeigPtrAssertion}
\begin{lrbox}{\BeigPtrAssertion}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global int* a, global int* b, global int* c) {
      a[get_global_id(0)] = a[get_global_id(0)] > b;
    }
  \end{lstlisting}
\end{lrbox}

\newsavebox{\BeigIterAssertion}
\begin{lrbox}{\BeigIterAssertion}
  \hspace{1.5em}
  \begin{lstlisting}
    kernel void A(global int* a) {
      global int* b = ((void*)0);
      b[0] = a;
    }
  \end{lstlisting}
\end{lrbox}


\section{Evaluation}%
\label{sec:eval}

%We report on the results of extensive DeepSmith testing of the 20 testbeds from Table~\ref{tab:platforms} over four months. 
\hl{We report on the results of DeepSmith testing of the 20 testbeds from Table~\ref{tab:platforms}, in which each ran for 48 hours.}
We found bugs in all the compilers we tested --- every compiler crashed, and every compiler generated programs which either crash or silently compute the wrong result. To date, we have submitted XX bug reports to compiler vendors. We first provide a qualitative analysis of compile-time and runtime defects found, followed by a quantitative comparison of our approach against the state-of-the-art in OpenCL compiler fuzzing --- CLSmith~\cite{Lidbury2015a}. DeepSmith is able to identify a broad range of defects, many of which CLSmith cannot, for only a fraction of the engineering effort. Finally, we provide a quantitative analysis of compiler robustness over time, using the compiler crash rate of every LLVM release in the past two years as a metric of compiler robustness. We find that progress is good, compilers are becoming more robust, yet the introduction of new features and regressions means that compiler validation is a moving target.

%Unless stated otherwise, all code listings are presented verbatim as generated by DeepSmith --- only uneeded whitespace and braces have been removed to save space.

Unless stated otherwise, DeepSmith code listings are presented verbatim, with only minor formatting changes to save space. No test case reduction, manual or automatic, was needed.

% We use a shorthand to refer to specific testbed configurations. $1+$ means Testbed 1 with optimizations enabled, $2-$ means Testbed 2 with optimizations disabled, and $3\pm$ means Testbed 3 with either optimizations enabled or disabled.

For the remainder of the paper we identify testbeds using the OpenCL system number from from Table~\ref{tab:platforms}, suffixed with $+$, $-$ or $\pm$ to denote optimizations on, off, or either, respectively.

\subsection{Compile-time Defects}%
\label{subsec:compile-time-defects}

OpenCL is typically compiled online, which amplifies the significance of detecting compile-time defects, as they may not be discovered until code has been shipped to customers. We found numerous cases where DeepSmith kernels trigger a crash in the compiler (and as a result, the host process), or cause the compiler to loop indefinitely. In the testing time allotted we have identified 207 test cases which trigger unreachable code failures, triggered 36 distinct compiler assertions, and produced 21 distinct stack traces from other compiler crashes.

\begin{figure}
  \centering %
  \subfloat[Testbed $10\pm$ assertion \emph{Uncorrected typos!} during semantic analysis.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\OclgrindUncorrectedTypos}}}%
    \label{lst:oclgrind-uncorrected-typos}
  }\\%
  \subfloat[Testbeds $1\pm$, $2\pm$ segmentation fault due to implicit address space conversion.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\NvidiaRecursionSegfault}}}%
    \label{lst:nvidia-recursion-segfault}
  }\\%
%  \subfloat[Reduced version of Figure~\ref{lst:nvidia-recursion-segfault}.]{%
%    \noindent\mbox{\parbox{\columnwidth}{\usebox{\NvidiaRecursionSegfaultReduced}}}%
%    \label{lst:nvidia-recursion-segfault}
%  }\\%
%  \subfloat[Testbed $10\pm$ assertion \emph{Uncorrected typos!} during semantic analysis.]{%
%    \noindent\mbox{\parbox{\columnwidth}{\usebox{\OclgrindSemaAssertion}}}%
%    \label{lst:oclgrind-uncorrected-typos}
%  }\\%
  \subfloat[Testbed $3\pm$ assertion \emph{sel.hasDoubleType()} during code generation.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\IntelGtDoubleAssertion}}}%
    \label{lst:intel-gt2-double-assertion}
  }\\%
  \subfloat[Testbed $3\pm$ assertion \emph{scalarizeInsert} during code generation.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\BeignetScalarizeInsert}}}%
    \label{lst:beignet-scalarize-insert}
  }\\%
  \subfloat[Of the 10 compilers we tested, 6 crash with segfault when compiling this kernel.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\AlmostEverythingCrash}}}%
    \label{lst:almost-everything-crash}
  }\\%
%  \subfloat[Testbeds $7\pm$ segmentation fault.]{%
%    \noindent\mbox{\parbox{\columnwidth}{\usebox{\XeonPhiSegfault}}}%
%    \label{lst:xeon-phi-segfault}
%  }\\%
  \caption{Example kernels which crash compilers.}%
\end{figure}
 
\paragraph{Semantic Analysis Failures} %
Compilers should produce meaningful diagnostics when inputs are invalid, yet we discovered dozens of compiler defects attributable to improper or missing error handling. Many prior works on compiler validation have focused solely on testing under \emph{valid inputs}. As such, this class of bugs may go undiscovered. We believe that our approach contributes a significant improvement to generating plausibly-erroneous code over prior random-enumeration approaches.

% We do not enforce this requirement on DeepSmith productions, and have discovered dozens of compiler defects induced by \emph{invalid} or \emph{unexpected} inputs.

The use of undeclared identifiers is a core error diagnostic which one would expect to be robust in a mature compiler. Surprisingly, DeepSmith discovered cases in which an undeclared identifier crashes Testbed $10\pm$. For example, the undeclared identifier \texttt{c} in Figure~\ref{lst:oclgrind-uncorrected-typos} raises an assertion during semantic analysis of the AST when used as an array index.

Type errors were an occasional cause of compile-time defect. Figure~\ref{lst:nvidia-recursion-segfault} induces an error in NVIDIA compilers due to implicit global to constant address qualifiers. Worse, we found that Testbed $3\pm$ would loop indefinitely on some kernels containing implicit conversions from a pointer to an integer, as shown in Figure~\ref{lst:beignet-ptr-int-spin}. While spinning, the compiler would consume an increasing amount of host memory until the entire system memory is depleted and the process crashes. % This would be a nice one to have fixed.

% \paragraph{Code Generation} %
Occasionally incorrect program semantics will remain undetected until late in the compilation process. Both Figures~\ref{lst:intel-gt2-double-assertion} and~\ref{lst:beignet-scalarize-insert} pass the type checker and semantic analysis, but trigger compiler assertions during code generation.

% \paragraph{Compiler-specific Code} %
An interesting yet unintended byproduct of having trained DeepSmith on thousands of real world examples is that the model learned to occasionally generate compiler-specific code, such as invoking compiler builtins. We found the quality of error handling on these builtins to vary wildly. For example, Figure~\ref{lst:almost-everything-crash} silently crashes 6 of the 10 compilers.

% Since the expressiveness of our approach is bounded only by the handwritten programs we train on, DeepSmith will occasionally emit compiler-specific code

% CLgen result ID 994
% TODO: Testbed $3\pm$ assertion in \emph{gbe::GenEncoder::handleDouble}

\paragraph{Parser Failures} %
Parser development is a mature and well understood practice. We uncovered parser errors in several compilers. Each of the following three code samples induce crash errors during parsing of compound statements in both Testbeds $5\pm$ and $7\pm$:

\hl{Should be as figures?
\begin{enumerate}
% Hand reduction of a 40 line kernel:
\item \texttt{void A() \{ (global a*)()}
% Hand reduction of a 52 line kernel:
\item \texttt{void A() \{ void* a; uint4 b = 0; b = (b > b) ? a : a}
% 68 line kernel:
\item \texttt{void A() \{ double2 k; return (float4)(k, k, k, k)}
\end{enumerate}
}

The code fragments were hand-reduced from 40, 52, and 68 line DeepSmith samples, respectively. It took about 10 minutes to perform all three reductions by hand, producing these minimal code samples which we have reported to Intel. In total, we have generated 100 distinct programs which crash compilers during parsing.

\begin{figure}
  \centering %
  \subfloat[Testbed $3\pm$ loop indefinitely, leaking memory until the entire system memory is depleted and the process crashes.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\BeignetPtrIntSpin}}}%
    \label{lst:beignet-ptr-int-spin}
  }\\%
  \subfloat[Testbed $1+$ hangs during optimization of kernels with large loop bounds. Testbeds $1-$ and $2\pm$ compile in under 1 second.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\NvidiaOptLoopHang}}}%
    \label{lst:nvidia-opt-loop-hang}
  }\\%
  \subfloat[Testbeds $4+$, $5+$, $6+$, $7+$ hang during optimization of kernels with non-terminating loops.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\IntelOptLoopHang}}}%
    \label{lst:intel-inf-loop}
  }\\%
  \subfloat[Testbeds $7\pm$ loops indefinitely, consuming 100\% CPU usage.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\XeonPhiSpin}}}%
    \label{lst:xeon-phi-spin}
  }\\%
  \caption{Example kernels which hang compilers.}%
  \label{lst:compiler-hangs}%
\end{figure}

\paragraph{Compiler Hangs} %
As expected, some compiler behavior is optimization sensitive. Testbeds $1+$ and $2+$ hang on large loop bounds, shown in Figure~\ref{lst:nvidia-opt-loop-hang} \cc{how large does the loop bound have to be?}. All commercial Intel compilers we tested hang during optimization of non-terminating loops (Figure~\ref{lst:intel-inf-loop}).

Testbed $7\pm$, loops indefinitely during compilation of the simple kernel in Figure~\ref{lst:xeon-phi-spin}.

\paragraph{Other errors} %

Some compilers are more permissive then others. Testbeds~$4\pm$, $6\pm$, $9\pm$ reject out-of-range literal values e.g. \texttt{int i = 0xFFFFFFFFFFFFFFFFFFFFFFFF}, whilst testbeds $3\pm$, $5\pm$, $7\pm$, $8\pm$, and $10\pm$ interpret the literal as an \texttt{unsigned long long} and implicitly cast to an integer value of \texttt{-1}. Testbeds $1\pm$, $2\pm$ omit no warning.

Testbeds $1\pm$, $2\pm$, $3\pm$ rejects address space qualifiers on automatic variables. \cc{always? or just the one constant example}.
% T3± mad24() result ID: 891687

On Testbed~$3\pm$, the statement \texttt{int n = mad24(a, (32), get\_global\_size(0));} (a call to a math builtin with mixed types) is rejected as ambiguous.

% 110 distinct test cases which crash testbed $9\pm$ during compilation, all silently.

% \begin{figure}
%   \centering %
%   \subfloat[]{%
%     \noindent\mbox{\parbox{\columnwidth}{\usebox{\NvidiaLocalGlobalSegfault}}}%
%     \label{lst:nvidia-local-global-sefault}
%   }\\%
%   \subfloat[]{%
%       \noindent\mbox{\parbox{\columnwidth}{\usebox{\NvidiaLocalSegfault}}}%
%       \label{lst:nvidia-local-global-sefault}
%     }\\%
%   \caption{Kernels containing pointer assignments which segfault Nvidia compilers.}%
%   \label{lst:nvidia-silent-segfaults}
% \end{figure}
%
% This makes identifying root causes more difficult. Figure~\ref{lst:nvidia-silent-segfaults} shows examples of crashes we identified as caused by pointer assignments. Without error messages and access to the compiler source code, we can only report a couple of errors and move on.
%


%\begin{figure}
%  \centering %
%  \subfloat[Testbeds $1\pm$, $2\pm$, $3\pm$ reject address space-qualified automatic variables.]{%
%    \noindent\mbox{\parbox{\columnwidth}{\usebox{\AddressQualifiedAutoVar}}}%
%    \label{lst:adress-qualified-autovar}
%  }\\%  
%  \subfloat[Testbeds $4\pm$, $6\pm$ reject anonymous declarations. %\emph{declaration doesn't declare anything}.
%    % All other testbeds compile, some with a warning.
%    ]{%
%    \noindent\mbox{\parbox{\columnwidth}{\usebox{\IntelDeclDoesntDeclareAnything}}}%
%    \label{lst:intel-decl-doesnt-declare-anything}
%  }\\%
%  \caption{Well-formed kernels which do not compile.}%
%\end{figure}


\subsection{Runtime Defects}
\label{subsec:runtime-defects}

\begin{figure}
  \centering %
  \subfloat[Testbeds $4+$, $6+$ incorrectly optimize the \texttt{if} statement, causing the conditional branch to execute (it shouldn't). This pattern of integer comparison to thread ID is widely used.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\IntelSizetIntUnreduced}}}%
    \label{lst:intel-size_t-int-unreduced}
  }\\%
  \subfloat[A race condition in \texttt{switch} statement evaluation causes $10\pm$ to sporadically crash when executed with a global size $> 1$.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\OclgrindRaceSwitch}}}%
    \label{lst:oclgrind-race-switch}
  }\\%
  \subfloat[Testbed $3\pm$ silently miscompiles ternary ops in which the operands are global buffers \cc{double check the cause}.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\BeignetTernary}}}%
    \label{lst:beig-ternary-ops}
  }\\%
  \subfloat[Compilation should fail due to call to undefined function \texttt{B()}; Testbed $8\pm$ silently succeed then crash upon kernel execution.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\PoclUndefinedSymbols}}}%
    \label{lst:pocl-undefined-symbols}
  }\\%
%  \subfloat[Testbeds $3\pm$ incorrect cast yields \texttt{b[e] = 127}, not \texttt{b[e] = 0}. \cc{TODO: Is char overflow defined?}]{%
%    \noindent\mbox{\parbox{\columnwidth}{\usebox{\BeignetCastError}}}%
%    \label{lst:beignet-cast-error}
%  }\\%
  \caption{Example kernels which are miscompiled.}%
\end{figure}

Prior work on compiler test case generation has focused on extensive stress-testing of compiler middle-ends to uncover miscompilations~\cite{Chen2014a}. CLSmith, the state-of-the-art in OpenCL compiler fuzzing, specifically targets this class of bugs. Grammar based enumeration is highly effective at this task, yet is bounded by the expressiveness of the grammar. Here we provide examples of bugs which cannot currently be discovered by CLSmith.

%
% cd ~/data/kernels/github-pp
% ls | xargs egrep -l 'int [A-Z]+ = get_global_id\(' -- | wc -l
% >> 2144
% ls | wc -l
% >> 4655
\paragraph{Thread-dependent Flow Control} A common pattern in OpenCL is to obtain the thread identity, often as an \texttt{int}, and to compare this against some fixed value to determine whether or not to complete a unit of work (46\% of OpenCL kernels on GitHub use this ($tid \rightarrow$ int, \texttt{if (tid < \ldots) \{\ldots\}}) pattern). DeepSmith, having modeled the frequency with which this pattern occurs in real handwritten code, generates many permutations of this pattern. And in doing so, exposed an error in the optimizer of two Testbeds $4+$, $6+$ which causes the \texttt{if} statement of Figure~\ref{lst:intel-size_t-int-unreduced} to be executed when the kernel is compiled with optimizations enabled. We have reported this issue to Intel. CLSmith does not permit the thread index to modify control flow, rendering such productions impossible.

Figure~\ref{lst:oclgrind-race-switch} shows a simple program in which thread identity determines the program output. We found that this test case would sporadically crash Testbeds~$10\pm$, an OpenCL device simulator and debugger. Upon reporting to the developers, the underlying cause was quickly diagnosed as a race condition in \texttt{switch} statement evaluation, and fixed within a week.

\paragraph{Device Memory} CLSmith kernels accept a single buffer parameter into which each thread computes its result. This fixed prototype limits the ability to detect bugs which depend on input arguments. Figure~\ref{lst:beig-ternary-ops} exposes a bug of this type. Testbed $3\pm$ will silently miscompile ternary operators when the ternary operands consist of values stored in multiple different global buffers. CLSmith, with its fixed single input prototype, is unable to discover this bug. % All data is allocated statically in global structs.

\paragraph{Latent Compile-time Defects} Sometimes, invalid compiler inputs may go undetected, leading to runtime defects only upon program execution. Since CLSmith enumerates only well-formed \cc{well-typed?} programs, this class of bugs cannot be discovered.

Figure~\ref{lst:pocl-undefined-symbols} exposes a bug in which a kernel containing an undefined symbol will successfully compile without warning on Testbed~$8\pm$, then crash the program when attempting to run the kernel. We have reported this issue to the developers.

%\subsection{Gray Areas and False Positives}
%
%None of the three statements in Figure~\ref{lst:xeon-phi-invalid-write} are executed by testbeds~$7\pm$, all other configurations return the final value. In testbeds $1\pm$ (but not $2\pm$), out-of-bounds memory reads and writes can be used to overflow into neighboring kernel arguments. In both cases, oclgrind can automatically catch the inalid accesses to prevent false-positives, but perhaps should results may be interesting for testing robustness / security. E.g.~\cite{Holler2012}.
%
%
%
%\begin{figure}
%  \centering %
%  \subfloat[The out-of-range write on line 3 is invalid, but does not affect execution of lines 2 and 4 for all testbeds except $7\pm$. On Testbeds $7\pm$, lines 2 and 4 execute when the invalid write has an index $1 \le i < 44032$, and not  when index $i \ge 44032$ or $i < 0$.]{%
%    \noindent\mbox{\parbox{\columnwidth}{\usebox{\XeonPhiInvalidWrite}}}%
%    \label{lst:xeon-phi-invalid-write}
%  }\\%
%  \caption{Example kernels which mis-match.}%
%  \label{lst:gray-areas}%
%\end{figure}
%
%\begin{figure}
%  \centering %
%  \subfloat[Read of uninitialized automatic variable \texttt{c}.]{%
%    \noindent\mbox{\parbox{\columnwidth}{\usebox{\UninitRead}}}%
%    \label{lst:uninit-read}
%  }\\%
%  \caption{False positives.}%
%  \label{lst:uninit-read}%
%\end{figure}


\subsection{Comparison to State-of-the-art}%
\label{subsec:vs_clsmith}

In this section we quantitatively compare the bug-finding capabilities of DeepSmith to CLSmith~\cite{Lidbury2015a}, the state-of-the-art in OpenCL compiler testing.

\paragraph{Results Overview}

\begin{table*}
  \scriptsize %
  \centering %
  \input{build/tab/megatable}
  \caption{%
    % CLSmith total ``interesting'': 19415
    % DeepSmith total ``interesting'': 8272
    Results from 48 hours of testing using CLSmith and DeepSmith. Testbed \#. as per Table~\ref{tab:platforms}. $\pm$ denotes optimizations off ($-$) vs on ($+$). The remaining columns denote the number of build crash (\textbf{bc}), build timeout (\textbf{bto}), build failure (\textbf{bf}), runtime crash (\textbf{c}), wrong-output (\textbf{w}), and pass (\textbf{\cmark}) results. \cc{remove ``Total'' row for submission}%
  }
  \label{tab:megatable}
\end{table*}

\begin{figure}
  \centering %
  \includegraphics[width=\columnwidth]{build/img/vs-clsmith}%
  \vspace{-1em}
  \caption{%
    Comparison of runtimes (a) and test case sizes (b). DeepSmith test cases are on average evaluated $3.03\times$ faster than CLSmith ($2.45\times$, and $4.46\times$ for generation and execution, respectively), and are two orders of magnitude smaller. Timings do not include the cost of timeouts which would increase the performance gains of DeepSmith by nearly a factor of two.
    % Runtimes, excluding timeouts. .%
%    Total speedup is 3.03x
%    CLgen generation is 2.45x faster than CLSmith
%    CLgen execution is 4.46x faster than CLSmith
%    CLgen reduction is 66.54x faster than CLSmith
  }%
  \label{fig:vs-clsmith} %
\end{figure}

Table~\ref{tab:megatable} shows the results of 48 hours of consecutive testing for all Testbeds. An average of 15k CLSmith and 91k DeepSmith test cases were evaluated on each Testbed, an average time per test case of 12.1s and 1.90s respectively. There are three significant factors providing the sixfold increase in testing throughput achieved by DeepSmith: test cases are faster to generate, test cases are less likely to timeout, and the test cases which do not timeout execute faster.

Figure~\ref{fig:vs-clsmith}a shows the generation and execution times of DeepSmith and CLSmith test cases, excluding timeouts\footnote{If timeouts are included then the performance improvement of DeepSmith is $6.5\times$ with the execution times being $11\times$ faster. However, this number grows as we change the arbitrary timeout threshold, so for fairness we have chosen to exclude it.}. DeepSmith generation time grows linearly with program length, and is on average $2.45\times$ faster than CLSmith. Test case execution is on average $4.46\times$ faster than CLSmith.

Optimization level generally does not affect testing throughput significantly, with the exception of Testbed $7+$. Optimization of large structs is expensive on testbed $7+$, and CLSmith test cases use global structs extensively. This is a known issue --- in~\cite{Lidbury2015a} the authors omit large-scale testing on this device for this reason. The use of structs in real life OpenCL is comparatively rare --- only 7.1\% of kernels on GitHub use them.

% 83.8\% of CLSmith test cases produce a majority \textbf{\cmark} outcome. Proportionally, DeepSmith test cases are less likely to produce a majority pass at 47.9\% of the total. \cc{This includes compile-only test cases?}.


\paragraph{Comparison of Test Cases} %
The average CLSmith program is 1189 lines long (excluding headers). CLSmith test cases require reduction in order to expose the underlying bug. An automated approach to OpenCL test case reduction is presented in~\cite{Pflanzer2016}, though it requires on average 100 minutes for each test case using a parallelized implementations (and over 6 hours if this parallelization is not available); the authors also suggest a final manual pass after automated reduction. In contrast, DeepSmith learned to program from humans, and humans do not typically write such large kernel functions. The average DeepSmith kernel is 20 lines long, which is interpretable without reduction, either manual or automatic. 

% CLSmith program sizes:
%+--------+-----------+--------+
%| minlen | meanlen   | maxlen |
%+--------+-----------+--------+
%|     56 | 1186.8496 |  11222 |
%+--------+-----------+--------+
% DeepSmith:
%+--------+---------+--------+
%| minlen | meanlen | maxlen |
%+--------+---------+--------+
%|      1 | 20.3163 |    636 |
%+--------+---------+--------+

% TODO: no thread control flow

% TODO: no floats

% TODO: single input

\paragraph{Comparison of Results} %
Both testing systems found anomalous results of all types.

% bc column:
% CLSmith generated 3800 silent build crashes. CLgen generated 1023 silent build crashes. Lets ignore these, since we can't be sure of the cause.
% CLSmith triggered 2 distinct compiler assertions. DeepSmith triggered 31.
% CLSmith triggered 0 distinct compiler ``unreachable'' errors. DeepSmith triggered 3.
In 48 hours of testing, CLSmith discovered compile-time crashes (\textbf{bc}) in 8 of the 20 testbeds, DeepSmith crashed all of them. DeepSmith triggered 31 distinct compiler assertions, CLSmith 2. Both of the assertions triggered by CLSmith were also triggered by CLgen. DeepSmith also triggered 3 distinct \emph{unreachable!} compile-time crashes, CLSmith triggered 0.

The Intel CPU testbeds (Testbeds 4--7) would occasionally emit a stack trace upon crashing, identifying the failure point in a specific pass. CLSmith triggered crashes in 4 distinct passes. DeepSmith triggered crashes in 10 distinct passes, including 3 of the 4 which CLSmith did. Figure~\ref{lst:intel-passes} provides examples. Many of these crashes are optimization sensitive. CLSmith was able to induce a crash in only one of the Intel testbeds with optimizations disabled. DeepSmith crashed all of the compilers with both optimizations enabled and disabled.

% DeepSmith triggered crashes in ten Intel passes, including three of the four which CLSmith triggered (the one missing one is \emph{Paketize function}).

% CLSmith crash passes:
% Combine Redundant instructions
% Packetize function
% Post-dominance Frontier Construction
% Predicator
%
% DeepSmith crash passes:
% Add SPIR related module scope metadata
% Combine Redundant instructions <- CLSmith triggered this too
% Intel OpenCL Barrier
% LoopWIAnalysis
% Post-dominance frontier construction <- CLSmith triggered this too
% Predicator <- CLSmith triggered this too
% PrepareKernelArgs
% RemoveDuplicateBarrier
% Simplify the CFG
% X86 DAG

\begin{figure}
  \centering
  % Result id: 110876
  \subfloat[\emph{Post-Dominance Frontier Construction} pass.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\IntelPostDominanceFrontier}}}%
    \label{lst:intel-postdominance-frontier}
  }\\%
  % Program id: 31656
  \subfloat[\emph{Predicator} pass.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\IntelPredicator}}}%
    \label{lst:intel-predicator}
  }\\%
  \subfloat[\emph{Combine redundant instructions} pass.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\IntelCombineRedundant}}}%
    \label{lst:intel-spir-metadata}
  }\\%
  % Program id: 10596
  \subfloat[\emph{PrepareKernelArgs} pass.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\IntelPrepareKernelArgs}}}%
    \label{lst:intel-prepare-kernel-args}
  }\\%
  % Program id: 37443
  \subfloat[\emph{Add SPIR related module scope metadata} pass.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\IntelSPIRMetadata}}}%
    \label{lst:intel-spir-metadata}
  }\\%
  % Program id: 44105
  \subfloat[\emph{Intel OpenCL RemoveDuplicationBarrier} pass.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\IntelRemoveDupeBarrier}}}%
    \label{lst:intel-spir-metadata}
  }\\%
  % CLgen result ID 452598
  % \cc{TODO: Intel pass \emph{X86 DAG->DAG Instruction Selection}}
  % kernel void A(global half* a) {
  %   int b = get_global_id(0);
  %   a[b] = b * b;
  % }
  % CLgen result ID 1903475
  % \cc{TODO: Intel pass \emph{Intel OpenCL Barrier}}
  % kernel void A(global float* a, global float* b, const int c) {
  %   int d = get_global_id(8);
  %   b[d] = a[d] + b[d];
  % }
  \caption{Example kernels which crash Intel compiler passes.}%
  \label{lst:intel-passes}
\end{figure}

% bto column:

% CLSmith triggered 4 distinct stack dumps (all from Intel passes). DeepSmith triggered 11 (10 from Intel passes, and multiple parser crashes).

CLSmith produced many \textbf{bto} results across 13 Testbeds. Given the large kernel size, it is unclear how many of those are infinite loops or simply a result of slow compilation of large kernels. The average size of CLSmith \textbf{bto} kernels is XX lines. Automated test case reduction --- in which thousands of permutations of a program are executed --- may be prohibitively expensive for test cases with very long runtimes. DeepSmith produced \textbf{bto} results across 11 Testbeds and with an average kernel size of XX lines, allowing for rapid identification of the underlying problem.


\begin{figure}
  \centering %
  \subfloat[Assertion \emph{storing/loading pointers only support private array}.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\BeigPtrAssertion}}}%
    \label{lst:beig-ptr-assertion}
  }\\%
  \subfloat[Assertion \emph{iter != pointerOrigMap.end()}.]{%
    \noindent\mbox{\parbox{\columnwidth}{\usebox{\BeigIterAssertion}}}%
    \label{lst:beig-iter-assertion}
  }\\%
  \caption{Example kernels which trigger compiler assertions which both CLSmith and DeepSmith exposed.}%
  \label{lst:beig-assertions}
\end{figure}

The integrated GPU Testbed ($3\pm$) frequently failed to compile CLSmith kernels, resulting in over 10k \textbf{bc} and \textbf{bto} results.
% 10,318
% SELECT stderr,COUNT(*) FROM CLSmithResults LEFT JOIN CLSmithMetas ON CLSmithResults.id=CLSmithMetas.id WHERE testbed_id=13 AND CLSmithResults.outcome='bc' AND cumtime < 48 * 3600 GROUP BY CLSmithResults.stderr;
Of the build crashes, 68\% failed silently, and the remainder were caused by the same two compiler assertions for which DeepSmith generated 4 line test cases, shown in Figure~\ref{lst:beig-assertions}. DeepSmith also triggered silent build crashes in Testbed $3\pm$, and a further 8 distinct compiler assertions.

% bf column: CLSmith generated 1 unique build failure (empty declaration). DeepSmith generated 6 unique build failures (including the same empty declaration as CLSmith).
The 4719 \textbf{bf} results for CLSmith on Testbeds $4\pm$ and $6\pm$ are all a result of compilers rejecting empty declarations, (e.g. \texttt{int;}) which CLSmith occasionally emits. DeepSmith also generated these statements, but with a much lower probability (only XX programs) given that it is an unusual construct.
% https://github.com/ChrisLidbury/CLSmith/issues/7
Similarly, Testbeds 4--7 reject DeepSmith kernels which omit a type specified (e.g. \texttt{\_\_global* a}), whereas all other Testbeds emit a warning and default to \texttt{int} type.

% c column

\cc{TODO: CLSmith Testbed $8-$ crashes, Testbed $2-$ crashes} Both CLSmith and DeepSmith cause Testbed $9\pm$ to crash silently during kernel execution. We suspect that this is \cc{latent build crash. ComputeAorta defers kernel compilation so that it can perform optimizations dependent on runtime parameters}

% CLSmith triggered 2 distinct crashes. DeepSmith triggered 2. Both produced silent crashes where we can't be sure of the cause.

% w column: CLSmith produced 51 distinct wrong-output test cases. Conservatively, let's assume they'll all interesting. DeepSmith produced 69 distinct wrong-output test cases. Conservatively, let's assume that only the bug reports we've submitted are interesting (3).
Over the course of testing, a combined $3.4 \times 10^8$ lines of CLSmith code was evaluated, compared to $3.8 \times 10^6$ lines of DeepSmith code. This provides CLSmith a greater potential to trigger miscompilations. CLSmith generated 33 programs with wrong-outputs. DeepSmith generated 30. 
%For this reason, we believe our approach to be complimentary, with CLSmith providing targeted middle-end stress-testing, and DeepSmith providing a broader class of bugs. \cc{Hugh, Pavlos, do you agree?}\hl{Don't think we need to draw such conclusions here.} However, as shown in Section~\ref{subsec:runtime-defects}, DeepSmith is capable of discovering miscompilations which CLSmith cannot. \cc{I'm not sure what we have to say about miscompilations. We didn't reduce CLSmith's, so there may be duplicates, and we definitely have false-positives in the 'w' column.}


%\paragraph{Bug Diversity} %
%
%\hl{ditch.}
%The design of CLSmith biases the system towards identifying miscompilations. %
% esp. struct miscompilations, though only 7.1\% of OpenCL kernels on GitHub use them
%Our results indicate that our system is capable of detecting a broader range of compiler defects, including miscompilations which CLSmith is unable to produce test cases for. For example, Oclgrind was resilient to CLSmith testing, yet we identified both compile-time and runtime defects.
%
%Our approach is biased towards identifying bugs in compiler front-ends, since not all generated programs are well formed/well typed. Overall, we believe the two systems to be complimentary, with CLSmith providing targeted middle-end stress-testing.


\subsection{Compiler Stability over Time}%
\label{subsec:clangs}

\begin{figure}
  \centering %
  \includegraphics[width=.95\columnwidth]{build/img/clang-crashes}%
  \caption{%
    Crash rate of the Clang front-end of every LLVM release in the past 24 months compiling 75k DeepSmith kernels.
  }%
  \label{fig:clangs} %
\end{figure}

\begin{table}
  \scriptsize %
  \centering %
  \input{build/tab/clang-assert-counts}
  \caption{%
    The number of DeepSmith programs which trigger distinct Clang front-end assertions, and the number of programs which trigger unreachables.%
  }
  \label{tab:clangs}
\end{table}

The Clang front-end to LLVM supports OpenCL, and is commonly used in OpenCL drivers. This in turn causes Clang-related defects to potentially affect multiple compilers, for example the one in Figure~\ref{lst:almost-everything-crash}. To evaluate the impact of Clang, we used debug+assert builds of every LLVM release in the past 24 months and processed 75,000 DeepSmith kernels through the Clang front-end (this includes the lexer, parser, and type checker, but not code generation).

Figure~\ref{fig:clangs} shows that the crash rate of Clang front-ends is, for the most part, steadily decreasing over time. The number of failing compiler crashes decreased tenfold between 3.6.2 and 6.0.0.
%\cc{Does that suggest that DeepSmith is finding bugs which developers are interested in fixing?} \pp{We do find interesting bugs, but the important question is whether we are more likely to find interesting bugs than CLSmith.}
Table~\ref{tab:clangs} shows the 7 distinct assertions triggered during this experiment. Assertion 1 (uncorrected typos) is raised on all compiler versions --- see Figure~\ref{lst:oclgrind-uncorrected-typos} for an example. The overall rate at which the assertion is triggered has decreased markedly, although there are slight increases between releases. This emphasizes that compiler validation is a moving target. Every change and feature addition has the potential to introduce regressions or new failure cases.

Release 6.0.0 has the second lowest crash rate, but is joint first in terms of the number of unique assertions. Assertions 3 and 4 where triggered by some kernels under version 6.0.0 but not under any other tested Clang version. An example of a kernel which crashes version 6.0.0 is shown in Figure~\ref{TODO}. This indicates that changes introduced in the latest version of Clang were not sufficiently tested \cc{OR that a new assertion was added! I need to check the source code}.

We have submitted bug reports for for each of the distinct assertions in LLVM 6.0.0, and two distinct unreachables.
